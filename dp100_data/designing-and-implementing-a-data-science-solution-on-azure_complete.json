{
  "url": "https://learn.microsoft.com/en-us/training/courses/dp-100t01",
  "title": "Designing and implementing a data science solution on Azure",
  "description": "",
  "learning_paths": [
    {
      "title": "Explore and configure the Azure Machine Learning workspace",
      "url": "https://learn.microsoft.com/en-us/training/paths/explore-azure-machine-learning-workspace/",
      "learn_uid": "learn.wwl.explore-azure-machine-learning-workspace",
      "modules": [
        {
          "title": "Explore Azure Machine Learning workspace resources and assets",
          "url": "https://learn.microsoft.com/en-us/training/modules/explore-azure-machine-learning-workspace-resources-assets/",
          "description": "",
          "learning_objectives": [],
          "prerequisites": [],
          "units": [
            {
              "number": 1,
              "title": "Introduction",
              "url": "https://learn.microsoft.com/en-us/training/modules/explore-azure-machine-learning-workspace-resources-assets/1-introduction",
              "href": "1-introduction",
              "content": "Read in English\nAdd\nAdd to plan\nIntroduction\nCompleted\n2 minutes\nAs a data scientist, you want to focus on training machine learning models. Ideally, you want to work with a service that gives you access to all the necessary infrastructure you need to train and deploy a model. You also want the service to allow you to track any work you do to make your model reproducible and robust.\nAzure Machine Learning provides a platform for data scientists to train, deploy, and manage their machine learning models on the Microsoft Azure platform. Azure Machine Learning provides a comprehensive set of\nresources\nand\nassets\nto train and deploy effective machine learning models.\nTo use these resources and assets, you create an Azure Machine Learning workspace resource in your Azure subscription. In the Azure Machine Learning workspace, you can manage data, compute resources, models, endpoints, and other artifacts related to your machine learning workloads.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Introduction"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 2,
              "title": "Create an Azure Machine Learning workspace",
              "url": "https://learn.microsoft.com/en-us/training/modules/explore-azure-machine-learning-workspace-resources-assets/2-provision",
              "href": "2-provision",
              "content": "Read in English\nAdd\nAdd to plan\nCreate an Azure Machine Learning workspace\nCompleted\n7 minutes\nTo get access to an Azure Machine Learning workspace, you first need to create the\nAzure Machine Learning\nservice in your Azure subscription. The\nworkspace\nis central place where you can work with all resources and assets available to train and deploy machine learning models. For reproducibility, the workspace stores a history of all training jobs, including logs, metrics, outputs, and a snapshot of your code.\nUnderstand the Azure Machine Learning service\nTo create an Azure Machine Learning service, you have to:\nGet access to\nAzure\n, for example through the Azure portal.\nSign in to get access to an\nAzure subscription\n.\nCreate a\nresource group\nwithin your subscription.\nCreate an\nAzure Machine Learning service\nto create a workspace.\nWhen a workspace is provisioned, Azure automatically creates other Azure resources within the same resource group to support the workspace:\nAzure Storage Account\n: To store files and notebooks used in the workspace, and to store metadata of jobs and models.\nAzure Key Vault\n: To securely manage secrets such as authentication keys and credentials used by the workspace.\nApplication Insights\n: To monitor predictive services in the workspace.\nAzure Container Registry\n: Created when needed to store images for Azure Machine Learning environments.\nCreate the workspace\nYou can create an Azure Machine Learning workspace in any of the following ways:\nUse the user interface in the\nAzure portal\nto create an Azure Machine Learning service.\nCreate an\nAzure Resource Manager\n(\nARM\n) template.\nLearn how to use an ARM template to create a workspace\n.\nUse the\nAzure Command Line Interface\n(\nCLI\n) with the Azure Machine Learning CLI extension.\nLearn how to create the workspace with the CLI v2\n.\nUse the\nAzure Machine Learning Python SDK\n.\nFor example, the following code uses the Python SDK to create a workspace named\nmlw-example\n:\nfrom azure.ai.ml.entities import Workspace\n\nworkspace_name = \"mlw-example\"\n\nws_basic = Workspace(\n    name=workspace_name,\n    location=\"eastus\",\n    display_name=\"Basic workspace-example\",\n    description=\"This example shows how to create a basic workspace\",\n)\nml_client.workspaces.begin_create(ws_basic)\nExplore the workspace in the Azure portal\nCreating an Azure Machine Learning workspace typically takes between 5-10 minutes to complete. When your workspace is created, you can select the workspace to view its details.\nFrom the\nOverview\npage of the Azure Machine Learning workspace in the Azure portal, you can launch the Azure Machine Learning studio. The Azure Machine Learning studio is a web portal and provides an easy-to-use interface to create, manage, and use resources and assets in the workspace.\nFrom the Azure portal, you can also give others access to the Azure Machine Learning workspace, using the\nAccess control\n.\nGive access to the Azure Machine Learning workspace\nYou can give individual users or teams access to the Azure Machine Learning workspace. Access is granted in Azure using\nrole-based access control\n(\nRBAC\n), which you can configure in the\nAccess control\ntab of the resource or resource group.\nIn the access control tab, you can manage permissions to restrict what actions certain users or teams can perform. For example, you could create a policy that only allows users in the\nAzure administrators group\nto create compute targets and datastores. While users in the\ndata scientists group\ncan create and run jobs to train models, and register models.\nThere are three general built-in roles that you can use across resources and resource groups to assign permissions to other users:\nOwner\n: Gets full access to all resources, and can grant access to others using access control.\nContributor\n: Gets full access to all resources, but can't grant access to others.\nReader\n: Can only view the resource, but isn't allowed to make any changes.\nAdditionally, Azure Machine Learning has specific built-in roles you can use:\nAzureML Data Scientist\n: Can perform all actions within the workspace, except for creating or deleting compute resources, or editing the workspace settings.\nAzureML Compute Operator\n: Is allowed to create, change, and manage access the compute resources within a workspace.\nFinally, if the built-in roles aren't meeting your needs, you can create a custom role to assign permissions to other users.\nTip\nLearn more about\nhow to manage access to an Azure Machine Learning workspace, including creating custom roles\n.\nOrganize your workspaces\nInitially, you might only work with one workspace. However, when working on large-scale projects, you might choose to use multiple workspaces.\nYou can use workspaces to group machine learning assets based on projects, deployment environments (for example, test and production), teams, or some other organizing principle.\nTip\nLearn more about\nhow to organize Azure Machine Learning workspaces for an enterprise environment\n.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Create an Azure Machine Learning workspace"
                },
                {
                  "level": 2,
                  "text": "Understand the Azure Machine Learning service"
                },
                {
                  "level": 3,
                  "text": "Create the workspace"
                },
                {
                  "level": 2,
                  "text": "Explore the workspace in the Azure portal"
                },
                {
                  "level": 2,
                  "text": "Give access to the Azure Machine Learning workspace"
                },
                {
                  "level": 2,
                  "text": "Organize your workspaces"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "mlw-example",
                "from azure.ai.ml.entities import Workspace\n\nworkspace_name = \"mlw-example\"\n\nws_basic = Workspace(\n    name=workspace_name,\n    location=\"eastus\",\n    display_name=\"Basic workspace-example\",\n    description=\"This example shows how to create a basic workspace\",\n)\nml_client.workspaces.begin_create(ws_basic)",
                "from azure.ai.ml.entities import Workspace\n\nworkspace_name = \"mlw-example\"\n\nws_basic = Workspace(\n    name=workspace_name,\n    location=\"eastus\",\n    display_name=\"Basic workspace-example\",\n    description=\"This example shows how to create a basic workspace\",\n)\nml_client.workspaces.begin_create(ws_basic)"
              ],
              "images": [
                {
                  "src": "../../wwl-azure/explore-azure-machine-learning-workspace-resources-assets/media/overview-azure-resources.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/explore-azure-machine-learning-workspace-resources-assets/media/overview-azure-resources.png",
                  "alt_text": "Diagram of hierarchy of Azure resources needed for the Azure Machine Learning workspace.",
                  "title": "",
                  "filename": "overview-azure-resources.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Understand the Azure Machine Learning service",
                    "following_text": "You can create an Azure Machine Learning workspace in any of the following ways:",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-azure/explore-azure-machine-learning-workspace-resources-assets/media/workspace-portal.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/explore-azure-machine-learning-workspace-resources-assets/media/workspace-portal.png",
                  "alt_text": "Screenshot of the overview page of the Azure Machine Learning workspace in the Azure portal.",
                  "title": "",
                  "filename": "workspace-portal.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Explore the workspace in the Azure portal",
                    "following_text": "From theOverviewpage of the Azure Machine Learning workspace in the Azure portal, you can launch the Azure Machine Learning studio. The Azure Machine Learning studio is a web portal and provides an ea",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-create-workspace-template?tabs=azcli?azure-portal=true",
                  "text": "Learn how to use an ARM template to create a workspace"
                },
                {
                  "url": "/en-us/training/modules/create-azure-machine-learning-resources-cli-v2/?azure-portal=true",
                  "text": "Learn how to create the workspace with the CLI v2"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-assign-roles?azure-portal=true",
                  "text": "how to manage access to an Azure Machine Learning workspace, including creating custom roles"
                },
                {
                  "url": "/en-us/azure/cloud-adoption-framework/ready/azure-best-practices/ai-machine-learning-resource-organization?azure-portal=true",
                  "text": "how to organize Azure Machine Learning workspaces for an enterprise environment"
                }
              ]
            },
            {
              "number": 3,
              "title": "Identify Azure Machine Learning resources",
              "url": "https://learn.microsoft.com/en-us/training/modules/explore-azure-machine-learning-workspace-resources-assets/3-identify-resources",
              "href": "3-identify-resources",
              "content": "Read in English\nAdd\nAdd to plan\nIdentify Azure Machine Learning resources\nCompleted\n6 minutes\nResources\nin Azure Machine Learning refer to the infrastructure you need to run a machine learning workflow. Ideally, you want someone like an administrator to create and manage the resources.\nThe resources in Azure Machine Learning include:\nThe workspace\nCompute resources\nDatastores\nCreate and manage the workspace\nThe\nworkspace\nis the top-level resource for Azure Machine Learning. Data scientists need access to the workspace to train and track models, and to deploy the models to endpoints.\nHowever, you want to be careful with who has\nfull\naccess to the workspace. Next to references to compute resources and datastores, you can find all logs, metrics, outputs, models, and snapshots of your code in the workspace.\nCreate and manage compute resources\nOne of the most important resources you need when training or deploying a model is\ncompute\n. There are five types of compute in the Azure Machine Learning workspace:\nCompute instances\n: Similar to a virtual machine in the cloud, managed by the workspace. Ideal to use as a development environment to run (Jupyter) notebooks.\nCompute clusters\n: On-demand clusters of CPU or GPU compute nodes in the cloud, managed by the workspace. Ideal to use for production workloads as they automatically scale to your needs.\nKubernetes clusters\n: Allows you to create or attach an Azure Kubernetes Service (AKS) cluster. Ideal to deploy trained machine learning models in production scenarios.\nAttached computes\n: Allows you to attach other Azure compute resources to the workspace, like Azure Databricks or Synapse Spark pools.\nServerless compute\n: A fully managed, on-demand compute you can use for training jobs.\nNote\nAs Azure Machine Learning creates and manages\nserverless compute\nfor you, it's not listed on the compute page in the studio. Learn more about how to\nuse serverless compute for model training\nThough compute is the most important resource when working with machine learning workloads, it can also be the most cost-intensive. Therefore, a best practice is to only allow administrators to create and manage compute resources. Data scientists shouldn't be allowed to edit compute, but only use the available compute to run their workloads.\nCreate and manage datastores\nThe workspace doesn't store any data itself. Instead, all data is stored in\ndatastores\n, which are references to Azure data services. The connection information to a data service that a datastore represents, is stored in the Azure Key Vault.\nWhen a workspace is created, an Azure Storage account is created and automatically connected to the workspace. As a result, you have four datastores already added to your workspace:\nworkspaceartifactstore\n: Connects to the\nazureml\ncontainer of the Azure Storage account created with the workspace. Used to store compute and experiment logs when running jobs.\nworkspaceworkingdirectory\n: Connects to the file share of the Azure Storage account created with the workspace used by the\nNotebooks\nsection of the studio. Whenever you upload files or folders to access from a compute instance, the files or folders are uploaded to this file share.\nworkspaceblobstore\n: Connects to the Blob Storage of the Azure Storage account created with the workspace. Specifically the\nazureml-blobstore-...\ncontainer. Set as the default datastore, which means that whenever you create a data asset and upload data, you store the data in this container.\nworkspacefilestore\n: Connects to the file share of the Azure Storage account created with the workspace. Specifically the\nazureml-filestore-...\nfile share.\nAdditionally, you can create datastores to connect to other Azure data services. Most commonly, your datastores connects to an Azure Storage Account or Azure Data Lake Storage (Gen2) as those data services are most often used in data science projects.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Identify Azure Machine Learning resources"
                },
                {
                  "level": 2,
                  "text": "Create and manage the workspace"
                },
                {
                  "level": 2,
                  "text": "Create and manage compute resources"
                },
                {
                  "level": 2,
                  "text": "Create and manage datastores"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "workspaceartifactstore",
                "workspaceworkingdirectory",
                "workspaceblobstore",
                "azureml-blobstore-...",
                "workspacefilestore",
                "azureml-filestore-..."
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-use-serverless-compute?azure-portal=true",
                  "text": "use serverless compute for model training"
                }
              ]
            },
            {
              "number": 4,
              "title": "Identify Azure Machine Learning assets",
              "url": "https://learn.microsoft.com/en-us/training/modules/explore-azure-machine-learning-workspace-resources-assets/4-identify-assets",
              "href": "4-identify-assets",
              "content": "Read in English\nAdd\nAdd to plan\nIdentify Azure Machine Learning assets\nCompleted\n7 minutes\nAs a data scientist, you mostly work with\nassets\nin the Azure Machine Learning workspace. Assets are created and used at various stages of a project and include:\nModels\nEnvironments\nData\nComponents\nCreate and manage models\nThe end product of training a model is the model itself. You can train machine learning models with various frameworks, like Scikit-learn or PyTorch. A common way to store such models is to package the model as a Python pickle file (\n.pkl\nextension).\nAlternatively, you can use the open-source platform MLflow to store your model in the MLModel format.\nTip\nLearn more about\nlogging workflow artifacts as models using MLflow and the MLModel format\n.\nWhatever format you choose, binary files represent the model and any corresponding metadata. To persist those files, you can create or register a model in the workspace.\nWhen you create a\nmodel\nin the workspace, you specify the\nname\nand\nversion\n. Especially useful when you deploy the registered model, versioning allows you to track the specific model you want to use.\nCreate and manage environments\nWhen you work with cloud compute, it's important to ensure that your code runs on any compute that is available to you. Whether you want to run a script on a compute instance, or a compute cluster, the code should execute successfully.\nImagine working in Python or R, using open-source frameworks to train a model, on your local device. If you want to use a library such as Scikit-learn or PyTorch, you have to install it on your device.\nSimilarly, when you write code that uses any frameworks or libraries, you need to ensure the necessary dependencies are installed on the compute that executes the code. To list all necessary requirements, you can create\nenvironments\n. When you create an environment, you have to specify the\nname\nand\nversion\n.\nEnvironments specify software packages, environment variables, and software settings to run scripts. An environment is stored as an image in the Azure Container Registry created with the workspace when it's used for the first time.\nWhenever you want to run a script, you can specify the environment that needs to be used by the compute target. The environment installs all necessary requirements on the compute before executing the script, making your code robust and reusable across compute targets.\nCreate and manage data\nWhereas datastores contain the connection information to Azure data storage services,\ndata assets\nrefer to a specific file or folder.\nYou can use data assets to easily access data every time, without having to provide authentication every time you want to access it.\nWhen you create a data asset in the workspace, you specify the path to point to the file or folder, and the\nname\nand\nversion\n.\nCreate and manage components\nTo train machine learning models, you write code. Across projects, there can be code you can reuse. Instead of writing code from scratch, you want to reuse snippets of code from other projects.\nTo make it easier to share code, you can create a\ncomponent\nin a workspace. To create a component, you have to specify the\nname\n,\nversion\n, code, and\nenvironment\nneeded to run the code.\nYou can use components when creating\npipelines\n. A component therefore often represents a step in a pipeline, for example to normalize data, to train a regression model, or to test the trained model on a validation dataset.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Identify Azure Machine Learning assets"
                },
                {
                  "level": 2,
                  "text": "Create and manage models"
                },
                {
                  "level": 2,
                  "text": "Create and manage environments"
                },
                {
                  "level": 2,
                  "text": "Create and manage data"
                },
                {
                  "level": 2,
                  "text": "Create and manage components"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/concept-mlflow-models?azure-portal=true",
                  "text": "logging workflow artifacts as models using MLflow and the MLModel format"
                }
              ]
            },
            {
              "number": 5,
              "title": "Train models in the workspace",
              "url": "https://learn.microsoft.com/en-us/training/modules/explore-azure-machine-learning-workspace-resources-assets/5-run-jobs",
              "href": "5-run-jobs",
              "content": "Read in English\nAdd\nAdd to plan\nTrain models in the workspace\nCompleted\n6 minutes\nTo train models with the Azure Machine Learning workspace, you have several options:\nUse\nAutomated Machine Learning\n.\nRun a Jupyter notebook.\nRun a script as a job.\nExplore algorithms and hyperparameter values with Automated Machine Learning\nWhen you have a training dataset and you're tasked with finding the best performing model, you might want to experiment with various algorithms and hyperparameter values.\nManually experimenting with different configurations to train a model might take long. Alternatively, you can use Automated Machine Learning to speed up the process.\nAutomated Machine Learning iterates through algorithms paired with feature selections to find the best performing model for your data.\nRun a notebook\nWhen you prefer to develop by running code in notebooks, you can use the built-in notebook feature in the workspace.\nThe\nNotebooks\npage in the studio allows you to edit and run Jupyter notebooks.\nAll files you clone or create in the notebooks section are stored in the file share of the Azure Storage account created with the workspace.\nTo run notebooks, you use a compute instance as they're ideal for development and work similar to a virtual machine.\nYou can also choose to edit and run notebooks in Visual Studio Code, while still using a compute instance to run the notebooks.\nRun a script as a job\nWhen you want to prepare your code to be production ready, it's better to use scripts. You can easily automate the execution of script to automate any machine learning workload.\nYou can run a script as a\njob\nin Azure Machine Learning. When you submit a job to the workspace, all inputs and outputs are stored in the workspace.\nThere are different types of jobs depending on how you want to execute a workload:\nCommand\n: Execute a single script.\nSweep\n: Perform hyperparameter tuning when executing a single script.\nPipeline\n: Run a pipeline consisting of multiple scripts or components.\nNote\nWhen you submit a pipeline you created with the designer it will run as a pipeline job. When you submit an Automated Machine Learning experiment, it will also run as a job.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Train models in the workspace"
                },
                {
                  "level": 2,
                  "text": "Explore algorithms and hyperparameter values with Automated Machine Learning"
                },
                {
                  "level": 2,
                  "text": "Run a notebook"
                },
                {
                  "level": 2,
                  "text": "Run a script as a job"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-azure/explore-azure-machine-learning-workspace-resources-assets/media/automated-machine-learning.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/explore-azure-machine-learning-workspace-resources-assets/media/automated-machine-learning.png",
                  "alt_text": "Screenshot of a task selection when configuring Automated Machine Learning.",
                  "title": "",
                  "filename": "automated-machine-learning.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Explore algorithms and hyperparameter values with Automated Machine Learning",
                    "following_text": "When you prefer to develop by running code in notebooks, you can use the built-in notebook feature in the workspace.",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-azure/explore-azure-machine-learning-workspace-resources-assets/media/notebooks.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/explore-azure-machine-learning-workspace-resources-assets/media/notebooks.png",
                  "alt_text": "Screenshot of an open notebook in the Azure Machine Learning studio.",
                  "title": "",
                  "filename": "notebooks.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Run a notebook",
                    "following_text": "All files you clone or create in the notebooks section are stored in the file share of the Azure Storage account created with the workspace.",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-azure/explore-azure-machine-learning-workspace-resources-assets/media/job-overview.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/explore-azure-machine-learning-workspace-resources-assets/media/job-overview.png",
                  "alt_text": "Screenshot of the overview of a command job showing the properties, inputs, and outputs.",
                  "title": "",
                  "filename": "job-overview.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Run a script as a job",
                    "following_text": "There are different types of jobs depending on how you want to execute a workload:",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 6,
              "title": "Exercise - Explore the workspace",
              "url": "https://learn.microsoft.com/en-us/training/modules/explore-azure-machine-learning-workspace-resources-assets/6-exercise-explore-workspace",
              "href": "6-exercise-explore-workspace",
              "content": "Read in English\nAdd\nAdd to plan\nExercise - Explore the workspace\nCompleted\n10 minutes\nNow, it's your chance to create and explore the workspace.\nIn this exercise, you learn how to:\nCreate an Azure Machine Learning workspace.\nExplore the Azure Machine Learning studio.\nRun a training job.\nInstructions\nLaunch the exercise and follow the instructions.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Exercise - Explore the workspace"
                },
                {
                  "level": 2,
                  "text": "Instructions"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-azure/explore-azure-machine-learning-workspace-resources-assets/media/launch-exercise.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/explore-azure-machine-learning-workspace-resources-assets/media/launch-exercise.png",
                  "alt_text": "Button to launch exercise.",
                  "title": "",
                  "filename": "launch-exercise.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Instructions",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 7,
              "title": "Module assessment",
              "url": "https://learn.microsoft.com/en-us/training/modules/explore-azure-machine-learning-workspace-resources-assets/7-knowledge-check",
              "href": "7-knowledge-check",
              "content": "Read in English\nAdd\nAdd to plan\nModule assessment\nCompleted\n3 minutes\n1.\nA data scientist needs access to the Azure Machine Learning workspace to run a script as a job. Which role should be used to give the data scientist the necessary access to the workspace?\nReader.\nAzure Machine Learning Data Scientist.\nAzure Machine Learning Compute Operator.\n2.\nThe data scientist wants to run a single script to train a model. What type of job is the best fit to run a single script?\nCommand\nPipeline\nSweep\nYou must answer all questions before checking your work.\nYou must answer all questions before checking your work.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Module assessment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 8,
              "title": "Summary",
              "url": "https://learn.microsoft.com/en-us/training/modules/explore-azure-machine-learning-workspace-resources-assets/8-summary",
              "href": "8-summary",
              "content": "Read in English\nAdd\nAdd to plan\nSummary\nCompleted\n1 minute\nIn this module, you learned how to:\nCreate an Azure Machine Learning workspace.\nIdentify resources and assets.\nTrain models in the workspace.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Summary"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            }
          ]
        },
        {
          "title": "Explore developer tools for workspace interaction",
          "url": "https://learn.microsoft.com/en-us/training/modules/explore-developer-tools-for-workspace-interaction/",
          "description": "",
          "learning_objectives": [],
          "prerequisites": [],
          "units": [
            {
              "number": 1,
              "title": "Introduction",
              "url": "https://learn.microsoft.com/en-us/training/modules/explore-developer-tools-for-workspace-interaction/1-introduction",
              "href": "1-introduction",
              "content": "Read in English\nAdd\nAdd to plan\nIntroduction\nCompleted\n2 minutes\nAzure Machine Learning provides data scientists with several resources and assets to build and manage machine learning models.\nYou can create and manage resources and assets by using various tools that interact with the Azure Machine Learning workspace.\nThough you can use any tool to perform the same tasks, each tool provides advantages and disadvantages for specific workloads. You can choose which tool or developer approach best fits your needs.\nImportant\nAzure Machine Learning has introduced version 2 (v2) to introduce a consistency of features and terminology across interfaces. You should use v2 if you're starting a new machine learning project. Therefore, this module only covers v2. Learn more about\ndeciding between v1 and v2\n.\nLearning objectives\nIn this module, you'll learn how and when to use:\nThe Azure Machine Learning studio.\nThe Python Software Development Kit (SDK).\nThe Azure Command Line Interface (CLI).\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Introduction"
                },
                {
                  "level": 2,
                  "text": "Learning objectives"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-migrate-from-v1?azure-portal=true",
                  "text": "deciding between v1 and v2"
                }
              ]
            },
            {
              "number": 2,
              "title": "Explore the studio",
              "url": "https://learn.microsoft.com/en-us/training/modules/explore-developer-tools-for-workspace-interaction/2-explore-studio",
              "href": "2-explore-studio",
              "content": "Read in English\nAdd\nAdd to plan\nExplore the studio\nCompleted\n6 minutes\nThe easiest and most intuitive way to interact with the Azure Machine Learning workspace, is by using the\nstudio\n.\nThe Azure Machine Learning studio is a web portal, which provides an overview of all resources and assets available in the workspace.\nAccess the studio\nAfter you've created an Azure Machine Learning workspace, there are two common ways to access the Azure Machine Learning studio:\nLaunch the studio from the\nOverview\npage of the Azure Machine Learning workspace resource in the Azure portal.\nNavigate to the studio directly by signing in at\nhttps://ml.azure.com\nusing the credentials associated with your Azure subscription.\nWhen you've opened your workspace in the Azure Machine Learning studio, a menu appears in the sidebar.\nThe menu shows what you can do in the studio:\nAuthor\n: Create new jobs to train and track a machine learning model.\nAssets\n: Create and review assets you use when training models.\nManage\n: Create and manage resources you need to train models.\nThough you can use each tool at any time, the studio is ideal for quick experimentation or when you want to explore your past jobs.\nFor example, use the studio if you want to verify that your pipeline ran successfully. Or when a pipeline job has failed, you can use the studio to navigate to the logs and review the error messages.\nFor more repetitive work, or tasks that you'd like to automate, the Azure CLI or Python SDK are better suited as these tools allow you to define your work in code.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Explore the studio"
                },
                {
                  "level": 2,
                  "text": "Access the studio"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-azure/explore-developer-tools-for-workspace-interaction/media/studio-home.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/explore-developer-tools-for-workspace-interaction/media/studio-home.png",
                  "alt_text": "Diagram of different hyperparameter values resulting in different models by performing hyperparameter tuning.",
                  "title": "",
                  "filename": "studio-home.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Access the studio",
                    "following_text": "The menu shows what you can do in the studio:",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "https://ml.azure.com?azure-portal=true",
                  "text": "https://ml.azure.com"
                }
              ]
            },
            {
              "number": 3,
              "title": "Explore the Python SDK",
              "url": "https://learn.microsoft.com/en-us/training/modules/explore-developer-tools-for-workspace-interaction/3-explore-python-sdk",
              "href": "3-explore-python-sdk",
              "content": "Read in English\nAdd\nAdd to plan\nExplore the Python SDK\nCompleted\n7 minutes\nImportant\nCurrently, there are two versions of the Python SDK: version 1 (v1) and version 2 (v2). For any new projects, you should use v2 and therefore,\nthe content in this unit only covers v2\n. Learn more about\ndeciding between v1 and v2\n.\nData scientists can use Azure Machine Learning to train, track, and manage machine learning models. As a data scientist, you'll mostly work with the assets within the Azure Machine Learning workspace for your machine learning workloads.\nAs most data scientists are familiar with Python, Azure Machine Learning offers a software development kit (SDK) so that you can interact with the workspace using Python.\nThe Python SDK for Azure Machine Learning is an ideal tool for data scientists that can be used in any Python environment. Whether you normally work with Jupyter notebooks, Visual Studio Code, you can install the Python SDK and connect to the workspace.\nInstall the Python SDK\nTo install the Python SDK within your Python environment, you need Python 3.7 or later. You can install the package with\npip\n:\npip install azure-ai-ml\nNote\nWhen working with notebooks within the Azure Machine Learning studio, the new Python SDK is already installed when using Python 3.10 or later. You can use the Python SDK v2 with earlier versions of Python, but you'll have to install it first.\nConnect to the workspace\nAfter the Python SDK is installed, you'll need to connect to the workspace. By connecting, you're authenticating your environment to interact with the workspace to create and manage assets and resources.\nTo authenticate, you need the values to three necessary parameters:\nsubscription_id\n: Your subscription ID.\nresource_group\n: The name of your resource group.\nworkspace_name\n: The name of your workspace.\nNext, you can define the authentication by using the following code:\nfrom azure.ai.ml import MLClient\nfrom azure.identity import DefaultAzureCredential\n\nml_client = MLClient(\n    DefaultAzureCredential(), subscription_id, resource_group, workspace\n)\nAfter defining the authentication, you need to call\nMLClient\nfor the environment to connect to the workspace. You'll call\nMLClient\nanytime you want to create or update an asset or resource in the workspace.\nFor example, you'll connect to the workspace when you create a new job to train a model:\nfrom azure.ai.ml import command\n\n# configure job\njob = command(\n    code=\"./src\",\n    command=\"python train.py\",\n    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n    compute=\"aml-cluster\",\n    experiment_name=\"train-model\"\n)\n\n# connect to workspace and submit job\nreturned_job = ml_client.create_or_update(job)\nUse the reference documentation\nTo efficiently work with the Python SDK, you'll need to use the reference documentation. In the reference documentation, you'll find all possible classes, methods, and parameters available within the Python SDK.\nThe reference documentation on the\nMLClient\nclass\nincludes the methods you can use to connect and interact with the workspace. Moreover, it also links to the possible operations for the various entities like how to list the existing datastores in your workspace.\nThe reference documentation also includes a list of the classes for all entities\nyou can interact with. For example, separate classes exist when you want to create a datastore that links to an Azure Blob Storage, or to an Azure Data Lake Gen 2.\nBy selecting a specific class like\nAmlCompute\nfrom the list of entities, you can find\na more detailed page on how to use the class and what parameters it accepts\n.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Explore the Python SDK"
                },
                {
                  "level": 2,
                  "text": "Install the Python SDK"
                },
                {
                  "level": 2,
                  "text": "Connect to the workspace"
                },
                {
                  "level": 2,
                  "text": "Use the reference documentation"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "pip install azure-ai-ml",
                "pip install azure-ai-ml",
                "subscription_id",
                "resource_group",
                "workspace_name",
                "from azure.ai.ml import MLClient\nfrom azure.identity import DefaultAzureCredential\n\nml_client = MLClient(\n    DefaultAzureCredential(), subscription_id, resource_group, workspace\n)",
                "from azure.ai.ml import MLClient\nfrom azure.identity import DefaultAzureCredential\n\nml_client = MLClient(\n    DefaultAzureCredential(), subscription_id, resource_group, workspace\n)",
                "from azure.ai.ml import command\n\n# configure job\njob = command(\n    code=\"./src\",\n    command=\"python train.py\",\n    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n    compute=\"aml-cluster\",\n    experiment_name=\"train-model\"\n)\n\n# connect to workspace and submit job\nreturned_job = ml_client.create_or_update(job)",
                "from azure.ai.ml import command\n\n# configure job\njob = command(\n    code=\"./src\",\n    command=\"python train.py\",\n    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n    compute=\"aml-cluster\",\n    experiment_name=\"train-model\"\n)\n\n# connect to workspace and submit job\nreturned_job = ml_client.create_or_update(job)"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-migrate-from-v1?azure-portal=true",
                  "text": "deciding between v1 and v2"
                },
                {
                  "url": "/en-us/python/api/azure-ai-ml/azure.ai.ml.mlclient?azure-portal=true",
                  "text": "The reference documentation on theMLClientclass"
                },
                {
                  "url": "/en-us/python/api/azure-ai-ml/azure.ai.ml.entities?azure-portal=true",
                  "text": "The reference documentation also includes a list of the classes for all entities"
                },
                {
                  "url": "/en-us/python/api/azure-ai-ml/azure.ai.ml.entities.amlcompute?azure-portal=true",
                  "text": "a more detailed page on how to use the class and what parameters it accepts"
                }
              ]
            },
            {
              "number": 4,
              "title": "Explore the CLI",
              "url": "https://learn.microsoft.com/en-us/training/modules/explore-developer-tools-for-workspace-interaction/4-explore-cli",
              "href": "4-explore-cli",
              "content": "Read in English\nAdd\nAdd to plan\nExplore the CLI\nCompleted\n8 minutes\nImportant\nThe content in this unit only covers version 2 of the CLI\n. Learn more about\ndeciding between version 1 and 2\n.\nAnother code-based approach to interact with the Azure Machine Learning workspace is the command-line interface (CLI). As a data scientist, you may not work with the CLI as much as you do with Python. The Azure CLI is commonly used by administrators and engineers to automate tasks in Azure.\nThere are many advantages to using the Azure CLI with Azure Machine Learning. The Azure CLI allows you to:\nAutomate the creation and configuration of assets and resources to make it\nrepeatable\n.\nEnsure\nconsistency\nfor assets and resources that must be replicated in multiple environments (for example, development, test, and production).\nIncorporate machine learning asset configuration into developer operations (\nDevOps\n)\nworkflows\n, such as\ncontinuous integration\nand\ncontinuous deployment\n(\nCI/CD\n) pipelines.\nTo interact with the Azure Machine Learning workspace using the Azure CLI, you'll need to install the Azure CLI and the Azure Machine Learning extension.\nInstall the Azure CLI\nYou can install the Azure CLI on a Linux, Mac, or Windows computer. With the Azure CLI, you run commands or scripts to manage Azure resources. You can also use the Azure CLI from a browser through the Azure Cloud Shell. No matter which platform you choose, you can execute the same tasks. But, the installation of the Azure CLI, the commands, and scripts are different across platforms.\nImportant\nTo install the Azure CLI on your computer you can use a package manager. Here are the instructions to\ninstall the Azure CLI\n, based on the platform you choose. You don't need to install the Azure CLI if you use the Azure Cloud Shell. Learn more about how to use\nthe Azure Cloud Shell in this overview\n.\nInstall the Azure Machine Learning extension\nAfter you've installed the Azure CLI, or set up the Azure Cloud Shell, you need to install the Azure Machine Learning extension to manage Azure Machine Learning resources using the Azure CLI.\nYou can install the Azure Machine Learning extension\nml\nwith the following command:\naz extension add -n ml -y\nYou can then run the help command\n-h\nto check that the extension is installed and to get a list of commands available with this extension. The list gives an overview of the tasks you can execute with the Azure CLI extension for Azure Machine Learning:\naz ml -h\nWork with the Azure CLI\nTo use the Azure CLI to interact with the Azure Machine Learning workspace, you'll use\ncommands\n. Each command is prefixed with\naz ml\n. You can find the\nlist of commands in the reference documentation of the CLI\n.\nFor example, to create a compute target, you can use the following command:\naz ml compute create --name aml-cluster --size STANDARD_DS3_v2 --min-instances 0 --max-instances 5 --type AmlCompute --resource-group my-resource-group --workspace-name my-workspace\nTo explore all possible parameters that you can use with a command, you can\nreview the reference documentation for the specific command\n.\nAs you define the parameters for an asset or resource you want to create, you may prefer using YAML files to define the configuration instead. When you store all parameter values in a YAML file, it becomes easier to organize and automate tasks.\nFor example, you can also create the same compute target by first defining the configuration in a YAML file:\n$schema: https://azuremlschemas.azureedge.net/latest/amlCompute.schema.json \nname: aml-cluster\ntype: amlcompute\nsize: STANDARD_DS3_v2\nmin_instances: 0\nmax_instances: 5\nAll possible parameters that you can include in the YAML file can be found in\nthe reference documentation for the specific asset or resource you want to create like a compute cluster\n.\nWhen you saved the YAML file as\ncompute.yml\n, you can create the compute target with the following command:\naz ml compute create --file compute.yml --resource-group my-resource-group --workspace-name my-workspace\nYou can find\nan overview of all the YAML schemas in the reference documentation\n.\nTip\nLearn more about\nhow to use the CLI (v2) with Azure Machine Learning to train models\n.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Explore the CLI"
                },
                {
                  "level": 2,
                  "text": "Install the Azure CLI"
                },
                {
                  "level": 2,
                  "text": "Install the Azure Machine Learning extension"
                },
                {
                  "level": 2,
                  "text": "Work with the Azure CLI"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "az extension add -n ml -y",
                "az extension add -n ml -y",
                "az ml compute create --name aml-cluster --size STANDARD_DS3_v2 --min-instances 0 --max-instances 5 --type AmlCompute --resource-group my-resource-group --workspace-name my-workspace",
                "az ml compute create --name aml-cluster --size STANDARD_DS3_v2 --min-instances 0 --max-instances 5 --type AmlCompute --resource-group my-resource-group --workspace-name my-workspace",
                "$schema: https://azuremlschemas.azureedge.net/latest/amlCompute.schema.json \nname: aml-cluster\ntype: amlcompute\nsize: STANDARD_DS3_v2\nmin_instances: 0\nmax_instances: 5",
                "$schema: https://azuremlschemas.azureedge.net/latest/amlCompute.schema.json \nname: aml-cluster\ntype: amlcompute\nsize: STANDARD_DS3_v2\nmin_instances: 0\nmax_instances: 5",
                "compute.yml",
                "az ml compute create --file compute.yml --resource-group my-resource-group --workspace-name my-workspace",
                "az ml compute create --file compute.yml --resource-group my-resource-group --workspace-name my-workspace"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-migrate-from-v1?azure-portal=true",
                  "text": "deciding between version 1 and 2"
                },
                {
                  "url": "/en-us/cli/azure/install-azure-cli?azure-portal=true",
                  "text": "install the Azure CLI"
                },
                {
                  "url": "/en-us/azure/cloud-shell/overview?azure-portal=true",
                  "text": "the Azure Cloud Shell in this overview"
                },
                {
                  "url": "/en-us/cli/azure/ml?azure-portal=true",
                  "text": "list of commands in the reference documentation of the CLI"
                },
                {
                  "url": "/en-us/cli/azure/ml/compute?azure-portal=true",
                  "text": "review the reference documentation for the specific command"
                },
                {
                  "url": "/en-us/azure/machine-learning/reference-yaml-compute-aml?azure-portal=true",
                  "text": "the reference documentation for the specific asset or resource you want to create like a compute cluster"
                },
                {
                  "url": "/en-us/azure/machine-learning/reference-yaml-overview?azure-portal=true",
                  "text": "an overview of all the YAML schemas in the reference documentation"
                },
                {
                  "url": "/en-us/training/paths/train-models-azure-machine-learning-cli-v2/?azure-portal=true",
                  "text": "how to use the CLI (v2) with Azure Machine Learning to train models"
                }
              ]
            },
            {
              "number": 5,
              "title": "Exercise - Explore the developer tools",
              "url": "https://learn.microsoft.com/en-us/training/modules/explore-developer-tools-for-workspace-interaction/5-exercise",
              "href": "5-exercise",
              "content": "Read in English\nAdd\nAdd to plan\nExercise - Explore the developer tools\nCompleted\n30 minutes\nNow, it's your chance to explore with which developer tools you can interact with the Azure Machine Learning workspace.\nIn this exercise, you learn how to:\nCreate resources with the Azure CLI.\nExplore the Azure Machine Learning workspace with the studio.\nUse the Python SDK to train a model.\nInstructions\nLaunch the exercise and follow the instructions.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Exercise - Explore the developer tools"
                },
                {
                  "level": 2,
                  "text": "Instructions"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-azure/explore-developer-tools-for-workspace-interaction/media/launch-exercise.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/explore-developer-tools-for-workspace-interaction/media/launch-exercise.png",
                  "alt_text": "Button to launch exercise.",
                  "title": "",
                  "filename": "launch-exercise.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Instructions",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 6,
              "title": "Module assessment",
              "url": "https://learn.microsoft.com/en-us/training/modules/explore-developer-tools-for-workspace-interaction/6-knowledge-check",
              "href": "6-knowledge-check",
              "content": "Read in English\nAdd\nAdd to plan\nModule assessment\nCompleted\n3 minutes\n1.\nA data scientist wants to experiment by training a machine learning model and tracking it with Azure Machine Learning. Which tool should be used to train the model by running a script from their preferred environment?\nThe Azure Machine Learning studio.\nThe Python SDK.\nThe Azure CLI.\n2.\nA machine learning model to predict the sales forecast has been developed. Every week, new sales data is ingested and the model needs to be retrained on the newest data before generating the new forecast. Which tool should be used to retrain the model every week?\nThe Azure Machine Learning studio.\nThe Python SDK.\nThe Azure CLI.\nYou must answer all questions before checking your work.\nYou must answer all questions before checking your work.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Module assessment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 7,
              "title": "Summary",
              "url": "https://learn.microsoft.com/en-us/training/modules/explore-developer-tools-for-workspace-interaction/7-summary",
              "href": "7-summary",
              "content": "Read in English\nAdd\nAdd to plan\nSummary\nCompleted\n1 minute\nIn this module, you've learned how and when to use:\nThe Azure Machine Learning studio.\nThe Python Software Development Kit (SDK).\nThe Azure Command Line Interface (CLI).\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Summary"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            }
          ]
        },
        {
          "title": "Make data available in Azure Machine Learning",
          "url": "https://learn.microsoft.com/en-us/training/modules/make-data-available-azure-machine-learning/",
          "description": "",
          "learning_objectives": [],
          "prerequisites": [],
          "units": [
            {
              "number": 1,
              "title": "Introduction",
              "url": "https://learn.microsoft.com/en-us/training/modules/make-data-available-azure-machine-learning/1-introduction",
              "href": "1-introduction",
              "content": "Read in English\nAdd\nAdd to plan\nIntroduction\nCompleted\n1 minute\nData is a fundamental element in any machine learning workload. You need data to train a model and you create data when using a model to generate predictions.\nTo work with data in Azure Machine Learning, you can access data by using\nUniform Resource Identifiers\n(\nURIs\n). When you work with a data source or a specific file or folder repeatedly, you can create\ndatastores\nand\ndata assets\nwithin the Azure Machine Learning workspace. Datastores and data assets allow you to securely store the connection information to your data.\nIn this module, you learn how to create and use URIs, datastores, and data assets in Azure Machine Learning.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Introduction"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 2,
              "title": "Understand URIs",
              "url": "https://learn.microsoft.com/en-us/training/modules/make-data-available-azure-machine-learning/2-understand-uris",
              "href": "2-understand-uris",
              "content": "Read in English\nAdd\nAdd to plan\nUnderstand URIs\nCompleted\n5 minutes\nYou can store data on your local device, or somewhere in the cloud. Wherever you store your data, you want to access the data when training machine learning models. To find and access data in Azure Machine Learning, you can use\nUniform Resource Identifiers\n(\nURIs\n).\nUnderstand URIs\nA URI references the location of your data. For Azure Machine Learning to connect to your data, you need to prefix the URI with the appropriate protocol. There are three common protocols when working with data in the context of Azure Machine Learning:\nhttp(s)\n: Use for data stores publicly or privately in an Azure Blob Storage or publicly available http(s) location.\nabfs(s)\n: Use for data stores in an Azure Data Lake Storage Gen 2.\nazureml\n: Use for data stored in a datastore.\nFor example, you may create an Azure Blob Storage in Azure. To store data, you create a container named\ntraining-data\n. Within the container, you create a folder\ndatastore-path\n. Within the folder, you store the CSV file\ndiabetes.csv\n.\nWhen you want to access the data from the Azure Machine Learning workspace, you can use the path to the folder or file directly. When you want to connect to the folder or file directly, you can use the\nhttp(s)\nprotocol. If the container is set to private, you'll need to provide some kind of authentication to get access to the data, like a Shared Access Signature (SAS).\nWhen you create a datastore in Azure Machine Learning, you'll store the connection and authentication information in the workspace. Then, to access the data in the container, you can use the\nazureml\nprotocol.\nTip\nA datastore is a reference to an existing storage account on Azure. Therefore, when you refer to data stored in a datastore, you may be referring to data being stored in an Azure Blob Storage or Azure Data Lake Storage. When you refer to the datastore however, you won't need to authenticate as the connection information stored with the datastore will be used by Azure Machine Learning.\nIt's considered a best practice to avoid any sensitive data in your code, like authentication information. Therefore, whenever possible, you should work with datastores and data assets in Azure Machine Learning. However, during experimentation in notebooks, you may want to connect directly to a storage location to avoid unnecessary overhead.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Understand URIs"
                },
                {
                  "level": 2,
                  "text": "Understand URIs"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "training-data",
                "datastore-path",
                "diabetes.csv"
              ],
              "images": [
                {
                  "src": "../../wwl-azure/make-data-available-azure-machine-learning/media/data.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/make-data-available-azure-machine-learning/media/data.png",
                  "alt_text": "Diagram of different types of protocols that Azure Machine Learning uses to connect to external data sources.",
                  "title": "",
                  "filename": "data.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Understand URIs",
                    "following_text": "For example, you may create an Azure Blob Storage in Azure. To store data, you create a container namedtraining-data. Within the container, you create a folderdatastore-path. Within the folder, you st",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-azure/make-data-available-azure-machine-learning/media/blob-storage.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/make-data-available-azure-machine-learning/media/blob-storage.png",
                  "alt_text": "Screenshot of data stored in an Azure Blob Storage.",
                  "title": "",
                  "filename": "blob-storage.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Understand URIs",
                    "following_text": "When you want to access the data from the Azure Machine Learning workspace, you can use the path to the folder or file directly. When you want to connect to the folder or file directly, you can use th",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 3,
              "title": "Create a datastore",
              "url": "https://learn.microsoft.com/en-us/training/modules/make-data-available-azure-machine-learning/3-create-datastore",
              "href": "3-create-datastore",
              "content": "Read in English\nAdd\nAdd to plan\nCreate a datastore\nCompleted\n7 minutes\nIn Azure Machine Learning,\ndatastores\nare abstractions for cloud data sources. They encapsulate the information needed to connect to data sources, and securely store this connection information so that you dont have to code it in your scripts.\nThe benefits of using datastores are:\nProvides easy-to-use URIs to your data storage.\nFacilitates data discovery within Azure Machine Learning.\nSecurely stores connection information, without exposing secrets and keys to data scientists.\nWhen you create a datastore with an existing storage account on Azure, you have the choice between two different authentication methods:\nCredential-based\n: Use a\nservice principal\n,\nshared access signature\n(\nSAS\n) token or\naccount key\nto authenticate access to your storage account.\nIdentity-based\n: Use your\nMicrosoft Entra identity\nor\nmanaged identity\n.\nUnderstand types of datastores\nAzure Machine Learning supports the creation of datastores for multiple kinds of Azure data source, including:\nAzure Blob Storage\nAzure File Share\nAzure Data Lake (Gen 2)\nUse the built-in datastores\nEvery workspace has four built-in datastores (two connecting to Azure Storage blob containers, and two connecting to Azure Storage file shares), which are used as system storages by Azure Machine Learning.\nIn most machine learning projects, you need to work with data sources of your own. For example, you can integrate your machine learning solution with data from existing applications or data engineering pipelines.\nCreate a datastore\nDatastores are attached to workspaces and are used to store connection information to storage services. When you create a datastore, you provide a name that can be used to retrieve the connection information.\nDatastores allow you to easily connect to storage services without having to provide all necessary details every time you want to read or write data. It also creates a protective layer if you want users to use the data, but not connect to the underlying storage service directly.\nCreate a datastore for an Azure Blob Storage container\nYou can create a datastore through the graphical user interface, the Azure command-line interface (CLI), or the Python software development kit (SDK).\nDepending on the storage service you want to connect to, there are different options for Azure Machine Learning to authenticate.\nFor example, when you want to create a datastore to connect to an Azure Blob Storage container, you can use an account key:\nblob_datastore = AzureBlobDatastore(\n    \t\t\tname = \"blob_example\",\n    \t\t\tdescription = \"Datastore pointing to a blob container\",\n    \t\t\taccount_name = \"mytestblobstore\",\n    \t\t\tcontainer_name = \"data-container\",\n    \t\t\tcredentials = AccountKeyConfiguration(\n        \t\t\taccount_key=\"XXXxxxXXXxXXXXxxXXX\"\n    \t\t\t),\n)\nml_client.create_or_update(blob_datastore)\nAlternatively, you can create a datastore to connect to an Azure Blob Storage container by using a SAS token to authenticate:\nblob_datastore = AzureBlobDatastore(\nname=\"blob_sas_example\",\ndescription=\"Datastore pointing to a blob container\",\naccount_name=\"mytestblobstore\",\ncontainer_name=\"data-container\",\ncredentials=SasTokenConfiguration(\nsas_token=\"?xx=XXXX-XX-XX&xx=xxxx&xxx=xxx&xx=xxxxxxxxxxx&xx=XXXX-XX-XXXXX:XX:XXX&xx=XXXX-XX-XXXXX:XX:XXX&xxx=xxxxx&xxx=XXxXXXxxxxxXXXXXXXxXxxxXXXXXxxXXXXXxXXXXxXXXxXXxXX\"\n),\n)\nml_client.create_or_update(blob_datastore)\nTip\nLearn more about\nhow to create datastores to connect to other types of cloud storage solutions\n.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Create a datastore"
                },
                {
                  "level": 2,
                  "text": "Understand types of datastores"
                },
                {
                  "level": 2,
                  "text": "Use the built-in datastores"
                },
                {
                  "level": 2,
                  "text": "Create a datastore"
                },
                {
                  "level": 3,
                  "text": "Create a datastore for an Azure Blob Storage container"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "blob_datastore = AzureBlobDatastore(\n    \t\t\tname = \"blob_example\",\n    \t\t\tdescription = \"Datastore pointing to a blob container\",\n    \t\t\taccount_name = \"mytestblobstore\",\n    \t\t\tcontainer_name = \"data-container\",\n    \t\t\tcredentials = AccountKeyConfiguration(\n        \t\t\taccount_key=\"XXXxxxXXXxXXXXxxXXX\"\n    \t\t\t),\n)\nml_client.create_or_update(blob_datastore)",
                "blob_datastore = AzureBlobDatastore(\n    \t\t\tname = \"blob_example\",\n    \t\t\tdescription = \"Datastore pointing to a blob container\",\n    \t\t\taccount_name = \"mytestblobstore\",\n    \t\t\tcontainer_name = \"data-container\",\n    \t\t\tcredentials = AccountKeyConfiguration(\n        \t\t\taccount_key=\"XXXxxxXXXxXXXXxxXXX\"\n    \t\t\t),\n)\nml_client.create_or_update(blob_datastore)",
                "blob_datastore = AzureBlobDatastore(\nname=\"blob_sas_example\",\ndescription=\"Datastore pointing to a blob container\",\naccount_name=\"mytestblobstore\",\ncontainer_name=\"data-container\",\ncredentials=SasTokenConfiguration(\nsas_token=\"?xx=XXXX-XX-XX&xx=xxxx&xxx=xxx&xx=xxxxxxxxxxx&xx=XXXX-XX-XXXXX:XX:XXX&xx=XXXX-XX-XXXXX:XX:XXX&xxx=xxxxx&xxx=XXxXXXxxxxxXXXXXXXxXxxxXXXXXxxXXXXXxXXXXxXXXxXXxXX\"\n),\n)\nml_client.create_or_update(blob_datastore)",
                "blob_datastore = AzureBlobDatastore(\nname=\"blob_sas_example\",\ndescription=\"Datastore pointing to a blob container\",\naccount_name=\"mytestblobstore\",\ncontainer_name=\"data-container\",\ncredentials=SasTokenConfiguration(\nsas_token=\"?xx=XXXX-XX-XX&xx=xxxx&xxx=xxx&xx=xxxxxxxxxxx&xx=XXXX-XX-XXXXX:XX:XXX&xx=XXXX-XX-XXXXX:XX:XXX&xxx=xxxxx&xxx=XXxXXXxxxxxXXXXXXXxXxxxXXXXXxxXXXXXxXXXXxXXXxXXxXX\"\n),\n)\nml_client.create_or_update(blob_datastore)"
              ],
              "images": [
                {
                  "src": "../../wwl-azure/make-data-available-azure-machine-learning/media/datastores.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/make-data-available-azure-machine-learning/media/datastores.png",
                  "alt_text": "Diagram of two different authentication methods Azure Machine Learning datastores use to connect to external data sources.",
                  "title": "",
                  "filename": "datastores.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Create a datastore",
                    "following_text": "Azure Machine Learning supports the creation of datastores for multiple kinds of Azure data source, including:",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-datastore?azure-portal=true",
                  "text": "how to create datastores to connect to other types of cloud storage solutions"
                }
              ]
            },
            {
              "number": 4,
              "title": "Create a data asset",
              "url": "https://learn.microsoft.com/en-us/training/modules/make-data-available-azure-machine-learning/4-create-data-asset",
              "href": "4-create-data-asset",
              "content": "Read in English\nAdd\nAdd to plan\nCreate a data asset\nCompleted\n12 minutes\nAs a data scientist, you want to focus on training machine learning models. Though you need access to data as input for a machine learning model, you don't want to worry about\nhow\nto get access. To simplify getting access to the data you want to work with, you can use\ndata assets\n.\nUnderstand data assets\nIn Azure Machine Learning, data assets are references to where the data is stored, how to get access, and any other relevant metadata. You can create data assets to get access to data in datastores, Azure storage services, public URLs, or data stored on your local device.\nThe benefits of using data assets are:\nYou can\nshare and reuse data\nwith other members of the team such that they don't need to remember file locations.\nYou can\nseamlessly access data\nduring model training (on any supported compute type) without worrying about connection strings or data paths.\nYou can\nversion\nthe metadata of the data asset.\nThere are three main types of data assets you can use:\nURI file\n: Points to a specific file.\nURI folder\n: Points to a folder.\nMLTable\n: Points to a folder or file, and includes a schema to read as tabular data.\nNote\nURI\nstands for\nUniform Resource Identifier\nand stands for a storage location on your local computer, Azure Blob or Data Lake Storage, publicly available https location, or even an attached datastore.\nWhen to use data assets\nData assets are most useful when executing machine learning tasks as Azure Machine Learning jobs. As a job, you can run a Python script that takes inputs and generates outputs. A data asset can be parsed as both an input or output of an Azure Machine Learning job.\nLets take a look at each of the types of data assets, how to create them, and how to use the data asset in a job.\nCreate a URI file data asset\nA URI file data asset points to a specific file. Azure Machine Learning only stores the path to the file, which means you can point to any type of file. When you use the data asset, you specify how you want to read the data, which depends on the type of data you're connecting to.\nThe supported paths you can use when creating a URI file data asset are:\nLocal:\n./<path>\nAzure Blob Storage:\nwasbs://<account_name>.blob.core.windows.net/<container_name>/<folder>/<file>\nAzure Data Lake Storage (Gen 2):\nabfss://<file_system>@<account_name>.dfs.core.windows.net/<folder>/<file>\nDatastore:\nazureml://datastores/<datastore_name>/paths/<folder>/<file>\nImportant\nWhen you create a data asset and point to a file or folder stored on your local device, a copy of the file or folder will be uploaded to the default datastore\nworkspaceblobstore\n. You can find the file or folder in the\nLocalUpload\nfolder. By uploading a copy, you'll still be able to access the data from the Azure Machine Learning workspace, even when the local device on which the data is stored is unavailable.\nTo create a URI file data asset, you can use the following code:\nfrom azure.ai.ml.entities import Data\nfrom azure.ai.ml.constants import AssetTypes\n\nmy_path = '<supported-path>'\n\nmy_data = Data(\n    path=my_path,\n    type=AssetTypes.URI_FILE,\n    description=\"<description>\",\n    name=\"<name>\",\n    version=\"<version>\"\n)\n\nml_client.data.create_or_update(my_data)\nWhen you parse the URI file data asset as input in an Azure Machine Learning job, you first need to read the data before you can work with it.\nImagine you create a Python script you want to run as a job, and you set the value of the input parameter\ninput_data\nto be the URI file data asset (which points to a CSV file). You can read the data by including the following code in your Python script:\nimport argparse\nimport pandas as pd\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--input_data\", type=str)\nargs = parser.parse_args()\n\ndf = pd.read_csv(args.input_data)\nprint(df.head(10))\nIf your URI file data asset points to a different type of file, you need to use the appropriate Python code to read the data. For example, if instead of CSV files, you're working with JSON files, you'd use\npd.read_json()\ninstead.\nCreate a URI folder data asset\nA URI folder data asset points to a specific folder. It works similar to a URI file data asset and supports the same paths.\nTo create a URI folder data asset with the Python SDK, you can use the following code:\nfrom azure.ai.ml.entities import Data\nfrom azure.ai.ml.constants import AssetTypes\n\nmy_path = '<supported-path>'\n\nmy_data = Data(\n    path=my_path,\n    type=AssetTypes.URI_FOLDER,\n    description=\"<description>\",\n    name=\"<name>\",\n    version='<version>'\n)\n\nml_client.data.create_or_update(my_data)\nWhen you parse the URI folder data asset as input in an Azure Machine Learning job, you first need to read the data before you can work with it.\nImagine you create a Python script you want to run as a job, and you set the value of the input parameter\ninput_data\nto be the URI folder data asset (which points to multiple CSV files). You can read all CSV files in the folder and concatenate them, which you can do by including the following code in your Python script:\nimport argparse\nimport glob\nimport pandas as pd\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--input_data\", type=str)\nargs = parser.parse_args()\n\ndata_path = args.input_data\nall_files = glob.glob(data_path + \"/*.csv\")\ndf = pd.concat((pd.read_csv(f) for f in all_files), sort=False)\nDepending on the type of data you're working with, the code you use to read the files can change.\nCreate a MLTable data asset\nA MLTable data asset allows you to point to tabular data. When you create a MLTable data asset, you specify the schema definition to read the data. As the schema is already defined and stored with the data asset, you don't have to specify how to read the data when you use it.\nTherefore, you want to use a MLTable data asset when the schema of your data is complex or changes frequently. Instead of changing how to read the data in every script that uses the data, you only have to change it in the data asset itself.\nWhen you define the schema when creating a MLTable data asset, you can also choose to only specify a subset of the data.\nFor certain features in Azure Machine Learning, like Automated Machine Learning, you need to use a MLTable data asset, as Azure Machine Learning needs to know how to read the data.\nTo define the schema, you can include a\nMLTable file\nin the same folder as the data you want to read. The MLTable file includes the path pointing to the data you want to read, and how to read the data:\ntype: mltable\n\npaths:\n  - pattern: ./*.txt\ntransformations:\n  - read_delimited:\n      delimiter: ','\n      encoding: ascii\n      header: all_files_same_headers\nTip\nLearn more on\nhow to create the MLTable file and which transformations you can include\n.\nTo create a MLTable data asset with the Python SDK, you can use the following code:\nfrom azure.ai.ml.entities import Data\nfrom azure.ai.ml.constants import AssetTypes\n\nmy_path = '<path-including-mltable-file>'\n\nmy_data = Data(\n    path=my_path,\n    type=AssetTypes.MLTABLE,\n    description=\"<description>\",\n    name=\"<name>\",\n    version='<version>'\n)\n\nml_client.data.create_or_update(my_data)\nWhen you parse a MLTable data asset as input to a Python script you want to run as an Azure Machine Learning job, you can include the following code to read the data:\nimport argparse\nimport mltable\nimport pandas\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--input_data\", type=str)\nargs = parser.parse_args()\n\ntbl = mltable.load(args.input_data)\ndf = tbl.to_pandas_dataframe()\n\nprint(df.head(10))\nA common approach is to convert the tabular data to a Pandas data frame. However, you can also convert the data to a Spark data frame if that suits your workload better.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Create a data asset"
                },
                {
                  "level": 2,
                  "text": "Understand data assets"
                },
                {
                  "level": 2,
                  "text": "When to use data assets"
                },
                {
                  "level": 2,
                  "text": "Create a URI file data asset"
                },
                {
                  "level": 2,
                  "text": "Create a URI folder data asset"
                },
                {
                  "level": 2,
                  "text": "Create a MLTable data asset"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "wasbs://<account_name>.blob.core.windows.net/<container_name>/<folder>/<file>",
                "abfss://<file_system>@<account_name>.dfs.core.windows.net/<folder>/<file>",
                "azureml://datastores/<datastore_name>/paths/<folder>/<file>",
                "workspaceblobstore",
                "LocalUpload",
                "from azure.ai.ml.entities import Data\nfrom azure.ai.ml.constants import AssetTypes\n\nmy_path = '<supported-path>'\n\nmy_data = Data(\n    path=my_path,\n    type=AssetTypes.URI_FILE,\n    description=\"<description>\",\n    name=\"<name>\",\n    version=\"<version>\"\n)\n\nml_client.data.create_or_update(my_data)",
                "from azure.ai.ml.entities import Data\nfrom azure.ai.ml.constants import AssetTypes\n\nmy_path = '<supported-path>'\n\nmy_data = Data(\n    path=my_path,\n    type=AssetTypes.URI_FILE,\n    description=\"<description>\",\n    name=\"<name>\",\n    version=\"<version>\"\n)\n\nml_client.data.create_or_update(my_data)",
                "import argparse\nimport pandas as pd\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--input_data\", type=str)\nargs = parser.parse_args()\n\ndf = pd.read_csv(args.input_data)\nprint(df.head(10))",
                "import argparse\nimport pandas as pd\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--input_data\", type=str)\nargs = parser.parse_args()\n\ndf = pd.read_csv(args.input_data)\nprint(df.head(10))",
                "pd.read_json()",
                "from azure.ai.ml.entities import Data\nfrom azure.ai.ml.constants import AssetTypes\n\nmy_path = '<supported-path>'\n\nmy_data = Data(\n    path=my_path,\n    type=AssetTypes.URI_FOLDER,\n    description=\"<description>\",\n    name=\"<name>\",\n    version='<version>'\n)\n\nml_client.data.create_or_update(my_data)",
                "from azure.ai.ml.entities import Data\nfrom azure.ai.ml.constants import AssetTypes\n\nmy_path = '<supported-path>'\n\nmy_data = Data(\n    path=my_path,\n    type=AssetTypes.URI_FOLDER,\n    description=\"<description>\",\n    name=\"<name>\",\n    version='<version>'\n)\n\nml_client.data.create_or_update(my_data)",
                "import argparse\nimport glob\nimport pandas as pd\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--input_data\", type=str)\nargs = parser.parse_args()\n\ndata_path = args.input_data\nall_files = glob.glob(data_path + \"/*.csv\")\ndf = pd.concat((pd.read_csv(f) for f in all_files), sort=False)",
                "import argparse\nimport glob\nimport pandas as pd\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--input_data\", type=str)\nargs = parser.parse_args()\n\ndata_path = args.input_data\nall_files = glob.glob(data_path + \"/*.csv\")\ndf = pd.concat((pd.read_csv(f) for f in all_files), sort=False)",
                "type: mltable\n\npaths:\n  - pattern: ./*.txt\ntransformations:\n  - read_delimited:\n      delimiter: ','\n      encoding: ascii\n      header: all_files_same_headers",
                "type: mltable\n\npaths:\n  - pattern: ./*.txt\ntransformations:\n  - read_delimited:\n      delimiter: ','\n      encoding: ascii\n      header: all_files_same_headers",
                "from azure.ai.ml.entities import Data\nfrom azure.ai.ml.constants import AssetTypes\n\nmy_path = '<path-including-mltable-file>'\n\nmy_data = Data(\n    path=my_path,\n    type=AssetTypes.MLTABLE,\n    description=\"<description>\",\n    name=\"<name>\",\n    version='<version>'\n)\n\nml_client.data.create_or_update(my_data)",
                "from azure.ai.ml.entities import Data\nfrom azure.ai.ml.constants import AssetTypes\n\nmy_path = '<path-including-mltable-file>'\n\nmy_data = Data(\n    path=my_path,\n    type=AssetTypes.MLTABLE,\n    description=\"<description>\",\n    name=\"<name>\",\n    version='<version>'\n)\n\nml_client.data.create_or_update(my_data)",
                "import argparse\nimport mltable\nimport pandas\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--input_data\", type=str)\nargs = parser.parse_args()\n\ntbl = mltable.load(args.input_data)\ndf = tbl.to_pandas_dataframe()\n\nprint(df.head(10))",
                "import argparse\nimport mltable\nimport pandas\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--input_data\", type=str)\nargs = parser.parse_args()\n\ntbl = mltable.load(args.input_data)\ndf = tbl.to_pandas_dataframe()\n\nprint(df.head(10))"
              ],
              "images": [
                {
                  "src": "../../wwl-azure/make-data-available-azure-machine-learning/media/datasets.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/make-data-available-azure-machine-learning/media/datasets.png",
                  "alt_text": "Diagram of different types of data assets in Azure Machine Learning.",
                  "title": "",
                  "filename": "datasets.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Understand data assets",
                    "following_text": "",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/reference-yaml-mltable?azure-portal=true",
                  "text": "how to create the MLTable file and which transformations you can include"
                }
              ]
            },
            {
              "number": 5,
              "title": "Exercise - Make data available in Azure Machine Learning",
              "url": "https://learn.microsoft.com/en-us/training/modules/make-data-available-azure-machine-learning/5-exercise",
              "href": "5-exercise",
              "content": "Read in English\nAdd\nAdd to plan\nExercise - Make data available in Azure Machine Learning\nCompleted\n10 minutes\nNow, it's your chance to explore how to work with data.\nIn this exercise, you learn how to:\nExplore the default datastores.\nCreate a datastore.\nCreate data assets.\nInstructions\nLaunch the exercise and follow the instructions.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Exercise - Make data available in Azure Machine Learning"
                },
                {
                  "level": 2,
                  "text": "Instructions"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-azure/make-data-available-azure-machine-learning/media/launch-exercise.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/make-data-available-azure-machine-learning/media/launch-exercise.png",
                  "alt_text": "Button to launch exercise.",
                  "title": "",
                  "filename": "launch-exercise.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Instructions",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 6,
              "title": "Module assessment",
              "url": "https://learn.microsoft.com/en-us/training/modules/make-data-available-azure-machine-learning/6-knowledge-check",
              "href": "6-knowledge-check",
              "content": "Read in English\nAdd\nAdd to plan\nModule assessment\nCompleted\n3 minutes\n1.\nA data scientist wants to read data stored in a publicly available GitHub repository. The data will be read in a Jupyter notebook in the Azure Machine Learning workspace for some quick experimentation. Which protocol should be used to read the data in the notebook?\nazureml\nhttp(s)\nabfs(s)\n2.\nWhat type of data asset should someone create when the schema changes frequently and the data is used in many different jobs?\nURI file\nURI folder\nMLTable\nYou must answer all questions before checking your work.\nYou must answer all questions before checking your work.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Module assessment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 7,
              "title": "Summary",
              "url": "https://learn.microsoft.com/en-us/training/modules/make-data-available-azure-machine-learning/7-summary",
              "href": "7-summary",
              "content": "Read in English\nAdd\nAdd to plan\nSummary\nCompleted\n1 minute\nIn this module, you've learned how to:\nAccess data by using URIs.\nConnect to cloud data sources with datastores.\nUse data asset to access specific files or folders.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Summary"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            }
          ]
        },
        {
          "title": "Work with compute targets in Azure Machine Learning",
          "url": "https://learn.microsoft.com/en-us/training/modules/work-compute-resources-azure-machine-learning/",
          "description": "",
          "learning_objectives": [],
          "prerequisites": [],
          "units": [
            {
              "number": 1,
              "title": "Introduction",
              "url": "https://learn.microsoft.com/en-us/training/modules/work-compute-resources-azure-machine-learning/1-introduction",
              "href": "1-introduction",
              "content": "Read in English\nAdd\nAdd to plan\nIntroduction\nCompleted\n2 minutes\nAs a data scientist, you can train machine learning models on your local device. For large-scale projects, a single local device can limit you to efficiently train machine learning models. When you use cloud compute for machine learning workloads, you're ready to scale your work when needed.\nIn Azure Machine Learning, you can use various types of managed cloud computes. By using any of the compute options in the Azure Machine Learning workspace, you can save time on managing compute.\nWhether you're working in notebooks during experimentation, or need to run scripts for production, Azure Machine Learning compute helps you run your workloads at scale.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Introduction"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 2,
              "title": "Choose the appropriate compute target",
              "url": "https://learn.microsoft.com/en-us/training/modules/work-compute-resources-azure-machine-learning/2-compute-targets",
              "href": "2-compute-targets",
              "content": "Read in English\nAdd\nAdd to plan\nChoose the appropriate compute target\nCompleted\n7 minutes\nIn Azure Machine Learning,\ncompute targets\nare physical or virtual computers on which jobs are run.\nUnderstand the available types of compute\nAzure Machine Learning supports multiple types of compute for experimentation, training, and deployment. By having multiple types of compute, you can select the most appropriate type of compute target for your needs.\nCompute instance\n: Behaves similarly to a virtual machine and is primarily used to run notebooks. It's ideal for\nexperimentation\n.\nCompute clusters\n: Multi-node clusters of virtual machines that automatically scale up or down to meet demand. A cost-effective way to run scripts that need to process large volumes of data. Clusters also allow you to use parallel processing to distribute the workload and reduce the time it takes to run a script.\nKubernetes clusters\n: Cluster based on Kubernetes technology, giving you more control over how the compute is configured and managed. You can attach your self-managed Azure Kubernetes (AKS) cluster for cloud compute, or an Arc Kubernetes cluster for on-premises workloads.\nAttached compute\n: Allows you to attach existing compute like Azure virtual machines or Azure Databricks clusters to your workspace.\nServerless compute\n: A fully managed, on-demand compute you can use for training jobs.\nNote\nAzure Machine Learning offers you the option to create and manage your own compute or to use compute that is fully managed by Azure Machine Learning.\nWhen to use which type of compute?\nIn general, there are some best practices that you can follow when working with compute targets. To understand how to choose the appropriate type of compute, several examples are provided. Remember that which type of compute you use always depends on your specific situation.\nChoose a compute target for experimentation\nImagine you're a data scientist and you're asked to develop a new machine learning model. You likely have a small subset of the training data with which you can experiment.\nDuring experimentation and development, you prefer working in a Jupyter notebook. A notebook experience benefits most from a compute that is continuously running.\nMany data scientists are familiar with running notebooks on their local device. A cloud alternative managed by Azure Machine Learning is a\ncompute instance\n. Alternatively, you can also opt for\nSpark serverless compute\nto run Spark code in notebooks, if you want to make use of Spark's distributed compute power.\nChoose a compute target for production\nAfter experimentation, you can train your models by running Python scripts to prepare for production. Scripts will be easier to automate and schedule for when you want to retrain your model continuously over time. You can run scripts as (pipeline) jobs.\nWhen moving to production, you want the compute target to be ready to handle large volumes of data. The more data you use, the better the machine learning model is likely to be.\nWhen training models with scripts, you want an on-demand compute target. A\ncompute cluster\nautomatically scales up when the script(s) need to be executed, and scales down when the script finishes executing. If you want an alternative that you don't have to create and manage, you can use Azure Machine Learning's\nserverless compute\n.\nChoose a compute target for deployment\nThe type of compute you need when using your model to generate predictions depends on whether you want batch or real-time predictions.\nFor batch predictions, you can run a pipeline job in Azure Machine Learning. Compute targets like compute clusters and Azure Machine Learning's serverless compute are ideal for pipeline jobs as they're on-demand and scalable.\nWhen you want real-time predictions, you need a type of compute that is running continuously. Real-time deployments therefore benefit from more lightweight (and thus more cost-efficient) compute. Containers are ideal for real-time deployments. When you deploy your model to a managed online endpoint, Azure Machine Learning creates and manages containers for you to run your model. Alternatively, you can attach Kubernetes clusters to manage the necessary compute to generate real-time predictions.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Choose the appropriate compute target"
                },
                {
                  "level": 2,
                  "text": "Understand the available types of compute"
                },
                {
                  "level": 2,
                  "text": "When to use which type of compute?"
                },
                {
                  "level": 3,
                  "text": "Choose a compute target for experimentation"
                },
                {
                  "level": 3,
                  "text": "Choose a compute target for production"
                },
                {
                  "level": 3,
                  "text": "Choose a compute target for deployment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-azure/work-compute-resources-azure-machine-learning/media/compute-targets.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/work-compute-resources-azure-machine-learning/media/compute-targets.png",
                  "alt_text": "Diagram of different hyperparameter values resulting in different models by performing hyperparameter tuning.",
                  "title": "",
                  "filename": "compute-targets.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Understand the available types of compute",
                    "following_text": "",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 3,
              "title": "Create and use a compute instance",
              "url": "https://learn.microsoft.com/en-us/training/modules/work-compute-resources-azure-machine-learning/3-create-use-compute-instance",
              "href": "3-create-use-compute-instance",
              "content": "Read in English\nAdd\nAdd to plan\nCreate and use a compute instance\nCompleted\n6 minutes\nWhen you want to execute code in notebooks, you can choose to use a\ncompute instance\nmanaged by Azure Machine Learning. You can create a compute instance in the Azure Machine Learning studio, using the Azure command-line interface (CLI), or the Python software development kit (SDK).\nCreate a compute instance with the Python SDK\nTo create a compute instance with the Python SDK, you can use the following code:\nfrom azure.ai.ml.entities import ComputeInstance\n\nci_basic_name = \"basic-ci-12345\"\nci_basic = ComputeInstance(\n    name=ci_basic_name, \n    size=\"STANDARD_DS3_v2\"\n)\nml_client.begin_create_or_update(ci_basic).result()\nTo understand which parameters the\nComputeInstance\nclass expects, you can review the\nreference documentation\n.\nNote\nCompute instances need to have a unique name across an Azure region (for example within west europe). If the name already exists, an error message will tell you to try again with another name.\nAlternatively, you can also create a compute instance by using a script. With a script, you ensure that any necessary packages, tools, or software is automatically installed on the compute and you can clone any repositories to the compute instance. When you need to create compute instances for multiple users, using a script allows you to create a consistent development environment for everyone.\nTip\nLearn more about\nhow to customize the compute instance with a script\n.\nAssign a compute instance to a user\nAs a data scientist, you can attach a compute instance to notebooks to run cells within the notebook. To be allowed to work with the compute instance, it needs to be assigned to you as a user.\nA compute instance can only be assigned to\none\nuser, as the compute instance can't handle parallel workloads. When you create a new compute instance, you can assign it to someone else if you have the appropriate permissions.\nMinimize compute time\nWhen you're actively working on code in a notebook, you want your compute instance to be running. When you're not executing any code, you want your compute instance to be stopped to save on costs.\nWhen a compute instance is assigned to you, you can start and stop a compute instance whenever you need. You can also add a schedule to the compute instance to start or stop at set times. Additionally, you can configure a compute to automatically shut down when it has been idle for a set amount of time.\nBy scheduling your compute instance to stop at the end of every day, you avoid unnecessary costs if you forget to stop a compute instance.\nUse a compute instance\nTo use a compute instance, you need an application that can host notebooks. The easiest option to work with the compute instance is through the integrated notebooks experience in the Azure Machine Learning studio.\nYou can prefer to work with Visual Studio Code for easier source control of your code. If you want to edit and run code in Visual Studio Code, you can attach a compute instance to run notebook cells remotely.\nTip\nLearn more about\nhow to create and manage an Azure Machine Learning compute instance\n.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Create and use a compute instance"
                },
                {
                  "level": 2,
                  "text": "Create a compute instance with the Python SDK"
                },
                {
                  "level": 3,
                  "text": "Assign a compute instance to a user"
                },
                {
                  "level": 3,
                  "text": "Minimize compute time"
                },
                {
                  "level": 2,
                  "text": "Use a compute instance"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "from azure.ai.ml.entities import ComputeInstance\n\nci_basic_name = \"basic-ci-12345\"\nci_basic = ComputeInstance(\n    name=ci_basic_name, \n    size=\"STANDARD_DS3_v2\"\n)\nml_client.begin_create_or_update(ci_basic).result()",
                "from azure.ai.ml.entities import ComputeInstance\n\nci_basic_name = \"basic-ci-12345\"\nci_basic = ComputeInstance(\n    name=ci_basic_name, \n    size=\"STANDARD_DS3_v2\"\n)\nml_client.begin_create_or_update(ci_basic).result()",
                "ComputeInstance"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/python/api/azure-ai-ml/azure.ai.ml.entities.computeinstance?azure-portal=true",
                  "text": "reference documentation"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-customize-compute-instance?azure-portal=true",
                  "text": "how to customize the compute instance with a script"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-create-manage-compute-instance?azure-portal=true",
                  "text": "how to create and manage an Azure Machine Learning compute instance"
                }
              ]
            },
            {
              "number": 4,
              "title": "Create and use a compute cluster",
              "url": "https://learn.microsoft.com/en-us/training/modules/work-compute-resources-azure-machine-learning/4-create-use-compute-cluster",
              "href": "4-create-use-compute-cluster",
              "content": "Read in English\nAdd\nAdd to plan\nCreate and use a compute cluster\nCompleted\n8 minutes\nAfter experimentation and development, you want your code to be production-ready. When you run code in production environments, it's better to use scripts instead of notebooks. When you run a script, you want to use a compute target that is scalable.\nWithin Azure Machine Learning,\ncompute clusters\nare ideal for running scripts. You can create a compute cluster in the Azure Machine Learning studio, using the Azure command-line interface (CLI), or the Python software development kit (SDK).\nCreate a compute cluster with the Python SDK\nTo create a compute cluster with the Python SDK, you can use the following code:\nfrom azure.ai.ml.entities import AmlCompute\n\ncluster_basic = AmlCompute(\n    name=\"cpu-cluster\",\n    type=\"amlcompute\",\n    size=\"STANDARD_DS3_v2\",\n    location=\"westus\",\n    min_instances=0,\n    max_instances=2,\n    idle_time_before_scale_down=120,\n    tier=\"low_priority\",\n)\nml_client.begin_create_or_update(cluster_basic).result()\nTo understand which parameters the\nAmlCompute\nclass expects, you can review the\nreference documentation\n.\nWhen you create a compute cluster, there are three main parameters you need to consider:\nsize\n: Specifies the\nvirtual machine type\nof each node within the compute cluster. Based on the\nsizes for virtual machines in Azure\n. Next to size, you can also specify whether you want to use CPUs or GPUs.\nmax_instances\n: Specifies the\nmaximum number of nodes\nyour compute cluster can scale out to. The number of parallel workloads your compute cluster can handle is analogous to the number of nodes your cluster can scale to.\ntier\n: Specifies whether your virtual machines are\nlow priority\nor\ndedicated\n. Setting to low priority can lower costs as you're not guaranteed availability.\nUse a compute cluster\nThere are three main scenarios in which you can use a compute cluster:\nRunning a pipeline job you built in the Designer.\nRunning an Automated Machine Learning job.\nRunning a script as a job.\nIn each of these scenarios, a compute cluster is ideal as a compute cluster automatically scales up when a job is submitted, and automatically shut down when a job is completed.\nA compute cluster also allows you to train multiple models in parallel, which is a common practice when using Automated Machine Learning.\nYou can run a Designer pipeline job and an Automated Machine Learning job through the Azure Machine Learning studio. When you submit the job through the studio, you can set the compute target to the compute cluster you created.\nWhen you prefer a code-first approach, you can set the compute target to your compute cluster by using the Python SDK.\nFor example, when you run a script as a command job, you can set the compute target to your compute cluster with the following code:\nfrom azure.ai.ml import command\n\n# configure job\njob = command(\n    code=\"./src\",\n    command=\"python diabetes-training.py\",\n    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n    compute=\"cpu-cluster\",\n    display_name=\"train-with-cluster\",\n    experiment_name=\"diabetes-training\"\n    )\n\n# submit job\nreturned_job = ml_client.create_or_update(job)\naml_url = returned_job.studio_url\nprint(\"Monitor your job at\", aml_url)\nAfter submitting a job that uses a compute cluster, the compute cluster scales out to one or more nodes. Resizing takes a few minutes, and your job starts running once the necessary nodes are provisioned. When a job's status is\npreparing\n, the compute cluster is being prepared. When the status is\nrunning\n, the compute cluster is ready, and the job is running.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Create and use a compute cluster"
                },
                {
                  "level": 2,
                  "text": "Create a compute cluster with the Python SDK"
                },
                {
                  "level": 2,
                  "text": "Use a compute cluster"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "from azure.ai.ml.entities import AmlCompute\n\ncluster_basic = AmlCompute(\n    name=\"cpu-cluster\",\n    type=\"amlcompute\",\n    size=\"STANDARD_DS3_v2\",\n    location=\"westus\",\n    min_instances=0,\n    max_instances=2,\n    idle_time_before_scale_down=120,\n    tier=\"low_priority\",\n)\nml_client.begin_create_or_update(cluster_basic).result()",
                "from azure.ai.ml.entities import AmlCompute\n\ncluster_basic = AmlCompute(\n    name=\"cpu-cluster\",\n    type=\"amlcompute\",\n    size=\"STANDARD_DS3_v2\",\n    location=\"westus\",\n    min_instances=0,\n    max_instances=2,\n    idle_time_before_scale_down=120,\n    tier=\"low_priority\",\n)\nml_client.begin_create_or_update(cluster_basic).result()",
                "max_instances",
                "from azure.ai.ml import command\n\n# configure job\njob = command(\n    code=\"./src\",\n    command=\"python diabetes-training.py\",\n    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n    compute=\"cpu-cluster\",\n    display_name=\"train-with-cluster\",\n    experiment_name=\"diabetes-training\"\n    )\n\n# submit job\nreturned_job = ml_client.create_or_update(job)\naml_url = returned_job.studio_url\nprint(\"Monitor your job at\", aml_url)",
                "from azure.ai.ml import command\n\n# configure job\njob = command(\n    code=\"./src\",\n    command=\"python diabetes-training.py\",\n    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n    compute=\"cpu-cluster\",\n    display_name=\"train-with-cluster\",\n    experiment_name=\"diabetes-training\"\n    )\n\n# submit job\nreturned_job = ml_client.create_or_update(job)\naml_url = returned_job.studio_url\nprint(\"Monitor your job at\", aml_url)"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/python/api/azure-ai-ml/azure.ai.ml.entities.amlcompute?azure-portal=true",
                  "text": "reference documentation"
                },
                {
                  "url": "/en-us/azure/virtual-machines/sizes?azure-portal=true",
                  "text": "sizes for virtual machines in Azure"
                }
              ]
            },
            {
              "number": 5,
              "title": "Exercise - Work with compute resources",
              "url": "https://learn.microsoft.com/en-us/training/modules/work-compute-resources-azure-machine-learning/5-exercise",
              "href": "5-exercise",
              "content": "Read in English\nAdd\nAdd to plan\nExercise - Work with compute resources\nCompleted\n10 minutes\nNow, it's your chance to explore how to work with compute resources in Azure Machine Learning.\nIn this exercise, you learn how to:\nCreate and use a compute instance.\nCreate and use a compute cluster.\nInstructions\nLaunch the exercise and follow the instructions.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Exercise - Work with compute resources"
                },
                {
                  "level": 2,
                  "text": "Instructions"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-azure/work-compute-resources-azure-machine-learning/media/launch-exercise.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/work-compute-resources-azure-machine-learning/media/launch-exercise.png",
                  "alt_text": "Button to launch exercise.",
                  "title": "",
                  "filename": "launch-exercise.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Instructions",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 6,
              "title": "Module assessment",
              "url": "https://learn.microsoft.com/en-us/training/modules/work-compute-resources-azure-machine-learning/6-knowledge-check",
              "href": "6-knowledge-check",
              "content": "Read in English\nAdd\nAdd to plan\nModule assessment\nCompleted\n3 minutes\n1.\nYou're working in Visual Studio Code. You cloned a GitHub repository to Visual Studio Code and you're editing code in a Jupyter notebook. To test the code, you want to run a cell within the notebook. Which compute should you use?\nCompute instance\nCompute cluster\nAzure Databricks cluster\n2.\nYou're experimenting with component-based pipelines in the Designer. You want to quickly iterate and experiment, as you're trying out varying configurations of a pipeline. You're using a compute cluster. To minimize the start-up time each time you submit a pipeline, which parameter should you change?\nCompute size\nIdle time before scale down\nMaximum number of instances\nYou must answer all questions before checking your work.\nYou must answer all questions before checking your work.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Module assessment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 7,
              "title": "Summary",
              "url": "https://learn.microsoft.com/en-us/training/modules/work-compute-resources-azure-machine-learning/7-summary",
              "href": "7-summary",
              "content": "Read in English\nAdd\nAdd to plan\nSummary\nCompleted\n1 minute\nIn this module, you've learned how to:\nChoose the appropriate compute target.\nCreate and use a compute instance.\nCreate and use a compute cluster.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Summary"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            }
          ]
        },
        {
          "title": "Work with environments in Azure Machine Learning",
          "url": "https://learn.microsoft.com/en-us/training/modules/work-environments-azure-machine-learning/",
          "description": "",
          "learning_objectives": [],
          "prerequisites": [],
          "units": [
            {
              "number": 1,
              "title": "Introduction",
              "url": "https://learn.microsoft.com/en-us/training/modules/work-environments-azure-machine-learning/1-introduction",
              "href": "1-introduction",
              "content": "Read in English\nAdd\nAdd to plan\nIntroduction\nCompleted\n2 minutes\nAs a data scientist, you want to write code that works in any development environment. Whether you're using local or cloud compute, the code should successfully execute to train a machine learning model for example.\nTo run code, you need to ensure necessary packages, libraries, and dependencies are installed on the compute you use to run the code. In Azure Machine Learning,\nenvironments\nlist and store the necessary packages that you can reuse across compute targets.\nNote\nIn this module, we refer to Azure Machine Learning's interpretation of environments. Note that the term environments is also used to describe other technical concepts. For example, in DevOps, environments refer to the collection of resources used for a specific phase in the application deployment, like the development or production environment.\nLearn more about continuous deployment for machine learning.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Introduction"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/training/modules/continuous-deployment-for-machine-learning/?azure-portal=true",
                  "text": "Learn more about continuous deployment for machine learning."
                }
              ]
            },
            {
              "number": 2,
              "title": "Understand environments",
              "url": "https://learn.microsoft.com/en-us/training/modules/work-environments-azure-machine-learning/2-understand-environments",
              "href": "2-understand-environments",
              "content": "Read in English\nAdd\nAdd to plan\nUnderstand environments\nCompleted\n6 minutes\nIn an enterprise machine learning solution, where experiments may be run in various compute contexts, it can be important to be aware of the environments in which your experiment code is running. You can use Azure Machine Learning\nenvironments\nto create environments and specify runtime configuration for an experiment.\nWhen you create an Azure Machine Learning workspace,\ncurated\nenvironments are automatically created and made available to you. Alternatively, you can create and manage your own\ncustom\nenvironments and register them in the workspace. Creating and registering custom environments makes it possible to define consistent, reusable runtime contexts for your experiments - regardless of where the experiment script is run.\nWhat is an environment in Azure Machine Learning?\nPython code runs in the context of a\nvirtual environment\nthat defines the version of the Python runtime to be used as well as the installed packages available to the code. In most Python installations, packages are installed and managed in environments using\nconda\nor\npip\n.\nTo improve portability, you usually create environments in Docker containers that are in turn hosted on compute targets, such as your development computer, virtual machines, or clusters in the cloud.\nAzure Machine Learning builds environment definitions into Docker images and conda environments. When you use an environment, Azure Machine Learning builds the environment on the\nAzure Container registry\nassociated with the workspace.\nTip\nWhen you create an Azure Machine Learning workspace, you can choose whether to use an existing Azure Container registry, or whether to let the workspace create a new registry for you when needed.\nTo view all available environments within the Azure Machine Learning workspace, you can list the environments in the studio, using the Azure CLI, or the Python SDK.\nFor example, to list the environments using the Python SDK:\nenvs = ml_client.environments.list()\nfor env in envs:\n    print(env.name)\nTo review the details of a specific environment, you can retrieve an environment by its registered name:\nenv = ml_client.environments.get(name=\"my-environment\", version=\"1\")\nprint(env)\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Understand environments"
                },
                {
                  "level": 2,
                  "text": "What is an environment in Azure Machine Learning?"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "envs = ml_client.environments.list()\nfor env in envs:\n    print(env.name)",
                "envs = ml_client.environments.list()\nfor env in envs:\n    print(env.name)",
                "env = ml_client.environments.get(name=\"my-environment\", version=\"1\")\nprint(env)",
                "env = ml_client.environments.get(name=\"my-environment\", version=\"1\")\nprint(env)"
              ],
              "images": [
                {
                  "src": "../../wwl-azure/work-environments-azure-machine-learning/media/environment.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/work-environments-azure-machine-learning/media/environment.png",
                  "alt_text": "Diagram of environments, in containers, in compute targets.",
                  "title": "",
                  "filename": "environment.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "What is an environment in Azure Machine Learning?",
                    "following_text": "Azure Machine Learning builds environment definitions into Docker images and conda environments. When you use an environment, Azure Machine Learning builds the environment on theAzure Container regist",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 3,
              "title": "Explore and use curated environments",
              "url": "https://learn.microsoft.com/en-us/training/modules/work-environments-azure-machine-learning/3-explore-use-curated-environments",
              "href": "3-explore-use-curated-environments",
              "content": "Read in English\nAdd\nAdd to plan\nExplore and use curated environments\nCompleted\n8 minutes\nCurated environments\nare prebuilt environments for the most common machine learning workloads, available in your workspace by default.\nCurated environments use the prefix\nAzureML-\nand are designed to provide for scripts that use popular machine learning frameworks and tooling.\nFor example, there are curated environments for when you want to run a script that trains a regression, clustering, or classification model with Scikit-Learn.\nTo explore a curated environment, you can view it in the studio, using the Azure CLI, or the Python SDK.\nThe following command allows you to retrieve the description and tags of a curated environment with the Python SDK:\nenv = ml_client.environments.get(\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\", version=44)\nprint(env. description, env.tags)\nUse a curated environment\nMost commonly, you use environments when you want to run a script as a (\ncommand\n)\njob\n.\nTo specify which environment you want to use to run your script, you reference an environment by its name and version.\nFor example, the following code shows how to configure a command job with the Python SDK, which uses a curated environment including Scikit-Learn:\nfrom azure.ai.ml import command\n\n# configure job\njob = command(\n    code=\"./src\",\n    command=\"python train.py\",\n    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n    compute=\"aml-cluster\",\n    display_name=\"train-with-curated-environment\",\n    experiment_name=\"train-with-curated-environment\"\n)\n\n# submit job\nreturned_job = ml_client.create_or_update(job)\nTest and troubleshoot a curated environment\nAs curated environments allow for faster deployment time, it's a best practice to first explore whether one of the pre-created curated environments can be used to run your code.\nYou can verify that a curated environment includes all necessary packages by reviewing its details. Then, you can test by using the environment to run the script.\nIf an environment doesn't include all necessary packages to run your code, your job fails.\nWhen a job fails, you can review the detailed error logs in the\nOutputs + logs\ntab of your job in the Azure Machine Learning studio.\nA common error message that indicates your environment is incomplete, is\nModuleNotFoundError\n. The module that isn't found is listed in the error message. By reviewing the error message, you can update the environment to include the libraries to ensure the necessary packages are installed on the compute target before running the code.\nWhen you need to specify other necessary packages, you can use a curated environment as reference for your own custom environments by modifying the Dockerfiles that back these curated environments.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Explore and use curated environments"
                },
                {
                  "level": 2,
                  "text": "Use a curated environment"
                },
                {
                  "level": 2,
                  "text": "Test and troubleshoot a curated environment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "env = ml_client.environments.get(\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\", version=44)\nprint(env. description, env.tags)",
                "env = ml_client.environments.get(\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\", version=44)\nprint(env. description, env.tags)",
                "from azure.ai.ml import command\n\n# configure job\njob = command(\n    code=\"./src\",\n    command=\"python train.py\",\n    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n    compute=\"aml-cluster\",\n    display_name=\"train-with-curated-environment\",\n    experiment_name=\"train-with-curated-environment\"\n)\n\n# submit job\nreturned_job = ml_client.create_or_update(job)",
                "from azure.ai.ml import command\n\n# configure job\njob = command(\n    code=\"./src\",\n    command=\"python train.py\",\n    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n    compute=\"aml-cluster\",\n    display_name=\"train-with-curated-environment\",\n    experiment_name=\"train-with-curated-environment\"\n)\n\n# submit job\nreturned_job = ml_client.create_or_update(job)",
                "ModuleNotFoundError"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 4,
              "title": "Create and use custom environments",
              "url": "https://learn.microsoft.com/en-us/training/modules/work-environments-azure-machine-learning/4-create-use-custom-environments",
              "href": "4-create-use-custom-environments",
              "content": "Read in English\nAdd\nAdd to plan\nCreate and use custom environments\nCompleted\n12 minutes\nWhen you need to create your own environment in Azure Machine Learning to list all necessary packages, libraries, and dependencies to run your scripts, you can create\ncustom environments\n.\nYou can define an environment from a Docker image, a Docker build context, and a conda specification with Docker image.\nCreate a custom environment from a Docker image\nThe easiest approach is likely to be to create an environment from a Docker image. Docker images can be hosted in a public registry like\nDocker Hub\nor privately stored in an Azure Container registry.\nMany open-source frameworks are encapsulated in public images to be found on Docker Hub. For example, you can find a public Docker image that contains all necessary packages to train a deep learning model with\nPyTorch\n.\nTo create an environment from a Docker image, you can use the Python SDK:\nfrom azure.ai.ml.entities import Environment\n\nenv_docker_image = Environment(\n    image=\"pytorch/pytorch:latest\",\n    name=\"public-docker-image-example\",\n    description=\"Environment created from a public Docker image.\",\n)\nml_client.environments.create_or_update(env_docker_image)\nYou can also use the Azure Machine Learning base images to create an environment (which are similar to the images used by curated environments):\nfrom azure.ai.ml.entities import Environment\n\nenv_docker_image = Environment(\n    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n    name=\"aml-docker-image-example\",\n    description=\"Environment created from a Azure ML Docker image.\",\n)\nml_client.environments.create_or_update(env_docker_image)\nCreate a custom environment with a conda specification file\nThough Docker images contain all necessary packages when working with a specific framework, it may be that you need to include other packages to run your code.\nFor example, you may want to train a model with PyTorch, and track the model with MLflow.\nWhen you need to include other packages or libraries in your environment, you can add a conda specification file to a Docker image when creating the environment.\nA conda specification file is a YAML file, which lists the packages that need to be installed using\nconda\nor\npip\n. Such a YAML file may look like:\nname: basic-env-cpu\nchannels:\n  - conda-forge\ndependencies:\n  - python=3.7\n  - scikit-learn\n  - pandas\n  - numpy\n  - matplotlib\nTip\nReview the conda documentation on how to\ncreate an environment manually\nfor information on the standard format for conda files.\nTo create an environment from a base Docker image and a conda specification file, you can use the following code:\nfrom azure.ai.ml.entities import Environment\n\nenv_docker_conda = Environment(\n    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n    conda_file=\"./conda-env.yml\",\n    name=\"docker-image-plus-conda-example\",\n    description=\"Environment created from a Docker image plus Conda environment.\",\n)\nml_client.environments.create_or_update(env_docker_conda)\nNote\nSince all curated environments are prefixed with\nAzureML-\n, you can't create an environment with the same prefix.\nUse an environment\nMost commonly, you use environments when you want to run a script as a (\ncommand\n)\njob\n.\nTo specify which environment you want to use to run your script, you reference an environment using the\n<curated-environment-name>:<version>\nor\n<curated-environment-name>@latest\nsyntax.\nFor example, the following code shows how to configure a command job with the Python SDK, which uses a curated environment including Scikit-Learn:\nfrom azure.ai.ml import command\n\n# configure job\njob = command(\n    code=\"./src\",\n    command=\"python train.py\",\n    environment=\"docker-image-plus-conda-example:1\",\n    compute=\"aml-cluster\",\n    display_name=\"train-custom-env\",\n    experiment_name=\"train-custom-env\"\n)\n\n# submit job\nreturned_job = ml_client.create_or_update(job)\nWhen you submit the job, the environment is built. The first time you use an environment, it can take 10-15 minutes to build the environment. You can review the logs of the environment build in the logs of the job.\nWhen Azure Machine Learning builds a new environment, it's added to the list of custom environments in the workspace. The image of the environment is hosted in the Azure Container registry associated to the workspace. Whenever you use the same environment for another job (and another script), the environment is ready to go and doesn't need to be build again.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Create and use custom environments"
                },
                {
                  "level": 2,
                  "text": "Create a custom environment from a Docker image"
                },
                {
                  "level": 2,
                  "text": "Create a custom environment with a conda specification file"
                },
                {
                  "level": 2,
                  "text": "Use an environment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "from azure.ai.ml.entities import Environment\n\nenv_docker_image = Environment(\n    image=\"pytorch/pytorch:latest\",\n    name=\"public-docker-image-example\",\n    description=\"Environment created from a public Docker image.\",\n)\nml_client.environments.create_or_update(env_docker_image)",
                "from azure.ai.ml.entities import Environment\n\nenv_docker_image = Environment(\n    image=\"pytorch/pytorch:latest\",\n    name=\"public-docker-image-example\",\n    description=\"Environment created from a public Docker image.\",\n)\nml_client.environments.create_or_update(env_docker_image)",
                "from azure.ai.ml.entities import Environment\n\nenv_docker_image = Environment(\n    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n    name=\"aml-docker-image-example\",\n    description=\"Environment created from a Azure ML Docker image.\",\n)\nml_client.environments.create_or_update(env_docker_image)",
                "from azure.ai.ml.entities import Environment\n\nenv_docker_image = Environment(\n    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n    name=\"aml-docker-image-example\",\n    description=\"Environment created from a Azure ML Docker image.\",\n)\nml_client.environments.create_or_update(env_docker_image)",
                "name: basic-env-cpu\nchannels:\n  - conda-forge\ndependencies:\n  - python=3.7\n  - scikit-learn\n  - pandas\n  - numpy\n  - matplotlib",
                "name: basic-env-cpu\nchannels:\n  - conda-forge\ndependencies:\n  - python=3.7\n  - scikit-learn\n  - pandas\n  - numpy\n  - matplotlib",
                "from azure.ai.ml.entities import Environment\n\nenv_docker_conda = Environment(\n    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n    conda_file=\"./conda-env.yml\",\n    name=\"docker-image-plus-conda-example\",\n    description=\"Environment created from a Docker image plus Conda environment.\",\n)\nml_client.environments.create_or_update(env_docker_conda)",
                "from azure.ai.ml.entities import Environment\n\nenv_docker_conda = Environment(\n    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n    conda_file=\"./conda-env.yml\",\n    name=\"docker-image-plus-conda-example\",\n    description=\"Environment created from a Docker image plus Conda environment.\",\n)\nml_client.environments.create_or_update(env_docker_conda)",
                "<curated-environment-name>:<version>",
                "<curated-environment-name>@latest",
                "from azure.ai.ml import command\n\n# configure job\njob = command(\n    code=\"./src\",\n    command=\"python train.py\",\n    environment=\"docker-image-plus-conda-example:1\",\n    compute=\"aml-cluster\",\n    display_name=\"train-custom-env\",\n    experiment_name=\"train-custom-env\"\n)\n\n# submit job\nreturned_job = ml_client.create_or_update(job)",
                "from azure.ai.ml import command\n\n# configure job\njob = command(\n    code=\"./src\",\n    command=\"python train.py\",\n    environment=\"docker-image-plus-conda-example:1\",\n    compute=\"aml-cluster\",\n    display_name=\"train-custom-env\",\n    experiment_name=\"train-custom-env\"\n)\n\n# submit job\nreturned_job = ml_client.create_or_update(job)"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "https://hub.docker.com/?azure-portal=true",
                  "text": "Docker Hub"
                },
                {
                  "url": "https://hub.docker.com/r/pytorch/pytorch?azure-portal=true",
                  "text": "PyTorch"
                },
                {
                  "url": "https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#creating-an-environment-file-manually?azure-portal=true",
                  "text": "create an environment manually"
                }
              ]
            },
            {
              "number": 5,
              "title": "Exercise - Work with environments",
              "url": "https://learn.microsoft.com/en-us/training/modules/work-environments-azure-machine-learning/5-exercise",
              "href": "5-exercise",
              "content": "Read in English\nAdd\nAdd to plan\nExercise - Work with environments\nCompleted\n10 minutes\nNow, it's your chance to explore how to work with environments in Azure Machine Learning.\nIn this exercise, you learn how to:\nCreate a custom environment.\nUse environments when running Azure Machine Learning jobs.\nInstructions\nLaunch the exercise and follow the instructions.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Exercise - Work with environments"
                },
                {
                  "level": 2,
                  "text": "Instructions"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-azure/work-environments-azure-machine-learning/media/launch-exercise.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/work-environments-azure-machine-learning/media/launch-exercise.png",
                  "alt_text": "Button to launch exercise.",
                  "title": "",
                  "filename": "launch-exercise.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Instructions",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 6,
              "title": "Module assessment",
              "url": "https://learn.microsoft.com/en-us/training/modules/work-environments-azure-machine-learning/6-knowledge-check",
              "href": "6-knowledge-check",
              "content": "Read in English\nAdd\nAdd to plan\nModule assessment\nCompleted\n3 minutes\n1.\nA data scientist created a script that trains a machine learning model using the open-source library scikit-learn. The data scientist wants to quickly test whether the script can run on the existing compute cluster, what type of environment should the data scientist use?\nDefault\nCurated\nCustom\n2.\nA command job fails with the error message that a module isn't found. The data scientist used a curated environment and wants to add a specific Python package to create a custom environment and successfully run the job. Which file should be created before creating the custom environment that uses a curated environment as reference?\nTraining script\nDocker image\nConda specification\nYou must answer all questions before checking your work.\nYou must answer all questions before checking your work.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Module assessment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 7,
              "title": "Summary",
              "url": "https://learn.microsoft.com/en-us/training/modules/work-environments-azure-machine-learning/7-summary",
              "href": "7-summary",
              "content": "Read in English\nAdd\nAdd to plan\nSummary\nCompleted\n1 minute\nIn this module, you've learned how to:\nUnderstand environments in Azure Machine Learning.\nExplore and use curated environments.\nCreate and use custom environments.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Summary"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "title": "Experiment with Azure Machine Learning",
      "url": "https://learn.microsoft.com/en-us/training/paths/automate-machine-learning-model-selection-azure-machine-learning/",
      "learn_uid": "learn.wwl.automate-machine-learning-model-selection-azure-machine-learning",
      "modules": [
        {
          "title": "Find the best classification model with Automated Machine Learning",
          "url": "https://learn.microsoft.com/en-us/training/modules/find-best-classification-model-automated-machine-learning/",
          "description": "",
          "learning_objectives": [],
          "prerequisites": [],
          "units": [
            {
              "number": 1,
              "title": "Introduction",
              "url": "https://learn.microsoft.com/en-us/training/modules/find-best-classification-model-automated-machine-learning/1-introduction",
              "href": "1-introduction",
              "content": "Read in English\nAdd\nAdd to plan\nIntroduction\nCompleted\n2 minutes\nGoing through trial and error to find the best performing model can be time-consuming. Instead of manually having to test and evaluate various configurations to train a machine learning model, you can automate it with\nautomated machine learning\nor\nAutoML\n.\nAutoML allows you to try multiple preprocessing transformations and algorithms with your data to find the best machine learning model.\nImagine you want to find the best performing\nclassification\nmodel. You can create an AutoML experiment using the visual interface of Azure Machine Learning studio, the Azure command-line interface (CLI), or the Python software development kit (SDK).\nNote\nYou can use AutoML for other tasks such as regression, forecasting, image classification, and natural language processing. Learn more about\nwhen you can use AutoML\n.\nAs a data scientist, you may prefer to configure your AutoML experiment with the Python SDK.\nLearning objectives\nIn this module, you'll learn how to:\nPrepare your data to use AutoML for classification.\nConfigure and run an AutoML experiment.\nEvaluate and compare models.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Introduction"
                },
                {
                  "level": 2,
                  "text": "Learning objectives"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-azure/find-best-classification-model-automated-machine-learning/media/automated-machine-learning.jpg",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/find-best-classification-model-automated-machine-learning/media/automated-machine-learning.jpg",
                  "alt_text": "Diagram illustrating how multiple models are trained and evaluated, after the model with the best performing metrics is selected.",
                  "title": "",
                  "filename": "automated-machine-learning.jpg",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Introduction",
                    "following_text": "Imagine you want to find the best performingclassificationmodel. You can create an AutoML experiment using the visual interface of Azure Machine Learning studio, the Azure command-line interface (CLI)",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/concept-automated-ml?azure-portal=true",
                  "text": "when you can use AutoML"
                }
              ]
            },
            {
              "number": 2,
              "title": "Preprocess data and configure featurization",
              "url": "https://learn.microsoft.com/en-us/training/modules/find-best-classification-model-automated-machine-learning/2-preprocess-data-configure-featurization",
              "href": "2-preprocess-data-configure-featurization",
              "content": "Read in English\nAdd\nAdd to plan\nPreprocess data and configure featurization\nCompleted\n6 minutes\nBefore you can run an automated machine learning (AutoML) experiment, you need to prepare your data. When you want to train a classification model, you'll only need to provide the training data.\nAfter you've collected the data, you need to create a\ndata asset\nin Azure Machine Learning. In order for AutoML to understand how to read the data, you need to create a\nMLTable\ndata asset that includes the schema of the data.\nYou can create a MLTable data asset when your data is stored in a folder together with a MLTable file. When you have created the data asset, you can specify it as input with the following code:\nfrom azure.ai.ml.constants import AssetTypes\nfrom azure.ai.ml import Input\n\nmy_training_data_input = Input(type=AssetTypes.MLTABLE, path=\"azureml:input-data-automl:1\")\nTip\nLearn more about\nhow to create a MLTable data asset in Azure Machine Learning\n.\nOnce you've created the data asset, you can configure the AutoML experiment. Before AutoML trains a classification model, preprocessing transformations can be applied to your data.\nUnderstand scaling and normalization\nAutoML applies scaling and normalization to numeric data automatically, helping prevent any large-scale features from dominating training. During an AutoML experiment, multiple scaling or normalization techniques will be applied.\nConfigure optional featurization\nYou can choose to have AutoML apply preprocessing transformations, such as:\nMissing value imputation to eliminate nulls in the training dataset.\nCategorical encoding to convert categorical features to numeric indicators.\nDropping high-cardinality features, such as record IDs.\nFeature engineering (for example, deriving individual date parts from DateTime features)\nBy default, AutoML will perform featurization on your data. You can disable it if you don't want the data to be transformed.\nIf you do want to make use of the integrated featurization function, you can customize it. For example, you can specify which imputation method should be used for a specific feature.\nAfter an AutoML experiment is completed, you'll be able to review which scaling and normalization methods have been applied. You'll also get notified if AutoML has detected any issues with the data, like whether there are missing values or class imbalance.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Preprocess data and configure featurization"
                },
                {
                  "level": 2,
                  "text": "Understand scaling and normalization"
                },
                {
                  "level": 2,
                  "text": "Configure optional featurization"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "from azure.ai.ml.constants import AssetTypes\nfrom azure.ai.ml import Input\n\nmy_training_data_input = Input(type=AssetTypes.MLTABLE, path=\"azureml:input-data-automl:1\")",
                "from azure.ai.ml.constants import AssetTypes\nfrom azure.ai.ml import Input\n\nmy_training_data_input = Input(type=AssetTypes.MLTABLE, path=\"azureml:input-data-automl:1\")"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-mltable?azure-portal=true",
                  "text": "how to create a MLTable data asset in Azure Machine Learning"
                }
              ]
            },
            {
              "number": 3,
              "title": "Run an Automated Machine Learning experiment",
              "url": "https://learn.microsoft.com/en-us/training/modules/find-best-classification-model-automated-machine-learning/3-run-job",
              "href": "3-run-job",
              "content": "Read in English\nAdd\nAdd to plan\nRun an Automated Machine Learning experiment\nCompleted\n12 minutes\nTo run an automated machine learning (AutoML) experiment, you can configure and submit the job with the Python SDK.\nThe algorithms AutoML uses will depend on the task you specify. When you want to train a classification model, AutoML will choose from a list of classification algorithms:\nLogistic Regression\nLight Gradient Boosting Machine (GBM)\nDecision Tree\nRandom Forest\nNaive Bayes\nLinear Support Vector Machine (SVM)\nXGBoost\nAnd others...\nTip\nFor a full list of supported algorithms, explore\nthe overview of supported algorithms\n.\nRestrict algorithm selection\nBy default, AutoML will randomly select from the full range of algorithms for the specified task. You can choose to block individual algorithms from being selected; which can be useful if you know that your data isn't suited to a particular type of algorithm. You also may want to block certain algorithms if you have to comply with a policy that restricts the type of machine learning algorithms you can use in your organization.\nConfigure an AutoML experiment\nWhen you use the Python SDK (v2) to configure an AutoML experiment or job, you configure the experiment using the\nautoml\nclass. For classification, you'll use the\nautoml.classification\nfunction as shown in the following example:\nfrom azure.ai.ml import automl\n\n# configure the classification job\nclassification_job = automl.classification(\n    compute=\"aml-cluster\",\n    experiment_name=\"auto-ml-class-dev\",\n    training_data=my_training_data_input,\n    target_column_name=\"Diabetic\",\n    primary_metric=\"accuracy\",\n    n_cross_validations=5,\n    enable_model_explainability=True\n)\nNote\nAutoML needs a MLTable data asset as input. In the example,\nmy_training_data_input\nrefers to a MLTable data asset created in the Azure Machine Learning workspace.\nSpecify the primary metric\nOne of the most important settings you must specify is the\nprimary_metric\n. The primary metric is the target performance metric for which the optimal model will be determined. Azure Machine Learning supports a set of named metrics for each type of task.\nTo retrieve the list of metrics available when you want to train a classification model, you can use the\nClassificationPrimaryMetrics\nfunction as shown here:\nfrom azure.ai.ml.automl import ClassificationPrimaryMetrics\n \nlist(ClassificationPrimaryMetrics)\nTip\nYou can find a full list of primary metrics and their definitions in\nevaluate automated machine learning experiment results\n.\nSet the limits\nTraining machine learning models will cost compute. To minimize costs and time spent on training, you can set limits to an AutoML experiment or job by using\nset_limits()\n.\nThere are several options to set limits to an AutoML experiment:\ntimeout_minutes\n: Number of minutes after which the complete AutoML experiment is terminated.\ntrial_timeout_minutes\n: Maximum number of minutes one trial can take.\nmax_trials\n: Maximum number of trials, or models that will be trained.\nenable_early_termination\n: Whether to end the experiment if the score isn't improving in the short term.\nclassification_job.set_limits(\n    timeout_minutes=60, \n    trial_timeout_minutes=20, \n    max_trials=5,\n    enable_early_termination=True,\n)\nTo save time, you can also run multiple trials in parallel. When you use a compute cluster, you can have as many parallel trials as you have nodes. The maximum number of parallel trials is therefore related to the maximum number of nodes your compute cluster has. If you want to set the maximum number of parallel trials to be less than the maximum number of nodes, you can use\nmax_concurrent_trials\n.\nSet the training properties\nAutoML will try various combinations of featurization and algorithms to train a machine learning model. If you already know that certain algorithms aren't well-suited for your data, you can exclude (or include) a subset of the available algorithms.\nYou can also choose whether you want to allow AutoML to use ensemble models.\nSubmit an AutoML experiment\nYou can submit an AutoML job with the following code:\n# submit the AutoML job\nreturned_job = ml_client.jobs.create_or_update(\n    classification_job\n)\nYou can monitor AutoML job runs in the Azure Machine Learning studio. To get a direct link to the AutoML job by running the following code:\naml_url = returned_job.studio_url\nprint(\"Monitor your job at\", aml_url)\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Run an Automated Machine Learning experiment"
                },
                {
                  "level": 2,
                  "text": "Restrict algorithm selection"
                },
                {
                  "level": 2,
                  "text": "Configure an AutoML experiment"
                },
                {
                  "level": 3,
                  "text": "Specify the primary metric"
                },
                {
                  "level": 3,
                  "text": "Set the limits"
                },
                {
                  "level": 3,
                  "text": "Set the training properties"
                },
                {
                  "level": 2,
                  "text": "Submit an AutoML experiment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "automl.classification",
                "from azure.ai.ml import automl\n\n# configure the classification job\nclassification_job = automl.classification(\n    compute=\"aml-cluster\",\n    experiment_name=\"auto-ml-class-dev\",\n    training_data=my_training_data_input,\n    target_column_name=\"Diabetic\",\n    primary_metric=\"accuracy\",\n    n_cross_validations=5,\n    enable_model_explainability=True\n)",
                "from azure.ai.ml import automl\n\n# configure the classification job\nclassification_job = automl.classification(\n    compute=\"aml-cluster\",\n    experiment_name=\"auto-ml-class-dev\",\n    training_data=my_training_data_input,\n    target_column_name=\"Diabetic\",\n    primary_metric=\"accuracy\",\n    n_cross_validations=5,\n    enable_model_explainability=True\n)",
                "my_training_data_input",
                "from azure.ai.ml.automl import ClassificationPrimaryMetrics\n \nlist(ClassificationPrimaryMetrics)",
                "from azure.ai.ml.automl import ClassificationPrimaryMetrics\n \nlist(ClassificationPrimaryMetrics)",
                "set_limits()",
                "timeout_minutes",
                "trial_timeout_minutes",
                "enable_early_termination",
                "classification_job.set_limits(\n    timeout_minutes=60, \n    trial_timeout_minutes=20, \n    max_trials=5,\n    enable_early_termination=True,\n)",
                "classification_job.set_limits(\n    timeout_minutes=60, \n    trial_timeout_minutes=20, \n    max_trials=5,\n    enable_early_termination=True,\n)",
                "max_concurrent_trials",
                "# submit the AutoML job\nreturned_job = ml_client.jobs.create_or_update(\n    classification_job\n)",
                "# submit the AutoML job\nreturned_job = ml_client.jobs.create_or_update(\n    classification_job\n)",
                "aml_url = returned_job.studio_url\nprint(\"Monitor your job at\", aml_url)",
                "aml_url = returned_job.studio_url\nprint(\"Monitor your job at\", aml_url)"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-configure-auto-train#supported-algorithms?azure-portal=true",
                  "text": "the overview of supported algorithms"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-understand-automated-ml?azure-portal=true",
                  "text": "evaluate automated machine learning experiment results"
                }
              ]
            },
            {
              "number": 4,
              "title": "Evaluate and compare models",
              "url": "https://learn.microsoft.com/en-us/training/modules/find-best-classification-model-automated-machine-learning/4-evaluate-compare-models",
              "href": "4-evaluate-compare-models",
              "content": "Read in English\nAdd\nAdd to plan\nEvaluate and compare models\nCompleted\n3 minutes\nWhen an automated machine learning (AutoML) experiment has completed, you'll want to review the models that have been trained and decide which one performed best.\nIn the Azure Machine Learning studio, you can select an AutoML experiment to explore its details.\nOn the\nOverview\npage of the AutoML experiment run, you can review the input data asset and the summary of the best model. To explore all models that have been trained, you can select the\nModels\ntab:\nExplore preprocessing steps\nWhen you've enabled featurization for your AutoML experiment, data guardrails will automatically be applied too. The three data guardrails that are supported for classification models are:\nClass balancing detection.\nMissing feature values imputation.\nHigh cardinality feature detection.\nEach of these data guardrails will show one of three possible states:\nPassed\n: No problems were detected and no action is required.\nDone\n: Changes were applied to your data. You should review the changes AutoML has made to your data.\nAlerted\n: An issue was detected but couldn't be fixed. You should review the data to fix the issue.\nNext to data guardrails, AutoML can apply scaling and normalization techniques to each model that is trained. You can review the technique applied in the list of models under\nAlgorithm name\n.\nFor example, the algorithm name of a model listed may be\nMaxAbsScaler, LightGBM\n.\nMaxAbsScaler\nrefers to a scaling technique where each feature is scaled by its maximum absolute value.\nLightGBM\nrefers to the classification algorithm used to train the model.\nRetrieve the best run and its model\nWhen you're reviewing the models in AutoML, you can easily identify the best run based on the primary metric you specified. In the Azure Machine Learning studio, the models are automatically sorted to show the best performing model at the top.\nIn the\nModels\ntab of the AutoML experiment, you can\nedit the columns\nif you want to show other metrics in the same overview. By creating a more comprehensive overview that includes various metrics, it may be easier to compare models.\nTo explore a model even further, you can generate explanations for each model that has been trained. When configuring an AutoML experiment, you can specify that explanations should be generated for the best performing model. If however, you're interested in the interpretability of another model, you can select the model in the overview and select\nExplain model\n.\nNote\nExplaining a model is an approximation to the model's interpretability. Specifically, explanations will estimate the relative importance of features on the target feature (what the model is trained to predict). Learn more about\nmodel interpretability\n.\nTip\nLearn more about\nhow to evaluate AutoML runs\n.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Evaluate and compare models"
                },
                {
                  "level": 2,
                  "text": "Explore preprocessing steps"
                },
                {
                  "level": 2,
                  "text": "Retrieve the best run and its model"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "MaxAbsScaler, LightGBM",
                "MaxAbsScaler"
              ],
              "images": [
                {
                  "src": "../../wwl-azure/find-best-classification-model-automated-machine-learning/media/models-overview.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/find-best-classification-model-automated-machine-learning/media/models-overview.png",
                  "alt_text": "Screenshot of the models tab in an automated machine learning experiment run in the Azure Machine Learning studio.",
                  "title": "",
                  "filename": "models-overview.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Evaluate and compare models",
                    "following_text": "When you've enabled featurization for your AutoML experiment, data guardrails will automatically be applied too. The three data guardrails that are supported for classification models are:",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-machine-learning-interpretability?azure-portal=true",
                  "text": "model interpretability"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-understand-automated-ml?azure-portal=true",
                  "text": "how to evaluate AutoML runs"
                }
              ]
            },
            {
              "number": 5,
              "title": "Exercise - Find the best classification model with Automated Machine Learning",
              "url": "https://learn.microsoft.com/en-us/training/modules/find-best-classification-model-automated-machine-learning/5-exercise",
              "href": "5-exercise",
              "content": "Read in English\nAdd\nAdd to plan\nExercise - Find the best classification model with Automated Machine Learning\nCompleted\n10 minutes\nNow, it's your chance to train a classification model with Automated Machine Learning in Azure Machine Learning.\nIn this exercise, you learn how to:\nPrepare the data.\nConfigure an Automated Machine Learning experiment.\nRun an Automated Machine Learning job.\nInstructions\nLaunch the exercise and follow the instructions.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Exercise - Find the best classification model with Automated Machine Learning"
                },
                {
                  "level": 2,
                  "text": "Instructions"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-azure/find-best-classification-model-automated-machine-learning/media/launch-exercise.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/find-best-classification-model-automated-machine-learning/media/launch-exercise.png",
                  "alt_text": "Button to launch exercise.",
                  "title": "",
                  "filename": "launch-exercise.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Instructions",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 6,
              "title": "Module assessment",
              "url": "https://learn.microsoft.com/en-us/training/modules/find-best-classification-model-automated-machine-learning/6-knowledge-check",
              "href": "6-knowledge-check",
              "content": "Read in English\nAdd\nAdd to plan\nModule assessment\nCompleted\n3 minutes\n1.\nA data scientist wants to use automated machine learning to find the model with the best AUC_weighted metric. Which parameter of the classification function should be configured?\ntask='AUC_weighted'\ntarget_column_name='AUC_weighted'\nprimary_metric='AUC_weighted'\n2.\nA data scientist has preprocessed the training data and wants to use automated machine learning to quickly iterate through various algorithms. The data shouldn't be changed. What should be the featurization mode to train a model without letting automated machine learning make changes to the data?\nauto\ncustom\noff\nYou must answer all questions before checking your work.\nYou must answer all questions before checking your work.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Module assessment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "task='AUC_weighted'",
                "target_column_name='AUC_weighted'",
                "primary_metric='AUC_weighted'"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 7,
              "title": "Summary",
              "url": "https://learn.microsoft.com/en-us/training/modules/find-best-classification-model-automated-machine-learning/7-summary",
              "href": "7-summary",
              "content": "Read in English\nAdd\nAdd to plan\nSummary\nCompleted\n1 minute\nIn this module, you've learned how to:\nPrepare your data to use AutoML for classification.\nConfigure and run an AutoML experiment.\nEvaluate and compare models.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Summary"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            }
          ]
        },
        {
          "title": "Track model training in Jupyter notebooks with MLflow",
          "url": "https://learn.microsoft.com/en-us/training/modules/track-model-training-jupyter-notebooks-mlflow/",
          "description": "",
          "learning_objectives": [],
          "prerequisites": [],
          "units": [
            {
              "number": 1,
              "title": "Introduction",
              "url": "https://learn.microsoft.com/en-us/training/modules/track-model-training-jupyter-notebooks-mlflow/1-introduction",
              "href": "1-introduction",
              "content": "Read in English\nAdd\nAdd to plan\nIntroduction\nCompleted\n3 minutes\nImagine you're a data scientist for a company developing an application for a cancer research lab. The application is to be used by researchers who upload an image of tissue to determine whether or not it's healthy tissue. You're asked to train the model to detect breast cancer on a large image database that contains examples of healthy and unhealthy tissue\nYou're familiar with Jupyter notebooks, which you plan to use to develop the model. However, you want to periodically retrain the model to create a better performing model that must then be deployed so that researchers can use the model in the application they're using.\nYou'll learn how to track model training in notebooks with MLflow in Azure Machine Learning.\nLearning objectives\nIn this module, you'll learn how to:\nConfigure MLflow to use in notebooks\nUse MLflow for model tracking in notebooks\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Introduction"
                },
                {
                  "level": 2,
                  "text": "Learning objectives"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 2,
              "title": "Configure MLflow for model tracking in notebooks",
              "url": "https://learn.microsoft.com/en-us/training/modules/track-model-training-jupyter-notebooks-mlflow/2-use-mlflow-model-tracking",
              "href": "2-use-mlflow-model-tracking",
              "content": "Read in English\nAdd\nAdd to plan\nConfigure MLflow for model tracking in notebooks\nCompleted\n6 minutes\nAs a data scientist, you'll want to develop a model in a notebook as it allows you to quickly test and run code.\nAnytime you train a model, you want the results to be reproducible. By tracking and logging your work, you can review your work at any time and decide what the best approach is to train a model.\nMLflow\nis an open-source library for tracking and managing your machine learning experiments. In particular,\nMLflow Tracking\nis a component of MLflow that logs everything about the model you're training, such as\nparameters\n,\nmetrics\n, and\nartifacts\n.\nTo use MLflow in notebooks in the Azure Machine Learning workspace, you'll need to install the necessary libraries and set Azure Machine Learning as the tracking store. When you've configured MLflow, you can start to use MLflow when training models in notebooks.\nConfigure MLflow in notebooks\nYou can create and edit notebooks within Azure Machine Learning or on a local device.\nUse Azure Machine Learning notebooks\nWithin the Azure Machine Learning workspace, you can create notebooks and connect the notebooks to an Azure Machine Learning managed\ncompute instance\n.\nWhen you're running a notebook on a compute instance, MLflow is already configured, and ready to be used.\nTo verify that the necessary packages are installed, you can run the following code:\npip show mlflow\npip show azureml-mlflow\nThe\nmlflow\npackage is the open-source library. The\nazureml-mlflow\npackage contains the integration code of Azure Machine Learning with MLflow.\nUse MLflow on a local device\nWhen you prefer working in notebooks on a local device, you can also make use of MLflow. You'll need to configure MLflow by completing the following steps:\nInstall the\nmlflow\nand\nazureml-mlflow\npackage.\npip install mlflow\npip install azureml-mlflow\nNavigate to the Azure Machine Learning studio.\nSelect the name of the workspace you're working on in the top right corner of the studio.\nSelect\nView all properties in Azure portal\n. A new tab will open to take you to the Azure Machine Learning service in the Azure portal.\nCopy the value of the\nMLflow tracking URI\n.\nUse the following code in your local notebook to configure MLflow to point to the Azure Machine Learning workspace, and set it to the workspace tracking URI.\nmlflow.set_tracking_uri = \"MLFLOW-TRACKING-URI\"\nTip\nLearn about alternative approaches to\nset up the tracking environment when working on a local device\n. For example, you can also use the Azure Machine Learning SDK v2 for Python, together with the workspace configuration file, to set the tracking URI.\nWhen you've configured MLflow to track your model's results and store it in your Azure Machine Learning workspace, you're ready to experiment in a notebook.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Configure MLflow for model tracking in notebooks"
                },
                {
                  "level": 2,
                  "text": "Configure MLflow in notebooks"
                },
                {
                  "level": 3,
                  "text": "Use Azure Machine Learning notebooks"
                },
                {
                  "level": 3,
                  "text": "Use MLflow on a local device"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "pip show mlflow\npip show azureml-mlflow",
                "pip show mlflow\npip show azureml-mlflow",
                "azureml-mlflow",
                "azureml-mlflow",
                "pip install mlflow\npip install azureml-mlflow",
                "pip install mlflow\npip install azureml-mlflow",
                "mlflow.set_tracking_uri = \"MLFLOW-TRACKING-URI\"",
                "mlflow.set_tracking_uri = \"MLFLOW-TRACKING-URI\""
              ],
              "images": [
                {
                  "src": "../../wwl-azure/track-model-training-jupyter-notebooks-mlflow/media/workspace-overview.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/track-model-training-jupyter-notebooks-mlflow/media/workspace-overview.png",
                  "alt_text": "Screenshot of overview page in Azure portal showing the MLflow tracking URI.",
                  "title": "",
                  "filename": "workspace-overview.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Use MLflow on a local device",
                    "following_text": "Use the following code in your local notebook to configure MLflow to point to the Azure Machine Learning workspace, and set it to the workspace tracking URI.",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-use-mlflow-cli-runs?azure-portal=true",
                  "text": "set up the tracking environment when working on a local device"
                }
              ]
            },
            {
              "number": 3,
              "title": "Train and track models in notebooks",
              "url": "https://learn.microsoft.com/en-us/training/modules/track-model-training-jupyter-notebooks-mlflow/3-train-models-notebooks",
              "href": "3-train-models-notebooks",
              "content": "Read in English\nAdd\nAdd to plan\nTrain and track models in notebooks\nCompleted\n10 minutes\nAs a data scientist, you use notebooks to experiment and train models. To group model training results, you'll use\nexperiments\n. To track model metrics with MLflow when training a model in a notebook, you can use MLflow's logging capabilities.\nCreate an MLflow experiment\nYou can create a MLflow experiment, which allows you to group runs. If you don't create an experiment, MLflow will assume the default experiment with name\nDefault\n.\nTo create an experiment, run the following command in a notebook:\nimport mlflow\n\nmlflow.set_experiment(experiment_name=\"heart-condition-classifier\")\nLog results with MLflow\nNow, you're ready to train your model. To start a run tracked by MLflow, you'll use\nstart_run()\n. Next, to track the model, you can:\nEnable\nautologging\n.\nUse\ncustom logging\n.\nEnable autologging\nMLflow supports automatic logging for popular machine learning libraries. If you're using a library that is supported by  autolog, then MLflow tells the framework you're using to log all the metrics, parameters, artifacts, and models that the framework considers relevant.\nYou can turn on autologging by using the\nautolog\nmethod for the framework you're using. For example, to enable autologging for XGBoost models you can use\nmlflow.xgboost.autolog()\n.\nTip\nFind a list of\nall supported frameworks for autologging in the official MLflow documentation\n.\nA notebook cell that trains and tracks a classification model using autologging may be similar to the following code example:\nfrom xgboost import XGBClassifier\n\nwith mlflow.start_run():\n    mlflow.xgboost.autolog()\n\n    model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\nAs soon as\nmlflow.xgboost.autolog()\nis called, MLflow will start a run within an experiment in Azure Machine Learning to start tracking the experiment's run.\nWhen the job has completed, you can review all logged metrics in the studio.\nUse custom logging\nAdditionally, you can manually log your model with MLflow. Manually logging models is helpful when you want to log supplementary or custom information that isn't logged through autologging.\nNote\nYou can choose to only use custom logging, or use custom logging in combination with autologging.\nCommon functions used with custom logging are:\nmlflow.log_param()\n: Logs a single key-value parameter. Use this function for an input parameter you want to log.\nmlflow.log_metric()\n: Logs a single key-value metric. Value must be a number. Use this function for any output you want to store with the run.\nmlflow.log_artifact()\n: Logs a file. Use this function for any plot you want to log, save as image file first.\nmlflow.log_model()\n: Logs a model. Use this function to create an MLflow model, which may include a custom signature, environment, and input examples.\nTip\nLearn more about how to track models with MLflow by exploring the\nofficial MLflow documentation\n, or the\nAzure Machine Learning documentation\nTo use custom logging in a notebook, start a run and log any metric you want:\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\n\nwith mlflow.start_run():\n    model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n    y_pred = model.predict(X_test)\n\n    accuracy = accuracy_score(y_test, y_pred)\n    mlflow.log_metric(\"accuracy\", accuracy)\nCustom logging gives you more flexibility, but also creates more work as you'll have to define any parameter, metric, or artifact you want to log.\nWhen the job has completed, you can review all logged metrics in the studio.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Train and track models in notebooks"
                },
                {
                  "level": 2,
                  "text": "Create an MLflow experiment"
                },
                {
                  "level": 2,
                  "text": "Log results with MLflow"
                },
                {
                  "level": 3,
                  "text": "Enable autologging"
                },
                {
                  "level": 3,
                  "text": "Use custom logging"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "import mlflow\n\nmlflow.set_experiment(experiment_name=\"heart-condition-classifier\")",
                "import mlflow\n\nmlflow.set_experiment(experiment_name=\"heart-condition-classifier\")",
                "start_run()",
                "mlflow.xgboost.autolog()",
                "from xgboost import XGBClassifier\n\nwith mlflow.start_run():\n    mlflow.xgboost.autolog()\n\n    model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)",
                "from xgboost import XGBClassifier\n\nwith mlflow.start_run():\n    mlflow.xgboost.autolog()\n\n    model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)",
                "mlflow.xgboost.autolog()",
                "mlflow.log_param()",
                "mlflow.log_metric()",
                "mlflow.log_artifact()",
                "mlflow.log_model()",
                "from xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\n\nwith mlflow.start_run():\n    model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n    y_pred = model.predict(X_test)\n\n    accuracy = accuracy_score(y_test, y_pred)\n    mlflow.log_metric(\"accuracy\", accuracy)",
                "from xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score\n\nwith mlflow.start_run():\n    model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n    y_pred = model.predict(X_test)\n\n    accuracy = accuracy_score(y_test, y_pred)\n    mlflow.log_metric(\"accuracy\", accuracy)"
              ],
              "images": [
                {
                  "src": "../../wwl-azure/track-model-training-jupyter-notebooks-mlflow/media/autolog-results.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/track-model-training-jupyter-notebooks-mlflow/media/autolog-results.png",
                  "alt_text": "Screenshot of overview page of MLflow experiment with autologging in Azure Machine Learning studio.",
                  "title": "",
                  "filename": "autolog-results.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Enable autologging",
                    "following_text": "Additionally, you can manually log your model with MLflow. Manually logging models is helpful when you want to log supplementary or custom information that isn't logged through autologging.",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-azure/track-model-training-jupyter-notebooks-mlflow/media/custom-logging.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/track-model-training-jupyter-notebooks-mlflow/media/custom-logging.png",
                  "alt_text": "Screenshot overview page of MLflow experiment run with only custom logging in Azure Machine Learning studio.",
                  "title": "",
                  "filename": "custom-logging.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Use custom logging",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "https://mlflow.org/docs/latest/tracking.html#automatic-logging?azure-portal=true",
                  "text": "all supported frameworks for autologging in the official MLflow documentation"
                },
                {
                  "url": "https://www.mlflow.org/docs/latest/tracking.html?azure-portal=true",
                  "text": "official MLflow documentation"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-log-view-metrics?azure-portal=true",
                  "text": "Azure Machine Learning documentation"
                }
              ]
            },
            {
              "number": 4,
              "title": "Exercise - Track model training",
              "url": "https://learn.microsoft.com/en-us/training/modules/track-model-training-jupyter-notebooks-mlflow/4-exercise-track-model-training",
              "href": "4-exercise-track-model-training",
              "content": "Read in English\nAdd\nAdd to plan\nExercise - Track model training\nCompleted\n10 minutes\nNow, it's your chance to explore how to track models with MLflow in notebooks.\nIn this exercise, you learn how to:\nTrain and track a model with autologging.\nTrain and track a model with custom logging.\nInstructions\nLaunch the exercise and follow the instructions.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Exercise - Track model training"
                },
                {
                  "level": 2,
                  "text": "Instructions"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-azure/track-model-training-jupyter-notebooks-mlflow/media/launch-exercise.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/track-model-training-jupyter-notebooks-mlflow/media/launch-exercise.png",
                  "alt_text": "Button to launch exercise.",
                  "title": "",
                  "filename": "launch-exercise.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Instructions",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 5,
              "title": "Module assessment",
              "url": "https://learn.microsoft.com/en-us/training/modules/track-model-training-jupyter-notebooks-mlflow/5-knowledge-check",
              "href": "5-knowledge-check",
              "content": "Read in English\nAdd\nAdd to plan\nModule assessment\nCompleted\n3 minutes\n1.\nYou want to train a diabetes classification model with the scikit-learn library. You want to focus on experimenting with the model, and minimize the effort needed to log the model's results. Which logging method should you use?\nAutologging\nCustom logging\nA combination of autologging and custom logging.\n2.\nWhen you use MLflow tracking when training a model in a notebook running on Azure Machine Learning compute, on which tab in the studio can you view the model's results?\nData\nModels\nJobs\nYou must answer all questions before checking your work.\nYou must answer all questions before checking your work.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Module assessment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 6,
              "title": "Summary",
              "url": "https://learn.microsoft.com/en-us/training/modules/track-model-training-jupyter-notebooks-mlflow/6-summary",
              "href": "6-summary",
              "content": "Read in English\nAdd\nAdd to plan\nSummary\nCompleted\n1 minute\nIn this module, you've learned how to:\nConfigure to use MLflow in notebooks\nUse MLflow for model tracking in notebooks\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Summary"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "title": "Optimize model training with Azure Machine Learning",
      "url": "https://learn.microsoft.com/en-us/training/paths/use-azure-machine-learning-pipelines-for-automation/",
      "learn_uid": "learn.wwl.use-azure-machine-learning-pipelines-for-automation",
      "modules": [
        {
          "title": "Run a training script as a command job in Azure Machine Learning",
          "url": "https://learn.microsoft.com/en-us/training/modules/run-training-script-command-job-azure-machine-learning/",
          "description": "",
          "learning_objectives": [],
          "prerequisites": [],
          "units": [
            {
              "number": 1,
              "title": "Introduction",
              "url": "https://learn.microsoft.com/en-us/training/modules/run-training-script-command-job-azure-machine-learning/1-introduction",
              "href": "1-introduction",
              "content": "Read in English\nAdd\nAdd to plan\nIntroduction\nCompleted\n2 minutes\nA common challenge when developing machine learning models is to prepare for production scenarios. When you write code to process data and train models, you want the code to be scalable, repeatable, and ready for automation.\nThough notebooks are ideal for experimentation and development, scripts are a better fit for production workloads. In Azure Machine Learning, you can run a script as a\ncommand job\n. When you submit a command job, you can configure various parameters like the input data and the compute environment. Azure Machine Learning also helps you track your work when working with command jobs to make it easier to compare workloads.\nYou'll learn how to run a script as a command job using the Python software development kit (SDK) v2 for Azure Machine Learning.\nLearning objectives\nIn this module, you'll learn how to:\nConvert a notebook to a script.\nTest scripts in a terminal.\nRun a script as a command job.\nUse parameters in a command job.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Introduction"
                },
                {
                  "level": 2,
                  "text": "Learning objectives"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 2,
              "title": "Convert a notebook to a script",
              "url": "https://learn.microsoft.com/en-us/training/modules/run-training-script-command-job-azure-machine-learning/2-convert-notebook-script",
              "href": "2-convert-notebook-script",
              "content": "Read in English\nAdd\nAdd to plan\nConvert a notebook to a script\nCompleted\n9 minutes\nWhen you've used notebooks for experimentation and development, you'll first need to convert a notebook to a script. Alternatively, you might choose to skip using notebooks and work only with scripts. Either way, there are some recommendations when creating scripts to have production-ready code.\nScripts are ideal for testing and automation in your production environment. To create a production-ready script, you'll need to:\nRemove nonessential code.\nRefactor your code into functions.\nTest your script in the terminal.\nRemove all nonessential code\nThe main benefit of using notebooks is being able to quickly explore your data. For example, you can use\nprint()\nand\ndf.describe()\nstatements to explore your data and variables. When you create a script that will be used for automation, you want to avoid including code written for exploratory purposes.\nThe first thing you therefore need to do to convert your code to production code is to remove the nonessential code. Especially when you'll run the code regularly, you want to avoid executing anything nonessential to reduce cost and compute time.\nRefactor your code into functions\nWhen using code in business processes, you want the code to be easy to read so that anyone can maintain it. One common approach to make code easier to read and test is to use functions.\nFor example, you might have used the following example code in a notebook to read and split the data:\n# read and visualize the data\nprint(\"Reading data...\")\ndf = pd.read_csv('diabetes.csv')\ndf.head()\n\n# split data\nprint(\"Splitting data...\")\nX, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\nAs functions also allow you to test parts of your code, you might prefer to create\nmultiple smaller functions\n, rather than one large function. If you want to test a part of your code, you can choose to only test a small part and avoid running more code than necessary.\nYou can refactor the code shown in the example into two functions:\nRead the data\nSplit the data\nAn example of refactored code might be the following:\ndef main(csv_file):\n    # read data\n    df = get_data(csv_file)\n\n    # split data\n    X_train, X_test, y_train, y_test = split_data(df)\n\n# function that reads the data\ndef get_data(path):\n    df = pd.read_csv(path)\n    \n    return df\n\n# function that splits the data\ndef split_data(df):\n    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n\n    return X_train, X_test, y_train, y_test\nNote\nYou may have noticed that nonessential code was also omitted in the refactored code. You may choose to use\nprint\nstatements in production code if you'll review the script's output and you want to ensure all code ran as expected. However, when you know you're not going to review the output of a script in a terminal, it's best to remove any code that has no purpose.\nTest your script\nBefore using scripts in production environments, for example by integrating them with automation pipelines, you'll want to test whether the scripts work as expected.\nOne simple way to test your script, is to run the script in a terminal. Within the Azure Machine Learning workspace, you can quickly run a script in the terminal of the compute instance.\nWhen you open a script in the\nNotebooks\npage of the Azure Machine Learning studio, you can choose to\nsave and run the script in the terminal\n.\nAlternatively, you can navigate directly to the terminal of the compute instance. Navigate to the\nCompute\npage and select the\nTerminal\nof the compute instance you want to use. You can use the following command to run a Python script named\ntrain.py\n:\npython train.py\nOutputs of\nprint\nstatements will show in the terminal. Any possible errors will also appear in the terminal.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Convert a notebook to a script"
                },
                {
                  "level": 2,
                  "text": "Remove all nonessential code"
                },
                {
                  "level": 2,
                  "text": "Refactor your code into functions"
                },
                {
                  "level": 2,
                  "text": "Test your script"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "df.describe()",
                "# read and visualize the data\nprint(\"Reading data...\")\ndf = pd.read_csv('diabetes.csv')\ndf.head()\n\n# split data\nprint(\"Splitting data...\")\nX, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)",
                "# read and visualize the data\nprint(\"Reading data...\")\ndf = pd.read_csv('diabetes.csv')\ndf.head()\n\n# split data\nprint(\"Splitting data...\")\nX, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)",
                "def main(csv_file):\n    # read data\n    df = get_data(csv_file)\n\n    # split data\n    X_train, X_test, y_train, y_test = split_data(df)\n\n# function that reads the data\ndef get_data(path):\n    df = pd.read_csv(path)\n    \n    return df\n\n# function that splits the data\ndef split_data(df):\n    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n\n    return X_train, X_test, y_train, y_test",
                "def main(csv_file):\n    # read data\n    df = get_data(csv_file)\n\n    # split data\n    X_train, X_test, y_train, y_test = split_data(df)\n\n# function that reads the data\ndef get_data(path):\n    df = pd.read_csv(path)\n    \n    return df\n\n# function that splits the data\ndef split_data(df):\n    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n\n    return X_train, X_test, y_train, y_test",
                "python train.py",
                "python train.py"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 3,
              "title": "Run a script as a command job",
              "url": "https://learn.microsoft.com/en-us/training/modules/run-training-script-command-job-azure-machine-learning/3-run-script-command-job",
              "href": "3-run-script-command-job",
              "content": "Read in English\nAdd\nAdd to plan\nRun a script as a command job\nCompleted\n5 minutes\nWhen you have a script that train a machine learning model, you can run it as a command job in Azure Machine Learning.\nConfigure and submit a command job\nTo run a script as a command job, you'll need to configure and submit the job.\nTo configure a command job with the Python SDK (v2), you'll use the\ncommand\nfunction. To run a script, you'll need to specify values for the following parameters:\ncode\n: The folder that includes the script to run.\ncommand\n: Specifies which file to run.\nenvironment\n: The necessary packages to be installed on the compute before running the command.\ncompute\n: The compute to use to run the command.\ndisplay_name\n: The name of the individual job.\nexperiment_name\n: The name of the experiment the job belongs to.\nTip\nLearn more about\nthe\ncommand\nfunction and all possible parameters\nin the reference documentation for the Python SDK (v2).\nYou can configure a command job to run a file named\ntrain.py\n, on the compute cluster named\naml-cluster\nwith the following code:\nfrom azure.ai.ml import command\n\n# configure job\njob = command(\n    code=\"./src\",\n    command=\"python train.py\",\n    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n    compute=\"aml-cluster\",\n    display_name=\"train-model\",\n    experiment_name=\"train-classification-model\"\n    )\nWhen your job is configured, you can submit it, which will initiate the job and run the script:\n# submit job\nreturned_job = ml_client.create_or_update(job)\nYou can monitor and review the job in the Azure Machine Learning studio. All jobs with the same experiment name will be grouped under the same experiment. You can find an individual job using the specified display name.\nAll inputs and outputs of a command job are tracked. You can review which command you specified, which compute was used, and which environment was used to run the script on the specified compute.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Run a script as a command job"
                },
                {
                  "level": 2,
                  "text": "Configure and submit a command job"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "environment",
                "display_name",
                "experiment_name",
                "aml-cluster",
                "from azure.ai.ml import command\n\n# configure job\njob = command(\n    code=\"./src\",\n    command=\"python train.py\",\n    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n    compute=\"aml-cluster\",\n    display_name=\"train-model\",\n    experiment_name=\"train-classification-model\"\n    )",
                "from azure.ai.ml import command\n\n# configure job\njob = command(\n    code=\"./src\",\n    command=\"python train.py\",\n    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n    compute=\"aml-cluster\",\n    display_name=\"train-model\",\n    experiment_name=\"train-classification-model\"\n    )",
                "# submit job\nreturned_job = ml_client.create_or_update(job)",
                "# submit job\nreturned_job = ml_client.create_or_update(job)"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/python/api/azure-ai-ml/azure.ai.ml?azure-portal=true",
                  "text": "thecommandfunction and all possible parameters"
                }
              ]
            },
            {
              "number": 4,
              "title": "Use parameters in a command job",
              "url": "https://learn.microsoft.com/en-us/training/modules/run-training-script-command-job-azure-machine-learning/4-use-parameters-command-job",
              "href": "4-use-parameters-command-job",
              "content": "Read in English\nAdd\nAdd to plan\nUse parameters in a command job\nCompleted\n7 minutes\nYou can increase the flexibility of your scripts by using parameters. For example, you might have created a script that trains a machine learning model. You can use the same script to train a model on different datasets, or using various hyperparameter values.\nWorking with script arguments\nTo use parameters in a script, you must use a library such as\nargparse\nto read arguments passed to the script and assign them to variables.\nFor example, the following script reads an arguments named\ntraining_data\n, which specifies the path to the training data.\n# import libraries\nimport argparse\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\n\ndef main(args):\n    # read data\n    df = get_data(args.training_data)\n\n# function that reads the data\ndef get_data(path):\n    df = pd.read_csv(path)\n    \n    return df\n\ndef parse_args():\n    # setup arg parser\n    parser = argparse.ArgumentParser()\n\n    # add arguments\n    parser.add_argument(\"--training_data\", dest='training_data',\n                        type=str)\n\n    # parse args\n    args = parser.parse_args()\n\n    # return args\n    return args\n\n# run script\nif __name__ == \"__main__\":\n\n    # parse args\n    args = parse_args()\n\n    # run main function\n    main(args)\nAny parameters you expect should be defined in the script. In the script, you can specify what type of value you expect for each parameter and whether you want to set a default value.\nPassing arguments to a script\nTo pass parameter values to a script, you need to provide the argument value in the command.\nFor example, if you would pass a parameter value when running a script in a terminal, you would use the following command:\npython train.py --training_data diabetes.csv\nIn the example,\ndiabetes.csv\nis a local file. Alternatively, you could specify the path to a data asset created in the Azure Machine Learning workspace.\nSimilarly, when you want to pass a parameter value to a script you want to run as a command job, you'll specify the values in the command:\nfrom azure.ai.ml import command\n\n# configure job\njob = command(\n    code=\"./src\",\n    command=\"python train.py --training_data diabetes.csv\",\n    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n    compute=\"aml-cluster\",\n    display_name=\"train-model\",\n    experiment_name=\"train-classification-model\"\n    )\nAfter submitting a command job, you can review the input and output parameters you specified.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Use parameters in a command job"
                },
                {
                  "level": 2,
                  "text": "Working with script arguments"
                },
                {
                  "level": 2,
                  "text": "Passing arguments to a script"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "training_data",
                "# import libraries\nimport argparse\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\n\ndef main(args):\n    # read data\n    df = get_data(args.training_data)\n\n# function that reads the data\ndef get_data(path):\n    df = pd.read_csv(path)\n    \n    return df\n\ndef parse_args():\n    # setup arg parser\n    parser = argparse.ArgumentParser()\n\n    # add arguments\n    parser.add_argument(\"--training_data\", dest='training_data',\n                        type=str)\n\n    # parse args\n    args = parser.parse_args()\n\n    # return args\n    return args\n\n# run script\nif __name__ == \"__main__\":\n\n    # parse args\n    args = parse_args()\n\n    # run main function\n    main(args)",
                "# import libraries\nimport argparse\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\n\ndef main(args):\n    # read data\n    df = get_data(args.training_data)\n\n# function that reads the data\ndef get_data(path):\n    df = pd.read_csv(path)\n    \n    return df\n\ndef parse_args():\n    # setup arg parser\n    parser = argparse.ArgumentParser()\n\n    # add arguments\n    parser.add_argument(\"--training_data\", dest='training_data',\n                        type=str)\n\n    # parse args\n    args = parser.parse_args()\n\n    # return args\n    return args\n\n# run script\nif __name__ == \"__main__\":\n\n    # parse args\n    args = parse_args()\n\n    # run main function\n    main(args)",
                "python train.py --training_data diabetes.csv",
                "python train.py --training_data diabetes.csv",
                "diabetes.csv",
                "from azure.ai.ml import command\n\n# configure job\njob = command(\n    code=\"./src\",\n    command=\"python train.py --training_data diabetes.csv\",\n    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n    compute=\"aml-cluster\",\n    display_name=\"train-model\",\n    experiment_name=\"train-classification-model\"\n    )",
                "from azure.ai.ml import command\n\n# configure job\njob = command(\n    code=\"./src\",\n    command=\"python train.py --training_data diabetes.csv\",\n    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n    compute=\"aml-cluster\",\n    display_name=\"train-model\",\n    experiment_name=\"train-classification-model\"\n    )"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 5,
              "title": "Exercise - Run a training script as a command job",
              "url": "https://learn.microsoft.com/en-us/training/modules/run-training-script-command-job-azure-machine-learning/5-exercise-run-training-script-command-job",
              "href": "5-exercise-run-training-script-command-job",
              "content": "Read in English\nAdd\nAdd to plan\nExercise - Run a training script as a command job\nCompleted\n10 minutes\nNow, it's your chance to run a script as a command job in Azure Machine Learning.\nIn this exercise, you will:\nConvert a notebook to a script.\nTest the script in the terminal.\nRun a script as a command job.\nUse parameters when running a script.\nInstructions\nFollow these instructions to complete the exercise:\nView the exercise repo at\nhttps://microsoftlearning.github.io/mslearn-azure-ml/\n.\nComplete the\nRun a training script as a command job in Azure Machine Learning\nexercise.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Exercise - Run a training script as a command job"
                },
                {
                  "level": 2,
                  "text": "Instructions"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "https://microsoftlearning.github.io/mslearn-azure-ml?azure-portal=true",
                  "text": "https://microsoftlearning.github.io/mslearn-azure-ml/"
                }
              ]
            },
            {
              "number": 6,
              "title": "Module assessment",
              "url": "https://learn.microsoft.com/en-us/training/modules/run-training-script-command-job-azure-machine-learning/6-knowledge-check",
              "href": "6-knowledge-check",
              "content": "Read in English\nAdd\nAdd to plan\nModule assessment\nCompleted\n3 minutes\n1.\nA data scientist wants to run a script as a command job to train a PyTorch model, setting the batch size and learning rate hyperparameters to specified values each time the job runs. What should be done by the data scientist?\nCreate multiple script files  one for each batch size and learning rate combination you want to use.\nSet the batch size and learning rate properties of the command job before submitting the job.\nAdd arguments for batch size and learning rate to the script, and set them in the command property of the command job.\n2.\nA data scientist has trained a model in a notebook. The model should be retrained every week on new data. What should the data scientist do to make the code production-ready?\nCopy and paste the code from each cell to a script.\nConvert the code to one function in a script that reads the data and trains the model.\nConvert the code to multiple functions in a script that read the data and train the model.\nYou must answer all questions before checking your work.\nYou must answer all questions before checking your work.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Module assessment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 7,
              "title": "Summary",
              "url": "https://learn.microsoft.com/en-us/training/modules/run-training-script-command-job-azure-machine-learning/7-summary",
              "href": "7-summary",
              "content": "Read in English\nAdd\nAdd to plan\nSummary\nCompleted\n1 minute\nIn this module, you've learned how to:\nConvert a notebook to a script.\nTest scripts in a terminal.\nRun a script as a command job.\nUse parameters in a command job.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Summary"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            }
          ]
        },
        {
          "title": "Track model training with MLflow in jobs",
          "url": "https://learn.microsoft.com/en-us/training/modules/train-models-training-mlflow-jobs/",
          "description": "",
          "learning_objectives": [],
          "prerequisites": [],
          "units": [
            {
              "number": 1,
              "title": "Introduction",
              "url": "https://learn.microsoft.com/en-us/training/modules/train-models-training-mlflow-jobs/1-introduction",
              "href": "1-introduction",
              "content": "Read in English\nAdd\nAdd to plan\nIntroduction\nCompleted\n3 minutes\nScripts are ideal when you want to run machine learning workloads in production environments. Imagine you're a data scientist who has developed a machine learning model to predict diabetes. The model is performing as expected and you created a training script. The script is used to retrain the model every month when new data has been collected.\nYou'll want to monitor the model's performance over time. You want to understand whether the new data every month benefits the model. Next to tracking models that are trained in notebooks, you can also use\nMLflow\nto track models in scripts.\nMLflow\nis an open-source platform that helps you to track model metrics and artifacts across platforms and is integrated with Azure Machine Learning.\nWhen you use MLflow together with Azure Machine Learning, you can run training scripts locally or in the cloud. You can review model metrics and artifacts in the Azure Machine Learning workspace to compare runs and decide on next steps.\nLearning objectives\nIn this module, you learn how to:\nUse MLflow when you run a script as a job.\nReview metrics, parameters, artifacts, and models from a run.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Introduction"
                },
                {
                  "level": 2,
                  "text": "Learning objectives"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 2,
              "title": "Track metrics with MLflow",
              "url": "https://learn.microsoft.com/en-us/training/modules/train-models-training-mlflow-jobs/2-track-metrics-mlflow",
              "href": "2-track-metrics-mlflow",
              "content": "Read in English\nAdd\nAdd to plan\nTrack metrics with MLflow\nCompleted\n9 minutes\nWhen you train a model with a script, you can include MLflow in the scripts to track any parameters, metrics, and artifacts. When you run the script as a job in Azure Machine Learning, you're able to review all input parameters and outputs for each run.\nUnderstand MLflow\nMLflow is an open-source platform, designed to manage the complete machine learning lifecycle. As it's open source, it can be used when training models on different platforms. Here, we explore how we can integrate MLflow with Azure Machine Learning jobs.\nThere are two options to track machine learning jobs with MLflow:\nEnable autologging using\nmlflow.autolog()\nUse logging functions to track custom metrics using\nmlflow.log_*\nBefore you can use either of these options, you need to set up the environment to use MLflow.\nInclude MLflow in the environment\nTo use MLflow during training job, the\nmlflow\nand\nazureml-mlflow\npip packages need to be installed on the compute executing the script. Therefore, you need to include these two packages in the environment. You can create an environment by referring to a YAML file that describes the Conda environment. As part of the Conda environment, you can include these two packages.\nFor example, in this custom environment\nmlflow\nand\nazureml-mlflow\nare installed using pip:\nname: mlflow-env\nchannels:\n  - conda-forge\ndependencies:\n  - python=3.8\n  - pip\n  - pip:\n    - numpy\n    - pandas\n    - scikit-learn\n    - matplotlib\n    - mlflow\n    - azureml-mlflow\nOnce the environment is defined and registered, make sure to refer to it when submitting a job.\nEnable autologging\nWhen working with one of the common libraries for machine learning, you can enable autologging in MLflow. Autologging logs parameters, metrics, and model artifacts without anyone needing to specify what needs to be logged.\nAutologging is supported for the following libraries:\nScikit-learn\nTensorFlow and Keras\nXGBoost\nLightGBM\nSpark\nFastai\nPytorch\nTo enable autologging, add the following code to your training script:\nimport mlflow\n\nmlflow.autolog()\nLog metrics with MLflow\nIn your training script, you can decide whatever custom metric you want to log with MLflow.\nDepending on the type of value you want to log, use the MLflow command to store the metric with the experiment run:\nmlflow.log_param()\n: Log single key-value parameter. Use this function for an input parameter you want to log.\nmlflow.log_metric()\n: Log single key-value metric. Value must be a number. Use this function for any output you want to store with the run.\nmlflow.log_artifact()\n: Log a file. Use this function for any plot you want to log, save as image file first.\nTo add MLflow to an existing training script, you can add the following code:\nimport mlflow\n\nreg_rate = 0.1\nmlflow.log_param(\"Regularization rate\", reg_rate)\nTip\nFor a complete overview of how to use MLflow Tracking, read the\nMLflow documentation\n.\nSubmit the job\nFinally, you need to submit the training script as a job in Azure Machine Learning. When you use MLflow in a training script and run it as a job, all tracked parameters, metrics, and artifacts are stored with the job run.\nYou configure the job as usual. You only need to make sure that the environment you refer to in the job includes the necessary packages, and the script describes which metrics you want to log.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Track metrics with MLflow"
                },
                {
                  "level": 2,
                  "text": "Understand MLflow"
                },
                {
                  "level": 2,
                  "text": "Include MLflow in the environment"
                },
                {
                  "level": 2,
                  "text": "Enable autologging"
                },
                {
                  "level": 2,
                  "text": "Log metrics with MLflow"
                },
                {
                  "level": 2,
                  "text": "Submit the job"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "mlflow.autolog()",
                "mlflow.log_*",
                "azureml-mlflow",
                "azureml-mlflow",
                "name: mlflow-env\nchannels:\n  - conda-forge\ndependencies:\n  - python=3.8\n  - pip\n  - pip:\n    - numpy\n    - pandas\n    - scikit-learn\n    - matplotlib\n    - mlflow\n    - azureml-mlflow",
                "name: mlflow-env\nchannels:\n  - conda-forge\ndependencies:\n  - python=3.8\n  - pip\n  - pip:\n    - numpy\n    - pandas\n    - scikit-learn\n    - matplotlib\n    - mlflow\n    - azureml-mlflow",
                "import mlflow\n\nmlflow.autolog()",
                "import mlflow\n\nmlflow.autolog()",
                "mlflow.log_param()",
                "mlflow.log_metric()",
                "mlflow.log_artifact()",
                "import mlflow\n\nreg_rate = 0.1\nmlflow.log_param(\"Regularization rate\", reg_rate)",
                "import mlflow\n\nreg_rate = 0.1\nmlflow.log_param(\"Regularization rate\", reg_rate)"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "https://www.mlflow.org/docs/latest/tracking.html",
                  "text": "MLflow documentation"
                }
              ]
            },
            {
              "number": 3,
              "title": "View metrics and evaluate models",
              "url": "https://learn.microsoft.com/en-us/training/modules/train-models-training-mlflow-jobs/3-view-metrics-evaluate-models",
              "href": "3-view-metrics-evaluate-models",
              "content": "Read in English\nAdd\nAdd to plan\nView metrics and evaluate models\nCompleted\n8 minutes\nAfter you've trained and tracked models with MLflow in Azure Machine Learning, you can explore the metrics and evaluate your models.\nReview metrics in the Azure Machine Learning studio.\nRetrieve runs and metrics with MLflow.\nNote\nAzure Machine Learning uses the concept of jobs when you run a script. Multiple job runs in Azure Machine Learning can be grouped within one experiment. MLflow uses a similar syntax where each script is a run, which is part of an experiment.\nView the metrics in the Azure Machine Learning studio\nWhen your job is completed, you can review the logged parameters, metrics, and artifacts in the Azure Machine Learning studio.\nWhen you review job runs in the Azure Machine Learning studio, you'll explore a job run's metrics, which is part of an experiment.\nTo view the metrics through an intuitive user interface, you can:\nOpen the Studio by navigating to\nhttps://ml.azure.com\n.\nFind your experiment run and open it to view its details.\nIn the\nDetails\ntab, all logged parameters are shown under\nParams\n.\nSelect the\nMetrics\ntab and select the metric you want to explore.\nAny plots that are logged as artifacts can be found under\nImages\n.\nThe model assets that can be used to register and deploy the model are stored in the\nmodels\nfolder under\nOutputs + logs\n.\nTip\nRead the documentation to learn more on\nhow to track models with MLflow\n.\nRetrieve metrics with MLflow in a notebook\nWhen you run a training script as a job in Azure Machine Learning, and track your model training with MLflow, you can query the runs in a notebook by using MLflow. Using MLflow in a notebook gives you more control over which runs you want to retrieve to compare.\nWhen using MLflow to query your runs, you'll refer to experiments and runs.\nSearch all the experiments\nYou can get all the active experiments in the workspace using MLFlow:\nexperiments = mlflow.search_experiments(max_results=2)\nfor exp in experiments:\n    print(exp.name)\nIf you want to retrieve archived experiments too, then include the option\nViewType.ALL\n:\nfrom mlflow.entities import ViewType\n\nexperiments = mlflow.search_experiments(view_type=ViewType.ALL)\nfor exp in experiments:\n    print(exp.name)\nTo retrieve a specific experiment, you can run:\nexp = mlflow.get_experiment_by_name(experiment_name)\nprint(exp)\nTip\nExplore the documentation on how to\nsearch experiments with MLflow\nRetrieve runs\nMLflow allows you to search for runs inside of any experiment. You need either the experiment ID or the experiment name.\nFor example, when you want to retrieve the metrics of a specific run:\nmlflow.search_runs(exp.experiment_id)\nYou can search runs across multiple experiments if necessary. Searching across experiments may be useful in case you want to compare runs of the same model when it's being logged in different experiments (by different people or different project iterations).\nYou can use\nsearch_all_experiments=True\nif you want to search across all the experiments in the workspace.\nBy default, experiments are ordered descending by\nstart_time\n, which is the time the experiment was queued in Azure Machine Learning. However, you can change this default by using the parameter\norder_by\n.\nFor example, if you want to sort by start time and only show the last two results:\nmlflow.search_runs(exp.experiment_id, order_by=[\"start_time DESC\"], max_results=2)\nYou can also look for a run with a specific combination in the hyperparameters:\nmlflow.search_runs(\n    exp.experiment_id, filter_string=\"params.num_boost_round='100'\", max_results=2\n)\nTip\nExplore the documentation on how to\nsearch runs with MLflow\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "View metrics and evaluate models"
                },
                {
                  "level": 2,
                  "text": "View the metrics in the Azure Machine Learning studio"
                },
                {
                  "level": 2,
                  "text": "Retrieve metrics with MLflow in a notebook"
                },
                {
                  "level": 3,
                  "text": "Search all the experiments"
                },
                {
                  "level": 3,
                  "text": "Retrieve runs"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "experiments = mlflow.search_experiments(max_results=2)\nfor exp in experiments:\n    print(exp.name)",
                "experiments = mlflow.search_experiments(max_results=2)\nfor exp in experiments:\n    print(exp.name)",
                "ViewType.ALL",
                "from mlflow.entities import ViewType\n\nexperiments = mlflow.search_experiments(view_type=ViewType.ALL)\nfor exp in experiments:\n    print(exp.name)",
                "from mlflow.entities import ViewType\n\nexperiments = mlflow.search_experiments(view_type=ViewType.ALL)\nfor exp in experiments:\n    print(exp.name)",
                "exp = mlflow.get_experiment_by_name(experiment_name)\nprint(exp)",
                "exp = mlflow.get_experiment_by_name(experiment_name)\nprint(exp)",
                "mlflow.search_runs(exp.experiment_id)",
                "mlflow.search_runs(exp.experiment_id)",
                "search_all_experiments=True",
                "mlflow.search_runs(exp.experiment_id, order_by=[\"start_time DESC\"], max_results=2)",
                "mlflow.search_runs(exp.experiment_id, order_by=[\"start_time DESC\"], max_results=2)",
                "mlflow.search_runs(\n    exp.experiment_id, filter_string=\"params.num_boost_round='100'\", max_results=2\n)",
                "mlflow.search_runs(\n    exp.experiment_id, filter_string=\"params.num_boost_round='100'\", max_results=2\n)"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "https://ml.azure.com",
                  "text": "https://ml.azure.com"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-use-mlflow",
                  "text": "how to track models with MLflow"
                },
                {
                  "url": "https://mlflow.org/docs/latest/search-experiments.html?azure-portal=true",
                  "text": "search experiments with MLflow"
                },
                {
                  "url": "https://mlflow.org/docs/latest/search-runs.html?azure-portal=true",
                  "text": "search runs with MLflow"
                }
              ]
            },
            {
              "number": 4,
              "title": "Exercise - Use MLflow to track training jobs",
              "url": "https://learn.microsoft.com/en-us/training/modules/train-models-training-mlflow-jobs/4-exercise-use-mlflow-track-training-jobs",
              "href": "4-exercise-use-mlflow-track-training-jobs",
              "content": "Read in English\nAdd\nAdd to plan\nExercise - Use MLflow to track training jobs\nCompleted\n10 minutes\nNow, it's your chance to explore how to track models with MLflow in scripts.\nIn this exercise, you learn how to:\nTrain and track a model with custom logging.\nTrain and track a model with autologging.\nInstructions\nLaunch the exercise and follow the instructions.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Exercise - Use MLflow to track training jobs"
                },
                {
                  "level": 2,
                  "text": "Instructions"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-azure/train-models-training-mlflow-jobs/media/launch-exercise.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/train-models-training-mlflow-jobs/media/launch-exercise.png",
                  "alt_text": "Button to launch exercise.",
                  "title": "",
                  "filename": "launch-exercise.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Instructions",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 5,
              "title": "Module assessment",
              "url": "https://learn.microsoft.com/en-us/training/modules/train-models-training-mlflow-jobs/5-knowledge-check",
              "href": "5-knowledge-check",
              "content": "Read in English\nAdd\nAdd to plan\nModule assessment\nCompleted\n3 minutes\n1.\nA data scientist trains a regression model and wants to track the model's performance by storing the Root Mean Squared Error (RMSE) with the experiment run. Which method can be used to log the RMSE?\nmlflow.log_param()\nmlflow.log_artifact()\nmlflow.log_metric()\n2.\nWhen a data scientist enables MLflow autologging, where can all model assets be found?\nIn the model folder under\nOutputs + logs\n.\nIn the outputs folder under\nOutputs + logs\n.\nIn the model folder under\nMetrics\n.\nYou must answer all questions before checking your work.\nYou must answer all questions before checking your work.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Module assessment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "mlflow.log_param()",
                "mlflow.log_artifact()",
                "mlflow.log_metric()"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 6,
              "title": "Summary",
              "url": "https://learn.microsoft.com/en-us/training/modules/train-models-training-mlflow-jobs/6-summary",
              "href": "6-summary",
              "content": "Read in English\nAdd\nAdd to plan\nSummary\nCompleted\n1 minute\nIn this module, you've learned how to:\nUse MLflow when you run a script as a job.\nReview metrics, parameters, artifacts, and models from a run.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Summary"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            }
          ]
        },
        {
          "title": "Perform hyperparameter tuning with Azure Machine Learning",
          "url": "https://learn.microsoft.com/en-us/training/modules/perform-hyperparameter-tuning-azure-machine-learning-pipelines/",
          "description": "",
          "learning_objectives": [],
          "prerequisites": [],
          "units": [
            {
              "number": 1,
              "title": "Introduction",
              "url": "https://learn.microsoft.com/en-us/training/modules/perform-hyperparameter-tuning-azure-machine-learning-pipelines/1-introduction",
              "href": "1-introduction",
              "content": "Read in English\nAdd\nAdd to plan\nIntroduction\nCompleted\n3 minutes\nIn machine learning, models are trained to predict unknown labels for new data based on correlations between known labels and features found in the training data. Depending on the algorithm used, you may need to specify\nhyperparameters\nto configure how the model is trained.\nFor example, the\nlogistic regression\nalgorithm uses a\nregularization rate\nhyperparameter to counteract overfitting; and deep learning techniques for convolutional neural networks (CNNs) use hyperparameters like\nlearning rate\nto control how weights are adjusted during training, and\nbatch size\nto determine how many data items are included in each training batch.\nNote\nMachine Learning is an academic field with its own particular terminology. Data scientists refer to the values determined from the training features as\nparameters\n, so a different term is required for values that are used to configure training behavior but which are\nnot\nderived from the training data - hence the term\nhyperparameter\n.\nThe choice of hyperparameter values can significantly affect the resulting model, making it important to select the best possible values for your particular data and predictive performance goals.\nTuning hyperparameters\nHyperparameter tuning\nis accomplished by training the multiple models, using the same algorithm and training data but different hyperparameter values. The resulting model from each training run is then evaluated to determine the performance metric for which you want to optimize (for example,\naccuracy\n), and the best-performing model is selected.\nIn Azure Machine Learning, you can tune hyperparameters by submitting a script as a\nsweep job\n. A sweep job will run a\ntrial\nfor each hyperparameter combination to be tested. Each trial uses a training script with parameterized hyperparameter values to train a model, and logs the target performance metric achieved by the trained model.\nLearning objectives\nIn this module, you'll learn how to:\nDefine a hyperparameter search space.\nConfigure hyperparameter sampling.\nSelect an early-termination policy.\nRun a sweep job.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Introduction"
                },
                {
                  "level": 2,
                  "text": "Tuning hyperparameters"
                },
                {
                  "level": 2,
                  "text": "Learning objectives"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-azure/perform-hyperparameter-tuning-azure-machine-learning-pipelines/media/08-01-hyperdrive.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/perform-hyperparameter-tuning-azure-machine-learning-pipelines/media/08-01-hyperdrive.png",
                  "alt_text": "Diagram of different hyperparameter values resulting in different models by performing hyperparameter tuning.",
                  "title": "",
                  "filename": "08-01-hyperdrive.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Tuning hyperparameters",
                    "following_text": "Hyperparameter tuningis accomplished by training the multiple models, using the same algorithm and training data but different hyperparameter values. The resulting model from each training run is then",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 2,
              "title": "Define a search space",
              "url": "https://learn.microsoft.com/en-us/training/modules/perform-hyperparameter-tuning-azure-machine-learning-pipelines/2-define-search-space",
              "href": "2-define-search-space",
              "content": "Read in English\nAdd\nAdd to plan\nDefine a search space\nCompleted\n5 minutes\nThe set of hyperparameter values tried during hyperparameter tuning is known as the\nsearch space\n. The definition of the range of possible values that can be chosen depends on the type of hyperparameter.\nDiscrete hyperparameters\nSome hyperparameters require\ndiscrete\nvalues - in other words, you must select the value from a particular\nfinite\nset of possibilities. You can define a search space for a discrete parameter using a\nChoice\nfrom a list of explicit values, which you can define as a Python\nlist\n(\nChoice(values=[10,20,30])\n), a\nrange\n(\nChoice(values=range(1,10))\n), or an arbitrary set of comma-separated values (\nChoice(values=(30,50,100))\n)\nYou can also select discrete values from any of the following discrete distributions:\nQUniform(min_value, max_value, q)\n: Returns a value like round(Uniform(min_value, max_value) / q) * q\nQLogUniform(min_value, max_value, q)\n: Returns a value like round(exp(Uniform(min_value, max_value)) / q) * q\nQNormal(mu, sigma, q)\n: Returns a value like round(Normal(mu, sigma) / q) * q\nQLogNormal(mu, sigma, q)\n: Returns a value like round(exp(Normal(mu, sigma)) / q) * q\nContinuous hyperparameters\nSome hyperparameters are\ncontinuous\n- in other words you can use any value along a scale, resulting in an\ninfinite\nnumber of possibilities. To define a search space for these kinds of value, you can use any of the following distribution types:\nUniform(min_value, max_value)\n: Returns a value uniformly distributed between min_value and max_value\nLogUniform(min_value, max_value)\n: Returns a value drawn according to exp(Uniform(min_value, max_value)) so that the logarithm of the return value is uniformly distributed\nNormal(mu, sigma)\n: Returns a real value that's normally distributed with mean mu and standard deviation sigma\nLogNormal(mu, sigma)\n: Returns a value drawn according to exp(Normal(mu, sigma)) so that the logarithm of the return value is normally distributed\nDefining a search space\nTo define a search space for hyperparameter tuning, create a dictionary with the appropriate parameter expression for each named hyperparameter.\nFor example, the following search space indicates that the\nbatch_size\nhyperparameter can have the value 16, 32, or 64, and the\nlearning_rate\nhyperparameter can have any value from a normal distribution with a mean of 10 and a standard deviation of 3.\nfrom azure.ai.ml.sweep import Choice, Normal\n\ncommand_job_for_sweep = job(\n    batch_size=Choice(values=[16, 32, 64]),    \n    learning_rate=Normal(mu=10, sigma=3),\n)\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Define a search space"
                },
                {
                  "level": 2,
                  "text": "Discrete hyperparameters"
                },
                {
                  "level": 2,
                  "text": "Continuous hyperparameters"
                },
                {
                  "level": 2,
                  "text": "Defining a search space"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "Choice(values=[10,20,30])",
                "Choice(values=range(1,10))",
                "Choice(values=(30,50,100))",
                "QUniform(min_value, max_value, q)",
                "QLogUniform(min_value, max_value, q)",
                "QNormal(mu, sigma, q)",
                "QLogNormal(mu, sigma, q)",
                "Uniform(min_value, max_value)",
                "LogUniform(min_value, max_value)",
                "Normal(mu, sigma)",
                "LogNormal(mu, sigma)",
                "learning_rate",
                "from azure.ai.ml.sweep import Choice, Normal\n\ncommand_job_for_sweep = job(\n    batch_size=Choice(values=[16, 32, 64]),    \n    learning_rate=Normal(mu=10, sigma=3),\n)",
                "from azure.ai.ml.sweep import Choice, Normal\n\ncommand_job_for_sweep = job(\n    batch_size=Choice(values=[16, 32, 64]),    \n    learning_rate=Normal(mu=10, sigma=3),\n)"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 3,
              "title": "Configure a sampling method",
              "url": "https://learn.microsoft.com/en-us/training/modules/perform-hyperparameter-tuning-azure-machine-learning-pipelines/3-configure-sampling-method",
              "href": "3-configure-sampling-method",
              "content": "Read in English\nAdd\nAdd to plan\nConfigure a sampling method\nCompleted\n8 minutes\nThe specific values used in a hyperparameter tuning run, or\nsweep job\n, depend on the type of\nsampling\nused.\nThere are three main sampling methods available in Azure Machine Learning:\nGrid sampling\n: Tries every possible combination.\nRandom sampling\n: Randomly chooses values from the search space.\nSobol\n: Adds a seed to random sampling to make the results reproducible.\nBayesian sampling\n: Chooses new values based on previous results.\nNote\nSobol is a variation of random sampling.\nGrid sampling\nGrid sampling can only be applied when all hyperparameters are discrete, and is used to try every possible combination of parameters in the search space.\nFor example, in the following code example, grid sampling is used to try every possible combination of discrete\nbatch_size\nand\nlearning_rate\nvalue:\nfrom azure.ai.ml.sweep import Choice\n\ncommand_job_for_sweep = command_job(\n    batch_size=Choice(values=[16, 32, 64]),\n    learning_rate=Choice(values=[0.01, 0.1, 1.0]),\n)\n\nsweep_job = command_job_for_sweep.sweep(\n    sampling_algorithm = \"grid\",\n    ...\n)\nRandom sampling\nRandom sampling is used to randomly select a value for each hyperparameter, which can be a mix of discrete and continuous values as shown in the following code example:\nfrom azure.ai.ml.sweep import Normal, Uniform\n\ncommand_job_for_sweep = command_job(\n    batch_size=Choice(values=[16, 32, 64]),   \n    learning_rate=Normal(mu=10, sigma=3),\n)\n\nsweep_job = command_job_for_sweep.sweep(\n    sampling_algorithm = \"random\",\n    ...\n)\nSobol\nYou may want to be able to reproduce a random sampling sweep job. If you expect that you do, you can use Sobol instead. Sobol is a type of random sampling that allows you to use a seed. When you add a seed, the sweep job can be reproduced, and the search space distribution is spread more evenly.\nThe following code example shows how to use Sobol by adding a seed and a rule, and using the\nRandomSamplingAlgorithm\nclass:\nfrom azure.ai.ml.sweep import RandomSamplingAlgorithm\n\nsweep_job = command_job_for_sweep.sweep(\n    sampling_algorithm = RandomSamplingAlgorithm(seed=123, rule=\"sobol\"),\n    ...\n)\nBayesian sampling\nBayesian sampling chooses hyperparameter values based on the Bayesian optimization algorithm, which tries to select parameter combinations that will result in improved performance from the previous selection. The following code example shows how to configure Bayesian sampling:\nfrom azure.ai.ml.sweep import Uniform, Choice\n\ncommand_job_for_sweep = job(\n    batch_size=Choice(values=[16, 32, 64]),    \n    learning_rate=Uniform(min_value=0.05, max_value=0.1),\n)\n\nsweep_job = command_job_for_sweep.sweep(\n    sampling_algorithm = \"bayesian\",\n    ...\n)\nYou can only use Bayesian sampling with\nchoice\n,\nuniform\n, and\nquniform\nparameter expressions.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Configure a sampling method"
                },
                {
                  "level": 2,
                  "text": "Grid sampling"
                },
                {
                  "level": 2,
                  "text": "Random sampling"
                },
                {
                  "level": 3,
                  "text": "Sobol"
                },
                {
                  "level": 2,
                  "text": "Bayesian sampling"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "from azure.ai.ml.sweep import Choice\n\ncommand_job_for_sweep = command_job(\n    batch_size=Choice(values=[16, 32, 64]),\n    learning_rate=Choice(values=[0.01, 0.1, 1.0]),\n)\n\nsweep_job = command_job_for_sweep.sweep(\n    sampling_algorithm = \"grid\",\n    ...\n)",
                "from azure.ai.ml.sweep import Choice\n\ncommand_job_for_sweep = command_job(\n    batch_size=Choice(values=[16, 32, 64]),\n    learning_rate=Choice(values=[0.01, 0.1, 1.0]),\n)\n\nsweep_job = command_job_for_sweep.sweep(\n    sampling_algorithm = \"grid\",\n    ...\n)",
                "from azure.ai.ml.sweep import Normal, Uniform\n\ncommand_job_for_sweep = command_job(\n    batch_size=Choice(values=[16, 32, 64]),   \n    learning_rate=Normal(mu=10, sigma=3),\n)\n\nsweep_job = command_job_for_sweep.sweep(\n    sampling_algorithm = \"random\",\n    ...\n)",
                "from azure.ai.ml.sweep import Normal, Uniform\n\ncommand_job_for_sweep = command_job(\n    batch_size=Choice(values=[16, 32, 64]),   \n    learning_rate=Normal(mu=10, sigma=3),\n)\n\nsweep_job = command_job_for_sweep.sweep(\n    sampling_algorithm = \"random\",\n    ...\n)",
                "RandomSamplingAlgorithm",
                "from azure.ai.ml.sweep import RandomSamplingAlgorithm\n\nsweep_job = command_job_for_sweep.sweep(\n    sampling_algorithm = RandomSamplingAlgorithm(seed=123, rule=\"sobol\"),\n    ...\n)",
                "from azure.ai.ml.sweep import RandomSamplingAlgorithm\n\nsweep_job = command_job_for_sweep.sweep(\n    sampling_algorithm = RandomSamplingAlgorithm(seed=123, rule=\"sobol\"),\n    ...\n)",
                "from azure.ai.ml.sweep import Uniform, Choice\n\ncommand_job_for_sweep = job(\n    batch_size=Choice(values=[16, 32, 64]),    \n    learning_rate=Uniform(min_value=0.05, max_value=0.1),\n)\n\nsweep_job = command_job_for_sweep.sweep(\n    sampling_algorithm = \"bayesian\",\n    ...\n)",
                "from azure.ai.ml.sweep import Uniform, Choice\n\ncommand_job_for_sweep = job(\n    batch_size=Choice(values=[16, 32, 64]),    \n    learning_rate=Uniform(min_value=0.05, max_value=0.1),\n)\n\nsweep_job = command_job_for_sweep.sweep(\n    sampling_algorithm = \"bayesian\",\n    ...\n)"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 4,
              "title": "Configure early termination",
              "url": "https://learn.microsoft.com/en-us/training/modules/perform-hyperparameter-tuning-azure-machine-learning-pipelines/4-configure-early-termination",
              "href": "4-configure-early-termination",
              "content": "Read in English\nAdd\nAdd to plan\nConfigure early termination\nCompleted\n8 minutes\nHyperparameter tuning helps you fine-tune your model and select the hyperparameter values that will make your model perform best.\nFor you to find the best model, however, can be a never-ending conquest. You always have to consider whether it's worth the time and expense of testing new hyperparameter values to find a model that may perform better.\nEach trial in a sweep job, a new model is trained with a new combination of hyperparameter values. If training a new model doesn't result in a significantly better model, you may want to stop the sweep job and use the model that performed best so far.\nWhen you configure a sweep job in Azure Machine Learning, you can also set a maximum number of trials. A more sophisticated approach may be to stop a sweep job when newer models don't produce significantly better results. To stop a sweep job based on the performance of the models, you can use an\nearly termination policy\n.\nWhen to use an early termination policy\nWhether you want to use an early termination policy may depend on the search space and sampling method you're working with.\nFor example, you may choose to use a\ngrid sampling\nmethod over a\ndiscrete\nsearch space that results in a maximum of six trials. With six trials, a maximum of six models will be trained and an early termination policy may be unnecessary.\nAn early termination policy can be especially beneficial when working with continuous hyperparameters in your search space. Continuous hyperparameters present an unlimited number of possible values to choose from. You'll most likely want to use an early termination policy when working with continuous hyperparameters and a random or Bayesian sampling method.\nConfigure an early termination policy\nThere are two main parameters when you choose to use an early termination policy:\nevaluation_interval\n: Specifies at which interval you want the policy to be evaluated. Every time the primary metric is logged for a trial counts as an interval.\ndelay_evaluation\n: Specifies when to start evaluating the policy. This parameter allows for at least a minimum of trials to complete without an early termination policy affecting them.\nNew models may continue to perform only slightly better than previous models. To determine the extent to which a model should perform better than previous trials, there are three options for early termination:\nBandit policy\n: Uses a\nslack_factor\n(relative) or\nslack_amount\n(absolute). Any new model must perform within the slack range of the best performing model.\nMedian stopping policy\n: Uses the median of the averages of the primary metric. Any new model must perform better than the median.\nTruncation selection policy\n: Uses a\ntruncation_percentage\n, which is the percentage of lowest performing trials. Any new model must perform better than the lowest performing trials.\nBandit policy\nYou can use a bandit policy to stop a trial if the target performance metric underperforms the best trial so far by a specified margin.\nFor example, the following code applies a bandit policy with a delay of five trials, evaluates the policy at every interval, and allows an absolute slack amount of 0.2.\nfrom azure.ai.ml.sweep import BanditPolicy\n\nsweep_job.early_termination = BanditPolicy(\n    slack_amount = 0.2, \n    delay_evaluation = 5, \n    evaluation_interval = 1\n)\nImagine the primary metric is the accuracy of the model. When after the first five trials, the best performing model has an accuracy of 0.9, any new model needs to perform better than (0.9-0.2) or 0.7. If the new model's accuracy is higher than 0.7, the sweep job will continue. If the new model has an accuracy score lower than 0.7, the policy will terminate the sweep job.\nYou can also apply a bandit policy using a slack\nfactor\n, which compares the performance metric as a ratio rather than an absolute value.\nMedian stopping policy\nA median stopping policy abandons trials where the target performance metric is worse than the median of the running averages for all trials.\nFor example, the following code applies a median stopping policy with a delay of five trials and evaluates the policy at every interval.\nfrom azure.ai.ml.sweep import MedianStoppingPolicy\n\nsweep_job.early_termination = MedianStoppingPolicy(\n    delay_evaluation = 5, \n    evaluation_interval = 1\n)\nImagine the primary metric is the accuracy of the model. When the accuracy is logged for the sixth trial, the metric needs to be higher than the median of the accuracy scores so far. Suppose the median of the accuracy scores so far is 0.82. If the new model's accuracy is higher than 0.82, the sweep job will continue. If the new model has an accuracy score lower than 0.82, the policy will stop the sweep job, and no new models will be trained.\nTruncation selection policy\nA truncation selection policy cancels the lowest performing\nX\n% of trials at each evaluation interval based on the\ntruncation_percentage\nvalue you specify for\nX\n.\nFor example, the following code applies a truncation selection policy with a delay of four trials, evaluates the policy at every interval, and uses a truncation percentage of 20%.\nfrom azure.ai.ml.sweep import TruncationSelectionPolicy\n\nsweep_job.early_termination = TruncationSelectionPolicy(\n    evaluation_interval=1, \n    truncation_percentage=20, \n    delay_evaluation=4 \n)\nImagine the primary metric is the accuracy of the model. When the accuracy is logged for the fifth trial, the metric should\nnot\nbe in the worst 20% of the trials so far. In this case, 20% translates to one trial. In other words, if the fifth trial is\nnot\nthe worst performing model so far, the sweep job will continue. If the fifth trial has the lowest accuracy score of all trials so far, the sweep job will stop.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Configure early termination"
                },
                {
                  "level": 2,
                  "text": "When to use an early termination policy"
                },
                {
                  "level": 2,
                  "text": "Configure an early termination policy"
                },
                {
                  "level": 2,
                  "text": "Bandit policy"
                },
                {
                  "level": 2,
                  "text": "Median stopping policy"
                },
                {
                  "level": 2,
                  "text": "Truncation selection policy"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "evaluation_interval",
                "delay_evaluation",
                "slack_factor",
                "slack_amount",
                "truncation_percentage",
                "from azure.ai.ml.sweep import BanditPolicy\n\nsweep_job.early_termination = BanditPolicy(\n    slack_amount = 0.2, \n    delay_evaluation = 5, \n    evaluation_interval = 1\n)",
                "from azure.ai.ml.sweep import BanditPolicy\n\nsweep_job.early_termination = BanditPolicy(\n    slack_amount = 0.2, \n    delay_evaluation = 5, \n    evaluation_interval = 1\n)",
                "from azure.ai.ml.sweep import MedianStoppingPolicy\n\nsweep_job.early_termination = MedianStoppingPolicy(\n    delay_evaluation = 5, \n    evaluation_interval = 1\n)",
                "from azure.ai.ml.sweep import MedianStoppingPolicy\n\nsweep_job.early_termination = MedianStoppingPolicy(\n    delay_evaluation = 5, \n    evaluation_interval = 1\n)",
                "from azure.ai.ml.sweep import TruncationSelectionPolicy\n\nsweep_job.early_termination = TruncationSelectionPolicy(\n    evaluation_interval=1, \n    truncation_percentage=20, \n    delay_evaluation=4 \n)",
                "from azure.ai.ml.sweep import TruncationSelectionPolicy\n\nsweep_job.early_termination = TruncationSelectionPolicy(\n    evaluation_interval=1, \n    truncation_percentage=20, \n    delay_evaluation=4 \n)"
              ],
              "images": [
                {
                  "src": "../../wwl-azure/perform-hyperparameter-tuning-azure-machine-learning-pipelines/media/bandit-policy.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/perform-hyperparameter-tuning-azure-machine-learning-pipelines/media/bandit-policy.png",
                  "alt_text": "Diagram of two examples when using a bandit policy: one model performs sufficiently good, the other underperforms.",
                  "title": "",
                  "filename": "bandit-policy.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Bandit policy",
                    "following_text": "You can also apply a bandit policy using a slackfactor, which compares the performance metric as a ratio rather than an absolute value.",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-azure/perform-hyperparameter-tuning-azure-machine-learning-pipelines/media/median-stopping.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/perform-hyperparameter-tuning-azure-machine-learning-pipelines/media/median-stopping.png",
                  "alt_text": "Diagram of two examples when using a median stopping policy: one model performs sufficiently good, the other underperforms.",
                  "title": "",
                  "filename": "median-stopping.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Median stopping policy",
                    "following_text": "A truncation selection policy cancels the lowest performingX% of trials at each evaluation interval based on thetruncation_percentagevalue you specify forX.",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-azure/perform-hyperparameter-tuning-azure-machine-learning-pipelines/media/truncation-selection.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/perform-hyperparameter-tuning-azure-machine-learning-pipelines/media/truncation-selection.png",
                  "alt_text": "Diagram of two examples when using a truncation selection policy: one model performs sufficiently good, the other underperforms.",
                  "title": "",
                  "filename": "truncation-selection.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Truncation selection policy",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 5,
              "title": "Use a sweep job for hyperparameter tuning",
              "url": "https://learn.microsoft.com/en-us/training/modules/perform-hyperparameter-tuning-azure-machine-learning-pipelines/5-use-sweep-job-hyperparameter-tuning",
              "href": "5-use-sweep-job-hyperparameter-tuning",
              "content": "Read in English\nAdd\nAdd to plan\nUse a sweep job for hyperparameter tuning\nCompleted\n8 minutes\nIn Azure Machine Learning, you can tune hyperparameters by running a\nsweep job\n.\nCreate a training script for hyperparameter tuning\nTo run a sweep job, you need to create a training script just the way you would do for any other training job, except that your script\nmust\n:\nInclude an argument for each hyperparameter you want to vary.\nLog the target performance metric with\nMLflow\n. A logged metric enables the sweep job to evaluate the performance of the trials it initiates, and identify the one that produces the best performing model.\nNote\nLearn how to\ntrack machine learning experiments and models with MLflow within Azure Machine Learning\n.\nFor example, the following example script trains a logistic regression model using a\n--regularization\nargument to set the\nregularization rate\nhyperparameter, and logs the\naccuracy\nmetric with the name\nAccuracy\n:\nimport argparse\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nimport mlflow\n\n# get regularization hyperparameter\nparser = argparse.ArgumentParser()\nparser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01)\nargs = parser.parse_args()\nreg = args.reg_rate\n\n# load the training dataset\ndata = pd.read_csv(\"data.csv\")\n\n# separate features and labels, and split for training/validatiom\nX = data[['feature1','feature2','feature3','feature4']].values\ny = data['label'].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n\n# train a logistic regression model with the reg hyperparameter\nmodel = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n\n# calculate and log accuracy\ny_hat = model.predict(X_test)\nacc = np.average(y_hat == y_test)\nmlflow.log_metric(\"Accuracy\", acc)\nConfigure and run a sweep job\nTo prepare the sweep job, you must first create a base\ncommand job\nthat specifies which script to run and defines the parameters used by the script:\nfrom azure.ai.ml import command\n\n# configure command job as base\njob = command(\n    code=\"./src\",\n    command=\"python train.py --regularization ${{inputs.reg_rate}}\",\n    inputs={\n        \"reg_rate\": 0.01,\n    },\n    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n    compute=\"aml-cluster\",\n    )\nYou can then override your input parameters with your search space:\nfrom azure.ai.ml.sweep import Choice\n\ncommand_job_for_sweep = job(\n    reg_rate=Choice(values=[0.01, 0.1, 1]),\n)\nFinally, call\nsweep()\non your command job to sweep over your search space:\nfrom azure.ai.ml import MLClient\n\n# apply the sweep parameter to obtain the sweep_job\nsweep_job = command_job_for_sweep.sweep(\n    compute=\"aml-cluster\",\n    sampling_algorithm=\"grid\",\n    primary_metric=\"Accuracy\",\n    goal=\"Maximize\",\n)\n\n# set the name of the sweep job experiment\nsweep_job.experiment_name=\"sweep-example\"\n\n# define the limits for this sweep\nsweep_job.set_limits(max_total_trials=4, max_concurrent_trials=2, timeout=7200)\n\n# submit the sweep\nreturned_sweep_job = ml_client.create_or_update(sweep_job)\nMonitor and review sweep jobs\nYou can monitor sweep jobs in Azure Machine Learning studio. The sweep job will initiate trials for each hyperparameter combination to be tried. For each trial, you can review all logged metrics.\nAdditionally, you can evaluate and compare models by visualizing the trials in the studio. You can adjust each chart to show and compare the hyperparameter values and metrics for each trial.\nTip\nLearn more about how to\nvisualize hyperparameter tuning jobs\n.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Use a sweep job for hyperparameter tuning"
                },
                {
                  "level": 2,
                  "text": "Create a training script for hyperparameter tuning"
                },
                {
                  "level": 2,
                  "text": "Configure and run a sweep job"
                },
                {
                  "level": 2,
                  "text": "Monitor and review sweep jobs"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "--regularization",
                "import argparse\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nimport mlflow\n\n# get regularization hyperparameter\nparser = argparse.ArgumentParser()\nparser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01)\nargs = parser.parse_args()\nreg = args.reg_rate\n\n# load the training dataset\ndata = pd.read_csv(\"data.csv\")\n\n# separate features and labels, and split for training/validatiom\nX = data[['feature1','feature2','feature3','feature4']].values\ny = data['label'].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n\n# train a logistic regression model with the reg hyperparameter\nmodel = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n\n# calculate and log accuracy\ny_hat = model.predict(X_test)\nacc = np.average(y_hat == y_test)\nmlflow.log_metric(\"Accuracy\", acc)",
                "import argparse\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nimport mlflow\n\n# get regularization hyperparameter\nparser = argparse.ArgumentParser()\nparser.add_argument('--regularization', type=float, dest='reg_rate', default=0.01)\nargs = parser.parse_args()\nreg = args.reg_rate\n\n# load the training dataset\ndata = pd.read_csv(\"data.csv\")\n\n# separate features and labels, and split for training/validatiom\nX = data[['feature1','feature2','feature3','feature4']].values\ny = data['label'].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n\n# train a logistic regression model with the reg hyperparameter\nmodel = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n\n# calculate and log accuracy\ny_hat = model.predict(X_test)\nacc = np.average(y_hat == y_test)\nmlflow.log_metric(\"Accuracy\", acc)",
                "from azure.ai.ml import command\n\n# configure command job as base\njob = command(\n    code=\"./src\",\n    command=\"python train.py --regularization ${{inputs.reg_rate}}\",\n    inputs={\n        \"reg_rate\": 0.01,\n    },\n    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n    compute=\"aml-cluster\",\n    )",
                "from azure.ai.ml import command\n\n# configure command job as base\njob = command(\n    code=\"./src\",\n    command=\"python train.py --regularization ${{inputs.reg_rate}}\",\n    inputs={\n        \"reg_rate\": 0.01,\n    },\n    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n    compute=\"aml-cluster\",\n    )",
                "from azure.ai.ml.sweep import Choice\n\ncommand_job_for_sweep = job(\n    reg_rate=Choice(values=[0.01, 0.1, 1]),\n)",
                "from azure.ai.ml.sweep import Choice\n\ncommand_job_for_sweep = job(\n    reg_rate=Choice(values=[0.01, 0.1, 1]),\n)",
                "from azure.ai.ml import MLClient\n\n# apply the sweep parameter to obtain the sweep_job\nsweep_job = command_job_for_sweep.sweep(\n    compute=\"aml-cluster\",\n    sampling_algorithm=\"grid\",\n    primary_metric=\"Accuracy\",\n    goal=\"Maximize\",\n)\n\n# set the name of the sweep job experiment\nsweep_job.experiment_name=\"sweep-example\"\n\n# define the limits for this sweep\nsweep_job.set_limits(max_total_trials=4, max_concurrent_trials=2, timeout=7200)\n\n# submit the sweep\nreturned_sweep_job = ml_client.create_or_update(sweep_job)",
                "from azure.ai.ml import MLClient\n\n# apply the sweep parameter to obtain the sweep_job\nsweep_job = command_job_for_sweep.sweep(\n    compute=\"aml-cluster\",\n    sampling_algorithm=\"grid\",\n    primary_metric=\"Accuracy\",\n    goal=\"Maximize\",\n)\n\n# set the name of the sweep job experiment\nsweep_job.experiment_name=\"sweep-example\"\n\n# define the limits for this sweep\nsweep_job.set_limits(max_total_trials=4, max_concurrent_trials=2, timeout=7200)\n\n# submit the sweep\nreturned_sweep_job = ml_client.create_or_update(sweep_job)"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-use-mlflow-cli-runs?azure-portal=true",
                  "text": "track machine learning experiments and models with MLflow within Azure Machine Learning"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-tune-hyperparameters#visualize-hyperparameter-tuning-jobs?azure-portal=true",
                  "text": "visualize hyperparameter tuning jobs"
                }
              ]
            },
            {
              "number": 6,
              "title": "Exercise - Run a sweep job",
              "url": "https://learn.microsoft.com/en-us/training/modules/perform-hyperparameter-tuning-azure-machine-learning-pipelines/6-exercise-run-sweep-job",
              "href": "6-exercise-run-sweep-job",
              "content": "Read in English\nAdd\nAdd to plan\nExercise - Run a sweep job\nCompleted\n10 minutes\nNow, it's your chance to explore how to tune hyperparameters with a sweep job.\nIn this exercise, you learn how to:\nRun a command job.\nConfigure a sweep job using the command job as a base.\nSubmit the sweep job.\nInstructions\nLaunch the exercise and follow the instructions.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Exercise - Run a sweep job"
                },
                {
                  "level": 2,
                  "text": "Instructions"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-azure/perform-hyperparameter-tuning-azure-machine-learning-pipelines/media/launch-exercise.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/perform-hyperparameter-tuning-azure-machine-learning-pipelines/media/launch-exercise.png",
                  "alt_text": "Button to launch exercise.",
                  "title": "",
                  "filename": "launch-exercise.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Instructions",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 7,
              "title": "Module assessment",
              "url": "https://learn.microsoft.com/en-us/training/modules/perform-hyperparameter-tuning-azure-machine-learning-pipelines/7-knowledge-check",
              "href": "7-knowledge-check",
              "content": "Read in English\nAdd\nAdd to plan\nModule assessment\nCompleted\n3 minutes\n1.\nYou plan to use hyperparameter tuning to find optimal discrete values for a set of hyperparameters. You want to try every possible combination of a set of specified discrete values. Which kind of sampling should you use?\nRandom sampling\nGrid sampling\nBayesian sampling\n2.\nYou're using hyperparameter tuning to train an optimal model based on a target metric named \"AUC\". What should you do in your training script?\nImport the logging package and use a logging.info() statement to log the AUC.\nInclude a print() statement to write the AUC value to the standard output stream.\nUse a mlflow.log_metric() statement to log the AUC value.\nYou must answer all questions before checking your work.\nYou must answer all questions before checking your work.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Module assessment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 8,
              "title": "Summary",
              "url": "https://learn.microsoft.com/en-us/training/modules/perform-hyperparameter-tuning-azure-machine-learning-pipelines/8-summary",
              "href": "8-summary",
              "content": "Read in English\nAdd\nAdd to plan\nSummary\nCompleted\n1 minute\nIn this module, you've learned how to:\nDefine a hyperparameter search space.\nConfigure hyperparameter sampling.\nSelect an early-termination policy.\nRun a sweep job.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Summary"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            }
          ]
        },
        {
          "title": "Run pipelines in Azure Machine Learning",
          "url": "https://learn.microsoft.com/en-us/training/modules/run-pipelines-azure-machine-learning/",
          "description": "",
          "learning_objectives": [],
          "prerequisites": [],
          "units": [
            {
              "number": 1,
              "title": "Introduction",
              "url": "https://learn.microsoft.com/en-us/training/modules/run-pipelines-azure-machine-learning/1-introduction",
              "href": "1-introduction",
              "content": "Read in English\nAdd\nAdd to plan\nIntroduction\nCompleted\n3 minutes\nIn Azure Machine Learning, you can experiment in notebooks and train (and retrain) machine learning models by running scripts as jobs.\nIn an enterprise data science process, you'll want to separate the overall process into individual tasks. You can group tasks together as\npipelines\n. Pipelines are key to implementing an effective\nMachine Learning Operations\n(\nMLOps\n) solution in Azure.\nYou'll learn how to create\ncomponents\nof individual tasks, making it easier to reuse and share code. You'll then combine components into an Azure Machine Learning pipeline, which you'll run as a\npipeline job\n.\nNote\nThe term\npipeline\nis used extensively across various domains, including machine learning and software engineering. In Azure Machine Learning, a pipeline contains steps related to the training of a machine learning model. In Azure DevOps or GitHub, a pipeline can refer to a build or release pipelines, which perform the build and configuration tasks required to deliver software. In Azure Synapse Analytics, a pipeline is used to define the data ingestion and transformation process. The focus of this module is on Azure Machine Learning pipelines. However, bear in mind that it's possible to have pipelines across services interact with each other. For example, an Azure DevOps or Azure Synapse Analytics pipeline can trigger an Azure Machine Learning pipeline.\nTip\nLearn more about MLOps in relation to Azure Machine Learning with\nan introduction to machine learning operations\nLearning objectives\nIn this module, you'll learn how to:\nCreate components.\nBuild an Azure Machine Learning pipeline.\nRun an Azure Machine Learning pipeline.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Introduction"
                },
                {
                  "level": 2,
                  "text": "Learning objectives"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/training/paths/introduction-machine-learn-operations?azure-portal=true",
                  "text": "an introduction to machine learning operations"
                }
              ]
            },
            {
              "number": 2,
              "title": "Create components",
              "url": "https://learn.microsoft.com/en-us/training/modules/run-pipelines-azure-machine-learning/2-create-components",
              "href": "2-create-components",
              "content": "Read in English\nAdd\nAdd to plan\nCreate components\nCompleted\n8 minutes\nComponents\nallow you to create reusable scripts that can easily be shared across users within the same Azure Machine Learning workspace. You can also use components to build an Azure Machine Learning pipeline.\nUse a component\nThere are two main reasons why you'd use components:\nTo build a pipeline.\nTo share ready-to-go code.\nYou'll want to create components when you're\npreparing your code for scale\n. When you're done with experimenting and developing, and ready to move your model to production.\nWithin Azure Machine Learning, you can create a component to store code (in your preferred language) within the workspace. Ideally, you design a component to perform a specific action that is relevant to your machine learning workflow.\nFor example, a component may consist of a Python script that normalizes your data, trains a machine learning model, or evaluates a model.\nComponents can be easily shared to other Azure Machine Learning users, who can reuse components in their own Azure Machine Learning pipelines.\nCreate a component\nA component consists of three parts:\nMetadata\n: Includes the component's name, version, etc.\nInterface\n: Includes the expected input parameters (like a dataset or hyperparameter) and expected output (like metrics and artifacts).\nCommand, code and environment\n: Specifies how to run the code.\nTo create a component, you need two files:\nA script that contains the workflow you want to execute.\nA YAML file to define the metadata, interface, and command, code, and environment of the component.\nYou can create the YAML file, or use the\ncommand_component()\nfunction as a decorator to create the YAML file.\nTip\nHere, we'll focus on creating a YAML file to create a component. Alternatively, learn more about\nhow to create components using\ncommand_component()\n.\nFor example, you may have a Python script\nprep.py\nthat prepares the data by removing missing values and normalizing the data:\n# import libraries\nimport argparse\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nfrom sklearn.preprocessing import MinMaxScaler\n\n# setup arg parser\nparser = argparse.ArgumentParser()\n\n# add arguments\nparser.add_argument(\"--input_data\", dest='input_data',\n                    type=str)\nparser.add_argument(\"--output_data\", dest='output_data',\n                    type=str)\n\n# parse args\nargs = parser.parse_args()\n\n# read the data\ndf = pd.read_csv(args.input_data)\n\n# remove missing values\ndf = df.dropna()\n\n# normalize the data    \nscaler = MinMaxScaler()\nnum_cols = ['feature1','feature2','feature3','feature4']\ndf[num_cols] = scaler.fit_transform(df[num_cols])\n\n# save the data as a csv\noutput_df = df.to_csv(\n    (Path(args.output_data) / \"prepped-data.csv\"), \n    index = False\n)\nTo create a component for the\nprep.py\nscript, you'll need a YAML file\nprep.yml\n:\n$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\nname: prep_data\ndisplay_name: Prepare training data\nversion: 1\ntype: command\ninputs:\n  input_data: \n    type: uri_file\noutputs:\n  output_data:\n    type: uri_file\ncode: ./src\nenvironment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\ncommand: >-\n  python prep.py \n  --input_data ${{inputs.input_data}}\n  --output_data ${{outputs.output_data}}\nNotice that the YAML file refers to the\nprep.py\nscript, which is stored in the\nsrc\nfolder. You can load the component with the following code:\nfrom azure.ai.ml import load_component\nparent_dir = \"\"\n\nloaded_component_prep = load_component(source=parent_dir + \"./prep.yml\")\nWhen you've loaded the component, you can use it in a pipeline or register the component.\nRegister a component\nTo use components in a pipeline, you'll need the script and the YAML file. To make the components accessible to other users in the workspace, you can also register components to the Azure Machine Learning workspace.\nYou can register a component with the following code:\nprep = ml_client.components.create_or_update(prepare_data_component)\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Create components"
                },
                {
                  "level": 2,
                  "text": "Use a component"
                },
                {
                  "level": 2,
                  "text": "Create a component"
                },
                {
                  "level": 2,
                  "text": "Register a component"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "command_component()",
                "command_component()",
                "# import libraries\nimport argparse\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nfrom sklearn.preprocessing import MinMaxScaler\n\n# setup arg parser\nparser = argparse.ArgumentParser()\n\n# add arguments\nparser.add_argument(\"--input_data\", dest='input_data',\n                    type=str)\nparser.add_argument(\"--output_data\", dest='output_data',\n                    type=str)\n\n# parse args\nargs = parser.parse_args()\n\n# read the data\ndf = pd.read_csv(args.input_data)\n\n# remove missing values\ndf = df.dropna()\n\n# normalize the data    \nscaler = MinMaxScaler()\nnum_cols = ['feature1','feature2','feature3','feature4']\ndf[num_cols] = scaler.fit_transform(df[num_cols])\n\n# save the data as a csv\noutput_df = df.to_csv(\n    (Path(args.output_data) / \"prepped-data.csv\"), \n    index = False\n)",
                "# import libraries\nimport argparse\nimport pandas as pd\nimport numpy as np\nfrom pathlib import Path\nfrom sklearn.preprocessing import MinMaxScaler\n\n# setup arg parser\nparser = argparse.ArgumentParser()\n\n# add arguments\nparser.add_argument(\"--input_data\", dest='input_data',\n                    type=str)\nparser.add_argument(\"--output_data\", dest='output_data',\n                    type=str)\n\n# parse args\nargs = parser.parse_args()\n\n# read the data\ndf = pd.read_csv(args.input_data)\n\n# remove missing values\ndf = df.dropna()\n\n# normalize the data    \nscaler = MinMaxScaler()\nnum_cols = ['feature1','feature2','feature3','feature4']\ndf[num_cols] = scaler.fit_transform(df[num_cols])\n\n# save the data as a csv\noutput_df = df.to_csv(\n    (Path(args.output_data) / \"prepped-data.csv\"), \n    index = False\n)",
                "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\nname: prep_data\ndisplay_name: Prepare training data\nversion: 1\ntype: command\ninputs:\n  input_data: \n    type: uri_file\noutputs:\n  output_data:\n    type: uri_file\ncode: ./src\nenvironment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\ncommand: >-\n  python prep.py \n  --input_data ${{inputs.input_data}}\n  --output_data ${{outputs.output_data}}",
                "$schema: https://azuremlschemas.azureedge.net/latest/commandComponent.schema.json\nname: prep_data\ndisplay_name: Prepare training data\nversion: 1\ntype: command\ninputs:\n  input_data: \n    type: uri_file\noutputs:\n  output_data:\n    type: uri_file\ncode: ./src\nenvironment: azureml:AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\ncommand: >-\n  python prep.py \n  --input_data ${{inputs.input_data}}\n  --output_data ${{outputs.output_data}}",
                "from azure.ai.ml import load_component\nparent_dir = \"\"\n\nloaded_component_prep = load_component(source=parent_dir + \"./prep.yml\")",
                "from azure.ai.ml import load_component\nparent_dir = \"\"\n\nloaded_component_prep = load_component(source=parent_dir + \"./prep.yml\")",
                "prep = ml_client.components.create_or_update(prepare_data_component)",
                "prep = ml_client.components.create_or_update(prepare_data_component)"
              ],
              "images": [
                {
                  "src": "../../wwl-azure/run-pipelines-azure-machine-learning/media/01-01-components.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/run-pipelines-azure-machine-learning/media/01-01-components.png",
                  "alt_text": "Screenshot of available components in the Azure Machine Learning workspace.",
                  "title": "",
                  "filename": "01-01-components.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Use a component",
                    "following_text": "A component consists of three parts:",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-create-component-pipeline-python?azure-portal=true",
                  "text": "how to create components usingcommand_component()"
                }
              ]
            },
            {
              "number": 3,
              "title": "Create a pipeline",
              "url": "https://learn.microsoft.com/en-us/training/modules/run-pipelines-azure-machine-learning/3-create-pipeline",
              "href": "3-create-pipeline",
              "content": "Read in English\nAdd\nAdd to plan\nCreate a pipeline\nCompleted\n6 minutes\nIn Azure Machine Learning, a\npipeline\nis a workflow of machine learning tasks in which each task is defined as a\ncomponent\n.\nComponents can be arranged sequentially or in parallel, enabling you to build sophisticated flow logic to orchestrate machine learning operations. Each component can be run on a specific compute target, making it possible to combine different types of processing as required to achieve an overall goal.\nA pipeline can be executed as a process by running the pipeline as a\npipeline job\n. Each component is executed as a\nchild job\nas part of the overall pipeline job.\nBuild a pipeline\nAn Azure Machine Learning pipeline is defined in a YAML file. The YAML file includes the pipeline job name, inputs, outputs, and settings.\nYou can create the YAML file, or use the\n@pipeline()\nfunction to create the YAML file.\nTip\nReview the\nreference documentation for the\n@pipeline()\nfunction\n.\nFor example, if you want to build a pipeline that first prepares the data, and then trains the model, you can use the following code:\nfrom azure.ai.ml.dsl import pipeline\n\n@pipeline()\ndef pipeline_function_name(pipeline_job_input):\n    prep_data = loaded_component_prep(input_data=pipeline_job_input)\n    train_model = loaded_component_train(training_data=prep_data.outputs.output_data)\n\n    return {\n        \"pipeline_job_transformed_data\": prep_data.outputs.output_data,\n        \"pipeline_job_trained_model\": train_model.outputs.model_output,\n    }\nTo pass a registered data asset as the pipeline job input, you can call the function you created with the data asset as input:\nfrom azure.ai.ml import Input\nfrom azure.ai.ml.constants import AssetTypes\n\npipeline_job = pipeline_function_name(\n    Input(type=AssetTypes.URI_FILE, \n    path=\"azureml:data:1\"\n))\nThe\n@pipeline()\nfunction builds a pipeline consisting of two sequential steps, represented by the two loaded components.\nTo understand the pipeline built in the example, let's explore it step by step:\nThe pipeline is built by defining the function\npipeline_function_name\n.\nThe pipeline function expects\npipeline_job_input\nas the overall pipeline input.\nThe first pipeline step requires a value for the input parameter\ninput_data\n. The value for the input will be the value of\npipeline_job_input\n.\nThe first pipeline step is defined by the loaded component for\nprep_data\n.\nThe value of the\noutput_data\nof the first pipeline step is used for the expected input\ntraining_data\nof the second pipeline step.\nThe second pipeline step is defined by the loaded component for\ntrain_model\nand results in a trained model referred to by\nmodel_output\n.\nPipeline outputs are defined by returning variables from the pipeline function.\nThere are two outputs:\npipeline_job_transformed_data\nwith the value of\nprep_data.outputs.output_data\npipeline_job_trained_model\nwith the value of\ntrain_model.outputs.model_output\nThe result of running the\n@pipeline()\nfunction is a YAML file that you can review by printing the\npipeline_job\nobject you created when calling the function:\nprint(pipeline_job)\nThe output will be formatted as a YAML file, which includes the configuration of the pipeline and its components. Some parameters included in the YAML file are shown in the following example.\ndisplay_name: pipeline_function_name\ntype: pipeline\ninputs:\n  pipeline_job_input:\n    type: uri_file\n    path: azureml:data:1\noutputs:\n  pipeline_job_transformed_data: null\n  pipeline_job_trained_model: null\njobs:\n  prep_data:\n    type: command\n    inputs:\n      input_data:\n        path: ${{parent.inputs.pipeline_job_input}}\n    outputs:\n      output_data: ${{parent.outputs.pipeline_job_transformed_data}}\n  train_model:\n    type: command\n    inputs:\n      input_data:\n        path: ${{parent.outputs.pipeline_job_transformed_data}}\n    outputs:\n      output_model: ${{parent.outputs.pipeline_job_trained_model}}\ntags: {}\nproperties: {}\nsettings: {}\nTip\nLearn more about\nthe pipeline job YAML schema to explore which parameters are included when building a component-based pipeline\n.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Create a pipeline"
                },
                {
                  "level": 2,
                  "text": "Build a pipeline"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "@pipeline()",
                "@pipeline()",
                "from azure.ai.ml.dsl import pipeline\n\n@pipeline()\ndef pipeline_function_name(pipeline_job_input):\n    prep_data = loaded_component_prep(input_data=pipeline_job_input)\n    train_model = loaded_component_train(training_data=prep_data.outputs.output_data)\n\n    return {\n        \"pipeline_job_transformed_data\": prep_data.outputs.output_data,\n        \"pipeline_job_trained_model\": train_model.outputs.model_output,\n    }",
                "from azure.ai.ml.dsl import pipeline\n\n@pipeline()\ndef pipeline_function_name(pipeline_job_input):\n    prep_data = loaded_component_prep(input_data=pipeline_job_input)\n    train_model = loaded_component_train(training_data=prep_data.outputs.output_data)\n\n    return {\n        \"pipeline_job_transformed_data\": prep_data.outputs.output_data,\n        \"pipeline_job_trained_model\": train_model.outputs.model_output,\n    }",
                "from azure.ai.ml import Input\nfrom azure.ai.ml.constants import AssetTypes\n\npipeline_job = pipeline_function_name(\n    Input(type=AssetTypes.URI_FILE, \n    path=\"azureml:data:1\"\n))",
                "from azure.ai.ml import Input\nfrom azure.ai.ml.constants import AssetTypes\n\npipeline_job = pipeline_function_name(\n    Input(type=AssetTypes.URI_FILE, \n    path=\"azureml:data:1\"\n))",
                "@pipeline()",
                "pipeline_function_name",
                "pipeline_job_input",
                "pipeline_job_input",
                "output_data",
                "training_data",
                "train_model",
                "model_output",
                "pipeline_job_transformed_data",
                "prep_data.outputs.output_data",
                "pipeline_job_trained_model",
                "train_model.outputs.model_output",
                "@pipeline()",
                "pipeline_job",
                "print(pipeline_job)",
                "print(pipeline_job)",
                "display_name: pipeline_function_name\ntype: pipeline\ninputs:\n  pipeline_job_input:\n    type: uri_file\n    path: azureml:data:1\noutputs:\n  pipeline_job_transformed_data: null\n  pipeline_job_trained_model: null\njobs:\n  prep_data:\n    type: command\n    inputs:\n      input_data:\n        path: ${{parent.inputs.pipeline_job_input}}\n    outputs:\n      output_data: ${{parent.outputs.pipeline_job_transformed_data}}\n  train_model:\n    type: command\n    inputs:\n      input_data:\n        path: ${{parent.outputs.pipeline_job_transformed_data}}\n    outputs:\n      output_model: ${{parent.outputs.pipeline_job_trained_model}}\ntags: {}\nproperties: {}\nsettings: {}",
                "display_name: pipeline_function_name\ntype: pipeline\ninputs:\n  pipeline_job_input:\n    type: uri_file\n    path: azureml:data:1\noutputs:\n  pipeline_job_transformed_data: null\n  pipeline_job_trained_model: null\njobs:\n  prep_data:\n    type: command\n    inputs:\n      input_data:\n        path: ${{parent.inputs.pipeline_job_input}}\n    outputs:\n      output_data: ${{parent.outputs.pipeline_job_transformed_data}}\n  train_model:\n    type: command\n    inputs:\n      input_data:\n        path: ${{parent.outputs.pipeline_job_transformed_data}}\n    outputs:\n      output_model: ${{parent.outputs.pipeline_job_trained_model}}\ntags: {}\nproperties: {}\nsettings: {}"
              ],
              "images": [
                {
                  "src": "../../wwl-azure/run-pipelines-azure-machine-learning/media/pipeline-overview.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/run-pipelines-azure-machine-learning/media/pipeline-overview.png",
                  "alt_text": "Diagram of pipeline structure including all inputs and outputs.",
                  "title": "",
                  "filename": "pipeline-overview.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Build a pipeline",
                    "following_text": "The result of running the@pipeline()function is a YAML file that you can review by printing thepipeline_jobobject you created when calling the function:",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/python/api/azure-ai-ml/azure.ai.ml.dsl?azure-portal=true",
                  "text": "reference documentation for the@pipeline()function"
                },
                {
                  "url": "/en-us/azure/machine-learning/reference-yaml-job-pipeline?azure-portal=true",
                  "text": "the pipeline job YAML schema to explore which parameters are included when building a component-based pipeline"
                }
              ]
            },
            {
              "number": 4,
              "title": "Run a pipeline job",
              "url": "https://learn.microsoft.com/en-us/training/modules/run-pipelines-azure-machine-learning/4-run-pipeline-job",
              "href": "4-run-pipeline-job",
              "content": "Read in English\nAdd\nAdd to plan\nRun a pipeline job\nCompleted\n9 minutes\nWhen you've built a component-based pipeline in Azure Machine Learning, you can run the workflow as a\npipeline job\n.\nConfigure a pipeline job\nA pipeline is defined in a YAML file, which you can also create using the\n@pipeline()\nfunction. After you've used the function, you can edit the pipeline configurations by specifying which parameters you want to change and the new value.\nFor example, you may want to change the output mode for the pipeline job outputs:\n# change the output mode\npipeline_job.outputs.pipeline_job_transformed_data.mode = \"upload\"\npipeline_job.outputs.pipeline_job_trained_model.mode = \"upload\"\nOr, you may want to set the default pipeline compute. When a compute isn't specified for a component, it will use the default compute instead:\n# set pipeline level compute\npipeline_job.settings.default_compute = \"aml-cluster\"\nYou may also want to change the default datastore to where all outputs will be stored:\n# set pipeline level datastore\npipeline_job.settings.default_datastore = \"workspaceblobstore\"\nTo review your pipeline configuration, you can print the pipeline job object:\nprint(pipeline_job)\nRun a pipeline job\nWhen you've configured the pipeline, you're ready to run the workflow as a pipeline job.\nTo submit the pipeline job, run the following code:\n# submit job to workspace\npipeline_job = ml_client.jobs.create_or_update(\n    pipeline_job, experiment_name=\"pipeline_job\"\n)\nAfter you submit a pipeline job, a new job will be created in the Azure Machine Learning workspace. A pipeline job also contains child jobs, which represent the execution of the individual components. The Azure Machine Learning studio creates a graphical representation of your pipeline. You can expand the\nJob overview\nto explore the pipeline parameters, outputs, and child jobs:\nTo troubleshoot a failed pipeline, you can check the outputs and logs of the pipeline job and its child jobs.\nIf there's an issue with the configuration of the pipeline itself, you'll find more information in the outputs and logs of the pipeline job.\nIf there's an issue with the configuration of a component, you'll find more information in the outputs and logs of the child job of the failed component.\nSchedule a pipeline job\nA pipeline is ideal if you want to get your model ready for production. Pipelines are especially useful for automating the retraining of a machine learning model. To automate the retraining of a model, you can schedule a pipeline.\nTo schedule a pipeline job, you'll use the\nJobSchedule\nclass to associate a schedule to a pipeline job.\nThere are various ways to create a schedule. A simple approach is to create a time-based schedule using the\nRecurrenceTrigger\nclass with the following parameters:\nfrequency\n: Unit of time to describe how often the schedule fires. Value can be either\nminute\n,\nhour\n,\nday\n,\nweek\n, or\nmonth\n.\ninterval\n: Number of frequency units to describe how often the schedule fires. Value needs to be an integer.\nTo create a schedule that fires every minute, run the following code:\nfrom azure.ai.ml.entities import RecurrenceTrigger\n\nschedule_name = \"run_every_minute\"\n\nrecurrence_trigger = RecurrenceTrigger(\n    frequency=\"minute\",\n    interval=1,\n)\nTo schedule a pipeline, you'll need\npipeline_job\nto represent the pipeline you've built:\nfrom azure.ai.ml.entities import JobSchedule\n\njob_schedule = JobSchedule(\n    name=schedule_name, trigger=recurrence_trigger, create_job=pipeline_job\n)\n\njob_schedule = ml_client.schedules.begin_create_or_update(\n    schedule=job_schedule\n).result()\nThe display names of the jobs triggered by the schedule will be prefixed with the name of your schedule. You can review the jobs in the Azure Machine Learning studio:\nTo delete a schedule, you first need to disable it:\nml_client.schedules.begin_disable(name=schedule_name).result()\nml_client.schedules.begin_delete(name=schedule_name).result()\nTip\nLearn more about\nthe schedules you can create to trigger pipeline jobs in Azure Machine Learning\n. Or, explore an\nexample notebook to learn how to work with schedules\n.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Run a pipeline job"
                },
                {
                  "level": 2,
                  "text": "Configure a pipeline job"
                },
                {
                  "level": 2,
                  "text": "Run a pipeline job"
                },
                {
                  "level": 2,
                  "text": "Schedule a pipeline job"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "@pipeline()",
                "# change the output mode\npipeline_job.outputs.pipeline_job_transformed_data.mode = \"upload\"\npipeline_job.outputs.pipeline_job_trained_model.mode = \"upload\"",
                "# change the output mode\npipeline_job.outputs.pipeline_job_transformed_data.mode = \"upload\"\npipeline_job.outputs.pipeline_job_trained_model.mode = \"upload\"",
                "# set pipeline level compute\npipeline_job.settings.default_compute = \"aml-cluster\"",
                "# set pipeline level compute\npipeline_job.settings.default_compute = \"aml-cluster\"",
                "# set pipeline level datastore\npipeline_job.settings.default_datastore = \"workspaceblobstore\"",
                "# set pipeline level datastore\npipeline_job.settings.default_datastore = \"workspaceblobstore\"",
                "print(pipeline_job)",
                "print(pipeline_job)",
                "# submit job to workspace\npipeline_job = ml_client.jobs.create_or_update(\n    pipeline_job, experiment_name=\"pipeline_job\"\n)",
                "# submit job to workspace\npipeline_job = ml_client.jobs.create_or_update(\n    pipeline_job, experiment_name=\"pipeline_job\"\n)",
                "JobSchedule",
                "RecurrenceTrigger",
                "from azure.ai.ml.entities import RecurrenceTrigger\n\nschedule_name = \"run_every_minute\"\n\nrecurrence_trigger = RecurrenceTrigger(\n    frequency=\"minute\",\n    interval=1,\n)",
                "from azure.ai.ml.entities import RecurrenceTrigger\n\nschedule_name = \"run_every_minute\"\n\nrecurrence_trigger = RecurrenceTrigger(\n    frequency=\"minute\",\n    interval=1,\n)",
                "pipeline_job",
                "from azure.ai.ml.entities import JobSchedule\n\njob_schedule = JobSchedule(\n    name=schedule_name, trigger=recurrence_trigger, create_job=pipeline_job\n)\n\njob_schedule = ml_client.schedules.begin_create_or_update(\n    schedule=job_schedule\n).result()",
                "from azure.ai.ml.entities import JobSchedule\n\njob_schedule = JobSchedule(\n    name=schedule_name, trigger=recurrence_trigger, create_job=pipeline_job\n)\n\njob_schedule = ml_client.schedules.begin_create_or_update(\n    schedule=job_schedule\n).result()",
                "ml_client.schedules.begin_disable(name=schedule_name).result()\nml_client.schedules.begin_delete(name=schedule_name).result()",
                "ml_client.schedules.begin_disable(name=schedule_name).result()\nml_client.schedules.begin_delete(name=schedule_name).result()"
              ],
              "images": [
                {
                  "src": "../../wwl-azure/run-pipelines-azure-machine-learning/media/pipeline-output.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/run-pipelines-azure-machine-learning/media/pipeline-output.png",
                  "alt_text": "Screenshot of the graphical representation of your pipeline in the Azure Machine Learning studio.",
                  "title": "",
                  "filename": "pipeline-output.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Run a pipeline job",
                    "following_text": "To troubleshoot a failed pipeline, you can check the outputs and logs of the pipeline job and its child jobs.",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-azure/run-pipelines-azure-machine-learning/media/scheduled-jobs.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/run-pipelines-azure-machine-learning/media/scheduled-jobs.png",
                  "alt_text": "Screenshot of the completed jobs scheduled in the Azure Machine Learning studio.",
                  "title": "",
                  "filename": "scheduled-jobs.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Schedule a pipeline job",
                    "following_text": "To delete a schedule, you first need to disable it:",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-schedule-pipeline-job?tabs=python?azure-portal=true",
                  "text": "the schedules you can create to trigger pipeline jobs in Azure Machine Learning"
                },
                {
                  "url": "https://github.com/Azure/azureml-examples/blob/main/sdk/python/schedules/job-schedule.ipynb?azure-portal=true",
                  "text": "example notebook to learn how to work with schedules"
                }
              ]
            },
            {
              "number": 5,
              "title": "Exercise - Run a pipeline job",
              "url": "https://learn.microsoft.com/en-us/training/modules/run-pipelines-azure-machine-learning/5-exercise-run-pipeline-job",
              "href": "5-exercise-run-pipeline-job",
              "content": "Read in English\nAdd\nAdd to plan\nExercise - Run a pipeline job\nCompleted\n10 minutes\nNow, it's your chance to explore how to create and run pipelines in Azure Machine Learning.\nIn this exercise, you learn how to:\nCreate components.\nBuild a pipeline.\nRun a pipeline.\nSchedule a pipeline.\nInstructions\nLaunch the exercise and follow the instructions.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Exercise - Run a pipeline job"
                },
                {
                  "level": 2,
                  "text": "Instructions"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-azure/run-pipelines-azure-machine-learning/media/launch-exercise.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/run-pipelines-azure-machine-learning/media/launch-exercise.png",
                  "alt_text": "Button to launch exercise.",
                  "title": "",
                  "filename": "launch-exercise.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Instructions",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 6,
              "title": "Module assessment",
              "url": "https://learn.microsoft.com/en-us/training/modules/run-pipelines-azure-machine-learning/6-knowledge-check",
              "href": "6-knowledge-check",
              "content": "Read in English\nAdd\nAdd to plan\nModule assessment\nCompleted\n3 minutes\n1.\nYou're creating a pipeline that includes two steps. Step 1 prepares some data, and step 2 uses the preprocessed data to train a model. Which option should you use as input to the second step to train the model?\npipeline_job_input\nprep_data.outputs.output_data\ntrain_model.outputs.model_output\n2.\nYou've built a pipeline that you want to run every week. You want to take a simple approach to creating a schedule. Which class can you use to create the schedule that runs once per week?\nRecurrencePattern\nJobSchedule\nRecurrenceTrigger\nYou must answer all questions before checking your work.\nYou must answer all questions before checking your work.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Module assessment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "pipeline_job_input",
                "prep_data.outputs.output_data",
                "train_model.outputs.model_output"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 7,
              "title": "Summary",
              "url": "https://learn.microsoft.com/en-us/training/modules/run-pipelines-azure-machine-learning/7-summary",
              "href": "7-summary",
              "content": "Read in English\nAdd\nAdd to plan\nSummary\nCompleted\n1 minute\nIn this module, you've learned how to:\nCreate components.\nBuild an Azure Machine Learning pipeline.\nRun an Azure Machine Learning pipeline.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Summary"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "title": "Manage and review models in Azure Machine Learning",
      "url": "https://learn.microsoft.com/en-us/training/paths/manage-review-models-azure-machine-learning/",
      "learn_uid": "learn.wwl.manage-review-models-azure-machine-learning",
      "modules": [
        {
          "title": "Register an MLflow model in Azure Machine Learning",
          "url": "https://learn.microsoft.com/en-us/training/modules/register-mlflow-model-azure-machine-learning/",
          "description": "",
          "learning_objectives": [],
          "prerequisites": [],
          "units": [
            {
              "number": 1,
              "title": "Introduction",
              "url": "https://learn.microsoft.com/en-us/training/modules/register-mlflow-model-azure-machine-learning/1-introduction",
              "href": "1-introduction",
              "content": "Read in English\nAdd\nAdd to plan\nIntroduction\nCompleted\n2 minutes\nAfter training, you want to deploy a machine learning model in order to integrate the model with an application. In Azure Machine Learning, you can easily deploy a model to a batch or online endpoint when you register the model with\nMLflow\n.\nImagine you're a data scientist, working for a company that creates an application for health care practitioners to help diagnose diabetes in patients. The practitioners enter a patient's medical information and expect a response from the application, indicating whether a patient is likely to have diabetes or not.\nYou expect to regularly retrain the model that predicts diabetes. Whenever you have more training data, you want to retrain the model to produce a better performing model. Every time the model is retrained, you want to update the model that is deployed to the endpoint and integrated with the application. By doing so, you're providing the practitioners with the latest version of the model anytime they use the application.\nYou'll learn how to register a model with MLflow in Azure Machine Learning to prepare the model for deployment.\nLearning objectives\nIn this module, you'll learn how to:\nLog models with MLflow.\nUnderstand the MLmodel format.\nRegister an MLflow model in Azure Machine Learning.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Introduction"
                },
                {
                  "level": 2,
                  "text": "Learning objectives"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 2,
              "title": "Log models with MLflow",
              "url": "https://learn.microsoft.com/en-us/training/modules/register-mlflow-model-azure-machine-learning/2-log-mlflow-model",
              "href": "2-log-mlflow-model",
              "content": "Read in English\nAdd\nAdd to plan\nLog models with MLflow\nCompleted\n9 minutes\nTo train a machine learning model, you can choose to use an open source framework that best suits your needs. After training, you want to deploy your model.\nMLflow\nis an open source platform that streamlines machine learning deployment, regardless of the type of model you trained and the framework you used.\nMLflow is integrated with Azure Machine Learning. The integration with Azure Machine Learning allows you to easily deploy models that you train and track with Mlflow. For example, when you have an MLflow model, you can opt for the no-code deployment in Azure Machine Learning.\nNote\nSome types of models are currently not supported by Azure Machine Learning and MLflow. In that case, you can register a\ncustom\nmodel. Learn more about\nhow to work with (custom) models in Azure Machine Learning\n.\nWhy use MLflow?\nWhen you train a machine learning model with Azure Machine Learning, you can use MLflow to register your model. MLflow standardizes the packaging of models, which means that an MLflow model can easily be imported or exported across different workflows.\nFor example, imagine training a model in an Azure Machine Learning workspace used for development. If you want to export the model to another workspace used for production, you can use an MLflow model to easily do so.\nWhen you train and log a model, you store all relevant artifacts in a directory. When you register the model, an\nMLmodel\nfile is created in that directory. The\nMLmodel\nfile contains the model's metadata, which allows for model traceability.\nYou can register models with MLflow by enabling autologging, or by using custom logging.\nNote\nMLflow allows you to log a model as an artifact, or as a model. When you log a model as an artifact, the model is treated as a file. When you log a model as a model, you're adding information to the registered model that enables you to use the model directly in pipelines or deployments. Learn more about\nthe difference between an artifact and a model\nUse autologging to log a model\nWhen you train a model, you can include\nmlflow.autolog()\nto enable autologging. MLflow's autologging automatically logs parameters, metrics, artifacts, and the model you train. The model is logged when the\n.fit()\nmethod is called. The framework you use to train your model is identified and included as the\nflavor\nof your model.\nOptionally, you can specify which flavor you want your model to be identified as by using\nmlflow.<flavor>.autolog()\n. Some common flavors that you can use with autologging are:\nKeras:\nmlflow.keras.autolog()\nScikit-learn:\nmlflow.sklearn.autolog()\nLightGBM:\nmlflow.lightgbm.autolog()\nXGBoost:\nmlflow.xgboost.autolog()\nTensorFlow:\nmlflow.tensorflow.autolog()\nPyTorch:\nmlflow.pytorch.autolog()\nONNX:\nmlflow.onnx.autolog()\nTip\nExplore the complete list of\nMLflow's built-in model flavors\n.\nWhen you use autologging, an output folder is created which includes all necessary model artifacts, including the\nMLmodel\nfile that references these files and includes the model's metadata.\nManually log a model\nWhen you want to have more control over how the model is logged, you can use\nautolog\n(for your parameters, metrics, and other artifacts), and set\nlog_models=False\n. When you set the\nlog_models\nparameter to false, MLflow doesn't automatically log the model, and you can add it manually.\nLogging the model allows you to easily deploy the model. To specify how the model should behave at inference time, you can customize the model's expected inputs and outputs. The schemas of the expected inputs and outputs are defined as the signature in the\nMLmodel\nfile.\nCustomize the signature\nThe model signature defines the schema of the model's inputs and outputs. The signature is stored in JSON format in the\nMLmodel\nfile, together with other metadata of the model.\nThe model signature can be inferred from datasets or created manually by hand.\nTo log a model with a signature that is inferred from your training dataset and model predictions, you can use\ninfer_signature()\n. For example, the following example takes the training dataset to infer the schema of the inputs, and the model's predictions to infer the schema of the output:\nimport pandas as pd\nfrom sklearn import datasets\nfrom sklearn.ensemble import RandomForestClassifier\nimport mlflow\nimport mlflow.sklearn\nfrom mlflow.models.signature import infer_signature\n\niris = datasets.load_iris()\niris_train = pd.DataFrame(iris.data, columns=iris.feature_names)\nclf = RandomForestClassifier(max_depth=7, random_state=0)\nclf.fit(iris_train, iris.target)\n\n# Infer the signature from the training dataset and model's predictions\nsignature = infer_signature(iris_train, clf.predict(iris_train))\n\n# Log the scikit-learn model with the custom signature\nmlflow.sklearn.log_model(clf, \"iris_rf\", signature=signature)\nAlternatively, you can create the signature manually:\nfrom mlflow.models.signature import ModelSignature\nfrom mlflow.types.schema import Schema, ColSpec\n\n# Define the schema for the input data\ninput_schema = Schema([\n  ColSpec(\"double\", \"sepal length (cm)\"),\n  ColSpec(\"double\", \"sepal width (cm)\"),\n  ColSpec(\"double\", \"petal length (cm)\"),\n  ColSpec(\"double\", \"petal width (cm)\"),\n])\n\n# Define the schema for the output data\noutput_schema = Schema([ColSpec(\"long\")])\n\n# Create the signature object\nsignature = ModelSignature(inputs=input_schema, outputs=output_schema)\nNote\nLearn more about\nlogging MLflow models in Azure Machine Learning\nand\nMLflow's model signature\n.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Log models with MLflow"
                },
                {
                  "level": 2,
                  "text": "Why use MLflow?"
                },
                {
                  "level": 2,
                  "text": "Use autologging to log a model"
                },
                {
                  "level": 2,
                  "text": "Manually log a model"
                },
                {
                  "level": 3,
                  "text": "Customize the signature"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "mlflow.autolog()",
                "mlflow.<flavor>.autolog()",
                "mlflow.keras.autolog()",
                "mlflow.sklearn.autolog()",
                "mlflow.lightgbm.autolog()",
                "mlflow.xgboost.autolog()",
                "mlflow.tensorflow.autolog()",
                "mlflow.pytorch.autolog()",
                "mlflow.onnx.autolog()",
                "log_models=False",
                "infer_signature()",
                "import pandas as pd\nfrom sklearn import datasets\nfrom sklearn.ensemble import RandomForestClassifier\nimport mlflow\nimport mlflow.sklearn\nfrom mlflow.models.signature import infer_signature\n\niris = datasets.load_iris()\niris_train = pd.DataFrame(iris.data, columns=iris.feature_names)\nclf = RandomForestClassifier(max_depth=7, random_state=0)\nclf.fit(iris_train, iris.target)\n\n# Infer the signature from the training dataset and model's predictions\nsignature = infer_signature(iris_train, clf.predict(iris_train))\n\n# Log the scikit-learn model with the custom signature\nmlflow.sklearn.log_model(clf, \"iris_rf\", signature=signature)",
                "import pandas as pd\nfrom sklearn import datasets\nfrom sklearn.ensemble import RandomForestClassifier\nimport mlflow\nimport mlflow.sklearn\nfrom mlflow.models.signature import infer_signature\n\niris = datasets.load_iris()\niris_train = pd.DataFrame(iris.data, columns=iris.feature_names)\nclf = RandomForestClassifier(max_depth=7, random_state=0)\nclf.fit(iris_train, iris.target)\n\n# Infer the signature from the training dataset and model's predictions\nsignature = infer_signature(iris_train, clf.predict(iris_train))\n\n# Log the scikit-learn model with the custom signature\nmlflow.sklearn.log_model(clf, \"iris_rf\", signature=signature)",
                "from mlflow.models.signature import ModelSignature\nfrom mlflow.types.schema import Schema, ColSpec\n\n# Define the schema for the input data\ninput_schema = Schema([\n  ColSpec(\"double\", \"sepal length (cm)\"),\n  ColSpec(\"double\", \"sepal width (cm)\"),\n  ColSpec(\"double\", \"petal length (cm)\"),\n  ColSpec(\"double\", \"petal width (cm)\"),\n])\n\n# Define the schema for the output data\noutput_schema = Schema([ColSpec(\"long\")])\n\n# Create the signature object\nsignature = ModelSignature(inputs=input_schema, outputs=output_schema)",
                "from mlflow.models.signature import ModelSignature\nfrom mlflow.types.schema import Schema, ColSpec\n\n# Define the schema for the input data\ninput_schema = Schema([\n  ColSpec(\"double\", \"sepal length (cm)\"),\n  ColSpec(\"double\", \"sepal width (cm)\"),\n  ColSpec(\"double\", \"petal length (cm)\"),\n  ColSpec(\"double\", \"petal width (cm)\"),\n])\n\n# Define the schema for the output data\noutput_schema = Schema([ColSpec(\"long\")])\n\n# Create the signature object\nsignature = ModelSignature(inputs=input_schema, outputs=output_schema)"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-manage-models?azure-portal=true",
                  "text": "how to work with (custom) models in Azure Machine Learning"
                },
                {
                  "url": "/en-us/azure/machine-learning/concept-mlflow-models#the-mlmodel-format?azure-portal=true",
                  "text": "the difference between an artifact and a model"
                },
                {
                  "url": "https://mlflow.org/docs/latest/models.html#built-in-model-flavors?azure-portal=true",
                  "text": "MLflow's built-in model flavors"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-log-mlflow-models?azure-portal=true",
                  "text": "logging MLflow models in Azure Machine Learning"
                },
                {
                  "url": "https://mlflow.org/docs/latest/models.html#model-signature-and-input-example?azure-portal=true",
                  "text": "MLflow's model signature"
                }
              ]
            },
            {
              "number": 3,
              "title": "Understand the MLflow model format",
              "url": "https://learn.microsoft.com/en-us/training/modules/register-mlflow-model-azure-machine-learning/3-understand-mlflow-model-format",
              "href": "3-understand-mlflow-model-format",
              "content": "Read in English\nAdd\nAdd to plan\nUnderstand the MLflow model format\nCompleted\n8 minutes\nMLflow uses the MLModel format to store all relevant model assets in a folder or directory. One essential file in the directory is the\nMLmodel\nfile. The\nMLmodel\nfile is the single source of truth about how the model should be loaded and used.\nExplore the MLmodel file format\nThe\nMLmodel\nfile may include:\nartifact_path\n: During the training job, the model is logged to this path.\nflavor\n: The machine learning library with which the model was created.\nmodel_uuid\n: The unique identifier of the registered model.\nrun_id\n: The unique identifier of job run during which the model was created.\nsignature\n: Specifies the schema of the model's inputs and outputs:\ninputs\n: Valid input to the model. For example, a subset of the training dataset.\noutputs\n: Valid model output. For example, model predictions for the input dataset.\nAn example of a MLmodel file created for a computer vision model trained with\nfastai\nmay look like:\nartifact_path: classifier\nflavors:\n  fastai:\n    data: model.fastai\n    fastai_version: 2.4.1\n  python_function:\n    data: model.fastai\n    env: conda.yaml\n    loader_module: mlflow.fastai\n    python_version: 3.8.12\nmodel_uuid: e694c68eba484299976b06ab9058f636\nrun_id: e13da8ac-b1e6-45d4-a9b2-6a0a5cfac537\nsignature:\n  inputs: '[{\"type\": \"tensor\",\n             \"tensor-spec\": \n                 {\"dtype\": \"uint8\", \"shape\": [-1, 300, 300, 3]}\n           }]'\n  outputs: '[{\"type\": \"tensor\", \n              \"tensor-spec\": \n                 {\"dtype\": \"float32\", \"shape\": [-1,2]}\n            }]'\nThe most important things to set are the\nflavor\nand the\nsignature\n.\nChoose the flavor\nA\nflavor\nis the machine learning library with which the model was created.\nFor example, to create an image classification model to detect breast cancer you're using\nfastai\n. Fastai is a flavor in MLflow that tells you how a model should be persisted and loaded. Because each model flavor indicates how they want to persist and load models, the MLModel format doesn't enforce a single serialization mechanism that all the models need to support. Such a decision allows each flavor to use the methods that provide the best performance or best support according to their best practices - without compromising compatibility with the MLModel standard.\nPython function\nflavor is the\ndefault\nmodel interface for models created from an MLflow run. Any MLflow python model can be loaded as a\npython_function\nmodel, which allows for workflows like deployment to work with any python model regardless of which framework was used to produce the model. This interoperability is immensely powerful as it reduces the time to operationalize in multiple environments.\nAn example of the Python function flavor may look like:\nartifact_path: pipeline\nflavors:\n  python_function:\n    env:\n      conda: conda.yaml\n      virtualenv: python_env.yaml\n    loader_module: mlflow.sklearn\n    model_path: model.pkl\n    predict_fn: predict\n    python_version: 3.8.5\n  sklearn:\n    code: null\n    pickled_model: model.pkl\n    serialization_format: cloudpickle\n    sklearn_version: 1.2.0\nmlflow_version: 2.1.0\nmodel_uuid: b8f9fe56972e48f2b8c958a3afb9c85d\nrun_id: 596d2e7a-c7ed-4596-a4d2-a30755c0bfa5\nsignature:\n  inputs: '[{\"name\": \"age\", \"type\": \"long\"}, {\"name\": \"sex\", \"type\": \"long\"}, {\"name\":\n    \"cp\", \"type\": \"long\"}, {\"name\": \"trestbps\", \"type\": \"long\"}, {\"name\": \"chol\",\n    \"type\": \"long\"}, {\"name\": \"fbs\", \"type\": \"long\"}, {\"name\": \"restecg\", \"type\":\n    \"long\"}, {\"name\": \"thalach\", \"type\": \"long\"}, {\"name\": \"exang\", \"type\": \"long\"},\n    {\"name\": \"oldpeak\", \"type\": \"double\"}, {\"name\": \"slope\", \"type\": \"long\"}, {\"name\":\n    \"ca\", \"type\": \"long\"}, {\"name\": \"thal\", \"type\": \"string\"}]'\n  outputs: '[{\"name\": \"target\", \"type\": \"long\"}]'\nConfigure the signature\nApart from flavors, the\nMLmodel\nfile also contains signatures that serve as data contracts between the model and the server running your model.\nThere are two types of signatures:\nColumn-based\n: used for tabular data with a\npandas.Dataframe\nas inputs.\nTensor-based\n: used for n-dimensional arrays or tensors (often used for unstructured data like text or images), with\nnumpy.ndarray\nas inputs.\nAs the\nMLmodel\nfile is created when you register the model, the signature also is created when you register the model. When you enable MLflow's autologging, the signature is inferred in the best effort way. If you want the signature to be different, you need to manually log the model.\nThe signature's inputs and outputs are important when deploying your model. When you use Azure Machine Learning's no-code deployment for MLflow models, the inputs and outputs set in the signature will be enforced. In other words, when you send data to a deployed MLflow model, the expected inputs and outputs need to match the schema as defined in the signature.\nTip\nLearn more about\nmodel signatures in MLflow\n.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Understand the MLflow model format"
                },
                {
                  "level": 2,
                  "text": "Explore the MLmodel file format"
                },
                {
                  "level": 3,
                  "text": "Choose the flavor"
                },
                {
                  "level": 3,
                  "text": "Configure the signature"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "artifact_path",
                "artifact_path: classifier\nflavors:\n  fastai:\n    data: model.fastai\n    fastai_version: 2.4.1\n  python_function:\n    data: model.fastai\n    env: conda.yaml\n    loader_module: mlflow.fastai\n    python_version: 3.8.12\nmodel_uuid: e694c68eba484299976b06ab9058f636\nrun_id: e13da8ac-b1e6-45d4-a9b2-6a0a5cfac537\nsignature:\n  inputs: '[{\"type\": \"tensor\",\n             \"tensor-spec\": \n                 {\"dtype\": \"uint8\", \"shape\": [-1, 300, 300, 3]}\n           }]'\n  outputs: '[{\"type\": \"tensor\", \n              \"tensor-spec\": \n                 {\"dtype\": \"float32\", \"shape\": [-1,2]}\n            }]'",
                "artifact_path: classifier\nflavors:\n  fastai:\n    data: model.fastai\n    fastai_version: 2.4.1\n  python_function:\n    data: model.fastai\n    env: conda.yaml\n    loader_module: mlflow.fastai\n    python_version: 3.8.12\nmodel_uuid: e694c68eba484299976b06ab9058f636\nrun_id: e13da8ac-b1e6-45d4-a9b2-6a0a5cfac537\nsignature:\n  inputs: '[{\"type\": \"tensor\",\n             \"tensor-spec\": \n                 {\"dtype\": \"uint8\", \"shape\": [-1, 300, 300, 3]}\n           }]'\n  outputs: '[{\"type\": \"tensor\", \n              \"tensor-spec\": \n                 {\"dtype\": \"float32\", \"shape\": [-1,2]}\n            }]'",
                "Python function",
                "python_function",
                "artifact_path: pipeline\nflavors:\n  python_function:\n    env:\n      conda: conda.yaml\n      virtualenv: python_env.yaml\n    loader_module: mlflow.sklearn\n    model_path: model.pkl\n    predict_fn: predict\n    python_version: 3.8.5\n  sklearn:\n    code: null\n    pickled_model: model.pkl\n    serialization_format: cloudpickle\n    sklearn_version: 1.2.0\nmlflow_version: 2.1.0\nmodel_uuid: b8f9fe56972e48f2b8c958a3afb9c85d\nrun_id: 596d2e7a-c7ed-4596-a4d2-a30755c0bfa5\nsignature:\n  inputs: '[{\"name\": \"age\", \"type\": \"long\"}, {\"name\": \"sex\", \"type\": \"long\"}, {\"name\":\n    \"cp\", \"type\": \"long\"}, {\"name\": \"trestbps\", \"type\": \"long\"}, {\"name\": \"chol\",\n    \"type\": \"long\"}, {\"name\": \"fbs\", \"type\": \"long\"}, {\"name\": \"restecg\", \"type\":\n    \"long\"}, {\"name\": \"thalach\", \"type\": \"long\"}, {\"name\": \"exang\", \"type\": \"long\"},\n    {\"name\": \"oldpeak\", \"type\": \"double\"}, {\"name\": \"slope\", \"type\": \"long\"}, {\"name\":\n    \"ca\", \"type\": \"long\"}, {\"name\": \"thal\", \"type\": \"string\"}]'\n  outputs: '[{\"name\": \"target\", \"type\": \"long\"}]'",
                "artifact_path: pipeline\nflavors:\n  python_function:\n    env:\n      conda: conda.yaml\n      virtualenv: python_env.yaml\n    loader_module: mlflow.sklearn\n    model_path: model.pkl\n    predict_fn: predict\n    python_version: 3.8.5\n  sklearn:\n    code: null\n    pickled_model: model.pkl\n    serialization_format: cloudpickle\n    sklearn_version: 1.2.0\nmlflow_version: 2.1.0\nmodel_uuid: b8f9fe56972e48f2b8c958a3afb9c85d\nrun_id: 596d2e7a-c7ed-4596-a4d2-a30755c0bfa5\nsignature:\n  inputs: '[{\"name\": \"age\", \"type\": \"long\"}, {\"name\": \"sex\", \"type\": \"long\"}, {\"name\":\n    \"cp\", \"type\": \"long\"}, {\"name\": \"trestbps\", \"type\": \"long\"}, {\"name\": \"chol\",\n    \"type\": \"long\"}, {\"name\": \"fbs\", \"type\": \"long\"}, {\"name\": \"restecg\", \"type\":\n    \"long\"}, {\"name\": \"thalach\", \"type\": \"long\"}, {\"name\": \"exang\", \"type\": \"long\"},\n    {\"name\": \"oldpeak\", \"type\": \"double\"}, {\"name\": \"slope\", \"type\": \"long\"}, {\"name\":\n    \"ca\", \"type\": \"long\"}, {\"name\": \"thal\", \"type\": \"string\"}]'\n  outputs: '[{\"name\": \"target\", \"type\": \"long\"}]'",
                "pandas.Dataframe",
                "numpy.ndarray"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "https://www.mlflow.org/docs/latest/models.html#model-signature?azure-portal=true",
                  "text": "model signatures in MLflow"
                }
              ]
            },
            {
              "number": 4,
              "title": "Register an MLflow model",
              "url": "https://learn.microsoft.com/en-us/training/modules/register-mlflow-model-azure-machine-learning/4-register-model",
              "href": "4-register-model",
              "content": "Read in English\nAdd\nAdd to plan\nRegister an MLflow model\nCompleted\n7 minutes\nIn Azure Machine Learning, models are trained in jobs. When you want to find the model's artifacts, you can find it in the job's outputs. To more easily manage your models, you can also store a model in the Azure Machine Learning\nmodel registry\n.\nThe model registry makes it easy to organize and keep track of your trained models. When you register a model, you store and version your model in the workspace.\nRegistered models are identified by name and version. Each time you register a model with the same name as an existing one, the registry increments the version. You can also add more metadata tags to more easily search for a specific model.\nTip\nYou can also register models trained outside Azure Machine Learning by providing the local path to the model's artifacts.\nThere are three types of models you can register:\nMLflow\n: Model trained and tracked with MLflow. Recommended for standard use cases.\nCustom\n: Model type with a custom standard not currently supported by Azure Machine Learning.\nTriton\n: Model type for deep learning workloads. Commonly used for TensorFlow and PyTorch model deployments.\nTip\nLearn more about\nDeploy deep learning workloads to production with Azure Machine Learning\nAzure Machine Learning integrates well with MLflow, which is why it's a best practice to log and register an MLflow model. Working with MLflow models makes model management and deployment in Azure Machine Learning easier. During deployment, for example, the environment and scoring script are created for you when using an MLflow model.\nRegister an MLflow model\nTo register an MLflow model, you can use the studio, the Azure CLI, or the Python SDK.\nAs a data scientist, you may be most comfortable working with the Python SDK.\nTo train the model, you can submit a training script as a command job by using the following code:\nfrom azure.ai.ml import command\n\n# configure job\n\njob = command(\n    code=\"./src\",\n    command=\"python train-model-signature.py --training_data diabetes.csv\",\n    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n    compute=\"aml-cluster\",\n    display_name=\"diabetes-train-signature\",\n    experiment_name=\"diabetes-training\"\n    )\n\n# submit job\nreturned_job = ml_client.create_or_update(job)\naml_url = returned_job.studio_url\nprint(\"Monitor your job at\", aml_url)\nOnce the job is completed and the model is trained, use the job name to find the job run and register the model from its outputs.\nfrom azure.ai.ml.entities import Model\nfrom azure.ai.ml.constants import AssetTypes\n\njob_name = returned_job.name\n\nrun_model = Model(\n    path=f\"azureml://jobs/{job_name}/outputs/artifacts/paths/model/\",\n    name=\"mlflow-diabetes\",\n    description=\"Model created from run.\",\n    type=AssetTypes.MLFLOW_MODEL,\n)\n# Uncomment after adding required details above\nml_client.models.create_or_update(run_model)\nAll registered models are listed in the\nModels\npage of the Azure Machine Learning studio. The registered model includes the model's output directory. When you log and register an MLflow model, you can find the\nMLmodel\nfile in the artifacts of the registered model.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Register an MLflow model"
                },
                {
                  "level": 2,
                  "text": "Register an MLflow model"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "from azure.ai.ml import command\n\n# configure job\n\njob = command(\n    code=\"./src\",\n    command=\"python train-model-signature.py --training_data diabetes.csv\",\n    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n    compute=\"aml-cluster\",\n    display_name=\"diabetes-train-signature\",\n    experiment_name=\"diabetes-training\"\n    )\n\n# submit job\nreturned_job = ml_client.create_or_update(job)\naml_url = returned_job.studio_url\nprint(\"Monitor your job at\", aml_url)",
                "from azure.ai.ml import command\n\n# configure job\n\njob = command(\n    code=\"./src\",\n    command=\"python train-model-signature.py --training_data diabetes.csv\",\n    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n    compute=\"aml-cluster\",\n    display_name=\"diabetes-train-signature\",\n    experiment_name=\"diabetes-training\"\n    )\n\n# submit job\nreturned_job = ml_client.create_or_update(job)\naml_url = returned_job.studio_url\nprint(\"Monitor your job at\", aml_url)",
                "from azure.ai.ml.entities import Model\nfrom azure.ai.ml.constants import AssetTypes\n\njob_name = returned_job.name\n\nrun_model = Model(\n    path=f\"azureml://jobs/{job_name}/outputs/artifacts/paths/model/\",\n    name=\"mlflow-diabetes\",\n    description=\"Model created from run.\",\n    type=AssetTypes.MLFLOW_MODEL,\n)\n# Uncomment after adding required details above\nml_client.models.create_or_update(run_model)",
                "from azure.ai.ml.entities import Model\nfrom azure.ai.ml.constants import AssetTypes\n\njob_name = returned_job.name\n\nrun_model = Model(\n    path=f\"azureml://jobs/{job_name}/outputs/artifacts/paths/model/\",\n    name=\"mlflow-diabetes\",\n    description=\"Model created from run.\",\n    type=AssetTypes.MLFLOW_MODEL,\n)\n# Uncomment after adding required details above\nml_client.models.create_or_update(run_model)"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/training/modules/deploy-deep-learning-workloads-to-production-azure-machine-learning/?azure-portal=true",
                  "text": "Deploy deep learning workloads to production with Azure Machine Learning"
                }
              ]
            },
            {
              "number": 5,
              "title": "Exercise - Log and register models with MLflow",
              "url": "https://learn.microsoft.com/en-us/training/modules/register-mlflow-model-azure-machine-learning/5-exercise-register-mlflow-model",
              "href": "5-exercise-register-mlflow-model",
              "content": "Read in English\nAdd\nAdd to plan\nExercise - Log and register models with MLflow\nCompleted\n10 minutes\nNow, it's your chance to explore how to log models with MLflow in Azure Machine Learning.\nIn this exercise, you learn how to:\nLog models with MLflow.\nRegister an MLflow model in the Azure Machine Learning model registry.\nInstructions\nLaunch the exercise and follow the instructions.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Exercise - Log and register models with MLflow"
                },
                {
                  "level": 2,
                  "text": "Instructions"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-azure/register-mlflow-model-azure-machine-learning/media/launch-exercise.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/register-mlflow-model-azure-machine-learning/media/launch-exercise.png",
                  "alt_text": "Button to launch exercise.",
                  "title": "",
                  "filename": "launch-exercise.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Instructions",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 6,
              "title": "Module assessment",
              "url": "https://learn.microsoft.com/en-us/training/modules/register-mlflow-model-azure-machine-learning/6-knowledge-check",
              "href": "6-knowledge-check",
              "content": "Read in English\nAdd\nAdd to plan\nModule assessment\nCompleted\n3 minutes\n1.\nA data scientist trains and logs a model with MLflow. When the data scientist deploys the model, the schema of the model's input and output isn't correct. What should the data scientist customize to fix the issue?\nCustomize the model's environment.\nChange the model's flavor.\nCustomize the model's signature.\n2.\nA data scientist trained a deep learning model with TensorFlow. The deployed model is compute-intensive and needs to use the most optimal inference server for similar workloads. Which model type is compatible with compute-intensive and no-code deployments?\nMLflow\nTriton\nCustom\nYou must answer all questions before checking your work.\nYou must answer all questions before checking your work.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Module assessment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 7,
              "title": "Summary",
              "url": "https://learn.microsoft.com/en-us/training/modules/register-mlflow-model-azure-machine-learning/7-summary",
              "href": "7-summary",
              "content": "Read in English\nAdd\nAdd to plan\nSummary\nCompleted\n1 minute\nIn this module, you've learned how to:\nLog models with MLflow.\nUnderstand the MLmodel format.\nRegister an MLflow model in Azure Machine Learning.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Summary"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            }
          ]
        },
        {
          "title": "Create and explore the Responsible AI dashboard for a model in Azure Machine Learning",
          "url": "https://learn.microsoft.com/en-us/training/modules/manage-compare-models-azure-machine-learning/",
          "description": "",
          "learning_objectives": [],
          "prerequisites": [],
          "units": [
            {
              "number": 1,
              "title": "Introduction",
              "url": "https://learn.microsoft.com/en-us/training/modules/manage-compare-models-azure-machine-learning/1-introduction",
              "href": "1-introduction",
              "content": "Read in English\nAdd\nAdd to plan\nIntroduction\nCompleted\n2 minutes\nWhen you train a machine learning model, you may experiment with multiple models to find the one that best fits your data. To compare and evaluate models, you can review relevant performance metrics. Next to the performance metrics, you should also review whether your models conform to\nresponsible Artificial Intelligence (AI)\nprinciples. Responsible AI is an approach to developing, assessing, and deploying models in a safe, trustworthy, and ethical way.\nTo help you with implementing responsible AI, Azure Machine Learning offers the\nResponsible AI dashboard\n. You can create and customize the Responsible AI dashboard to explore your data and model.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Introduction"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 2,
              "title": "Understand Responsible AI",
              "url": "https://learn.microsoft.com/en-us/training/modules/manage-compare-models-azure-machine-learning/2-understand-responsible-ai",
              "href": "2-understand-responsible-ai",
              "content": "Read in English\nAdd\nAdd to plan\nUnderstand Responsible AI\nCompleted\n4 minutes\nAs a data scientist, you may train a machine learning model to predict whether someone is able to pay back a loan, or whether a candidate is suitable for a job vacancy. As models are often used when making decisions, it's important that the models are unbiased and transparent.\nWhatever you use a model for, you should consider the\nResponsible Artificial Intelligence\n(\nResponsible AI\n) principles. Depending on the use case, you may focus on specific principles. Nevertheless, it's a best practice to consider all principles to ensure you're addressing any issues the model may have.\nMicrosoft has listed five Responsible AI principles:\nFairness and inclusiveness\n: Models should treat everyone fairly and avoid different treatment for similar groups.\nReliability and safety\n: Models should be reliable, safe, and consistent. You want a model to operate as intended, handle unexpected situations well, and resist harmful manipulation.\nPrivacy and security\n: Be transparent about data collection, use, and storage, to empower individuals with control over their data. Treat data with care to ensure an individual's privacy.\nTransparency\n: When models influence important decisions that affect people's lives, people need to understand how those decisions were made and how the model works.\nAccountability\n: Take accountability for decisions that models may influence and maintain human control.\nTip\nLearn about the\nResponsible AI Standard\nfor building AI systems according to the six key principles.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Understand Responsible AI"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2022/06/Microsoft-Responsible-AI-Standard-v2-General-Requirements-3.pdf",
                  "text": "Responsible AI Standard"
                }
              ]
            },
            {
              "number": 3,
              "title": "Create the Responsible AI dashboard",
              "url": "https://learn.microsoft.com/en-us/training/modules/manage-compare-models-azure-machine-learning/3-create-responsible-dashboard",
              "href": "3-create-responsible-dashboard",
              "content": "Read in English\nAdd\nAdd to plan\nCreate the Responsible AI dashboard\nCompleted\n9 minutes\nTo help you implement the\nResponsible Artificial Intelligence\n(\nResponsible AI\n) principles in Azure Machine Learning, you can create the\nResponsible AI dashboard\n.\nThe Responsible AI dashboard allows you to pick and choose insights you need, to evaluate whether your model is safe, trustworthy, and ethical.\nAzure Machine Learning has built-in\ncomponents\nthat can generate Responsible AI insights for you. The insights are then gathered in an interactive dashboard for you to explore. You can also generate a scorecard as PDF to easily share the insights with your colleagues to evaluate your models.\nCreate a Responsible AI dashboard\nTo create a Responsible AI (RAI) dashboard, you need to create a\npipeline\nby using the built-in components. The pipeline should:\nStart with the\nRAI Insights dashboard constructor\n.\nInclude one of the\nRAI tool components\n.\nEnd with\nGather RAI Insights dashboard\nto collect all insights into one dashboard.\nOptionally\nyou can also add the\nGather RAI Insights score card\nat the end of your pipeline.\nExplore the Responsible AI components\nThe available tool components and the insights you can use are:\nAdd Explanation to RAI Insights dashboard\n: Interpret models by generating explanations. Explanations show how much features influence the prediction.\nAdd Causal to RAI Insights dashboard\n: Use historical data to view the causal effects of features on outcomes.\nAdd Counterfactuals to RAI Insights dashboard\n: Explore how a change in input would change the model's output.\nAdd Error Analysis to RAI Insights dashboard\n: Explore the distribution of your data and identify erroneous subgroups of data.\nBuild and run the pipeline to create the Responsible AI dashboard\nTo create the Responsible AI dashboard, you build a pipeline with the components you selected. When you run the pipeline, a Responsible dashboard (and scorecard) is generated and associated with your model.\nAfter you've trained and registered a model in the Azure Machine Learning workspace, you can create the Responsible AI dashboard in three ways:\nUsing the Command Line Interface (CLI) extension for Azure Machine Learning.\nUsing the Python Software Development Kit (SDK).\nUsing the Azure Machine Learning studio for a no-code experience.\nUsing the Python SDK to build and run the pipeline\nTo generate a Responsible AI dashboard, you need to:\nRegister the training and test datasets as MLtable data assets.\nRegister the model.\nRetrieve the built-in components you want to use.\nBuild the pipeline.\nRun the pipeline.\nIf you want to build the pipeline using the Python SDK, you first have to retrieve the components you want to use.\nYou should start the pipeline with the\nRAI Insights dashboard constructor\ncomponent:\nrai_constructor_component = ml_client_registry.components.get(\n    name=\"microsoft_azureml_rai_tabular_insight_constructor\", label=\"latest\"\n)\nThen, you can add any of the available insights, like the explanations, by retrieving the\nAdd Explanation to RAI Insights dashboard component\n:\nrai_explanation_component = ml_client_registry.components.get(\n    name=\"microsoft_azureml_rai_tabular_explanation\", label=\"latest\"\n)\nNote\nThe parameters and expected inputs vary across components.\nExplore the component for the specific insights\nyou want to add to your dashboard to find which inputs you need to specify.\nAnd finally, your pipeline should end with a\nGather RAI Insights dashboard\ncomponent:\nrai_gather_component = ml_client_registry.components.get(\n    name=\"microsoft_azureml_rai_tabular_insight_gather\", label=\"latest\"\n)\nOnce you have the components, you can build the pipeline:\nfrom azure.ai.ml import Input, dsl\nfrom azure.ai.ml.constants import AssetTypes\n\n@dsl.pipeline(\n    compute=\"aml-cluster\",\n    experiment_name=\"Create RAI Dashboard\",\n)\ndef rai_decision_pipeline(\n    target_column_name, train_data, test_data\n):\n    # Initiate the RAIInsights\n    create_rai_job = rai_constructor_component(\n        title=\"RAI dashboard diabetes\",\n        task_type=\"classification\",\n        model_info=expected_model_id,\n        model_input=Input(type=AssetTypes.MLFLOW_MODEL, path=azureml_model_id),\n        train_dataset=train_data,\n        test_dataset=test_data,\n        target_column_name=\"Predictions\",\n    )\n    create_rai_job.set_limits(timeout=30)\n\n    # Add explanations\n    explanation_job = rai_explanation_component(\n        rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\n        comment=\"add explanation\", \n    )\n    explanation_job.set_limits(timeout=10)\n\n    # Combine everything\n    rai_gather_job = rai_gather_component(\n        constructor=create_rai_job.outputs.rai_insights_dashboard,\n        insight=explanation_job.outputs.explanation,\n    )\n    rai_gather_job.set_limits(timeout=10)\n\n    rai_gather_job.outputs.dashboard.mode = \"upload\"\n\n    return {\n        \"dashboard\": rai_gather_job.outputs.dashboard,\n    }\nExploring the Responsible AI dashboard\nAfter building the pipeline, you need to run it to generate the Responsible AI dashboard. When the pipeline successfully completed, you can select to\nview\nthe Responsible AI dashboard from the pipeline overview.\nAlternatively, you can find the Responsible AI dashboard in the\nResponsible AI\ntab of the registered model.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Create the Responsible AI dashboard"
                },
                {
                  "level": 2,
                  "text": "Create a Responsible AI dashboard"
                },
                {
                  "level": 2,
                  "text": "Explore the Responsible AI components"
                },
                {
                  "level": 2,
                  "text": "Build and run the pipeline to create the Responsible AI dashboard"
                },
                {
                  "level": 3,
                  "text": "Using the Python SDK to build and run the pipeline"
                },
                {
                  "level": 2,
                  "text": "Exploring the Responsible AI dashboard"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "RAI Insights dashboard constructor",
                "Gather RAI Insights dashboard",
                "Gather RAI Insights score card",
                "Add Explanation to RAI Insights dashboard",
                "Add Causal to RAI Insights dashboard",
                "Add Counterfactuals to RAI Insights dashboard",
                "Add Error Analysis to RAI Insights dashboard",
                "RAI Insights dashboard constructor",
                "rai_constructor_component = ml_client_registry.components.get(\n    name=\"microsoft_azureml_rai_tabular_insight_constructor\", label=\"latest\"\n)",
                "rai_constructor_component = ml_client_registry.components.get(\n    name=\"microsoft_azureml_rai_tabular_insight_constructor\", label=\"latest\"\n)",
                "Add Explanation to RAI Insights dashboard component",
                "rai_explanation_component = ml_client_registry.components.get(\n    name=\"microsoft_azureml_rai_tabular_explanation\", label=\"latest\"\n)",
                "rai_explanation_component = ml_client_registry.components.get(\n    name=\"microsoft_azureml_rai_tabular_explanation\", label=\"latest\"\n)",
                "Gather RAI Insights dashboard",
                "rai_gather_component = ml_client_registry.components.get(\n    name=\"microsoft_azureml_rai_tabular_insight_gather\", label=\"latest\"\n)",
                "rai_gather_component = ml_client_registry.components.get(\n    name=\"microsoft_azureml_rai_tabular_insight_gather\", label=\"latest\"\n)",
                "from azure.ai.ml import Input, dsl\nfrom azure.ai.ml.constants import AssetTypes\n\n@dsl.pipeline(\n    compute=\"aml-cluster\",\n    experiment_name=\"Create RAI Dashboard\",\n)\ndef rai_decision_pipeline(\n    target_column_name, train_data, test_data\n):\n    # Initiate the RAIInsights\n    create_rai_job = rai_constructor_component(\n        title=\"RAI dashboard diabetes\",\n        task_type=\"classification\",\n        model_info=expected_model_id,\n        model_input=Input(type=AssetTypes.MLFLOW_MODEL, path=azureml_model_id),\n        train_dataset=train_data,\n        test_dataset=test_data,\n        target_column_name=\"Predictions\",\n    )\n    create_rai_job.set_limits(timeout=30)\n\n    # Add explanations\n    explanation_job = rai_explanation_component(\n        rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\n        comment=\"add explanation\", \n    )\n    explanation_job.set_limits(timeout=10)\n\n    # Combine everything\n    rai_gather_job = rai_gather_component(\n        constructor=create_rai_job.outputs.rai_insights_dashboard,\n        insight=explanation_job.outputs.explanation,\n    )\n    rai_gather_job.set_limits(timeout=10)\n\n    rai_gather_job.outputs.dashboard.mode = \"upload\"\n\n    return {\n        \"dashboard\": rai_gather_job.outputs.dashboard,\n    }",
                "from azure.ai.ml import Input, dsl\nfrom azure.ai.ml.constants import AssetTypes\n\n@dsl.pipeline(\n    compute=\"aml-cluster\",\n    experiment_name=\"Create RAI Dashboard\",\n)\ndef rai_decision_pipeline(\n    target_column_name, train_data, test_data\n):\n    # Initiate the RAIInsights\n    create_rai_job = rai_constructor_component(\n        title=\"RAI dashboard diabetes\",\n        task_type=\"classification\",\n        model_info=expected_model_id,\n        model_input=Input(type=AssetTypes.MLFLOW_MODEL, path=azureml_model_id),\n        train_dataset=train_data,\n        test_dataset=test_data,\n        target_column_name=\"Predictions\",\n    )\n    create_rai_job.set_limits(timeout=30)\n\n    # Add explanations\n    explanation_job = rai_explanation_component(\n        rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\n        comment=\"add explanation\", \n    )\n    explanation_job.set_limits(timeout=10)\n\n    # Combine everything\n    rai_gather_job = rai_gather_component(\n        constructor=create_rai_job.outputs.rai_insights_dashboard,\n        insight=explanation_job.outputs.explanation,\n    )\n    rai_gather_job.set_limits(timeout=10)\n\n    rai_gather_job.outputs.dashboard.mode = \"upload\"\n\n    return {\n        \"dashboard\": rai_gather_job.outputs.dashboard,\n    }"
              ],
              "images": [
                {
                  "src": "../../wwl-azure/manage-compare-models-azure-machine-learning/media/responsible-pipeline.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/manage-compare-models-azure-machine-learning/media/responsible-pipeline.png",
                  "alt_text": "Screenshot of completed pipeline to create Responsible AI dashboard.",
                  "title": "",
                  "filename": "responsible-pipeline.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Exploring the Responsible AI dashboard",
                    "following_text": "Alternatively, you can find the Responsible AI dashboard in theResponsible AItab of the registered model.",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-azure/manage-compare-models-azure-machine-learning/media/responsible-model.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/manage-compare-models-azure-machine-learning/media/responsible-model.png",
                  "alt_text": "Screenshot of the Responsible AI tab of the registered model in the Azure Machine Learning studio.",
                  "title": "",
                  "filename": "responsible-model.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Exploring the Responsible AI dashboard",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-responsible-ai-insights-sdk-cli?view=azureml-api-2&tabs=python?azure-portal=true",
                  "text": "Explore the component for the specific insights"
                }
              ]
            },
            {
              "number": 4,
              "title": "Evaluate the Responsible AI dashboard",
              "url": "https://learn.microsoft.com/en-us/training/modules/manage-compare-models-azure-machine-learning/4-explore-responsible-dashboard",
              "href": "4-explore-responsible-dashboard",
              "content": "Read in English\nAdd\nAdd to plan\nEvaluate the Responsible AI dashboard\nCompleted\n6 minutes\nWhen your Responsible AI dashboard is generated, you can explore its contents in the Azure Machine Learning studio to evaluate your model.\nWhen you open the Responsible AI dashboard, the studio tries to automatically connect it to a compute instance. The compute instance provides the necessary compute for interactive exploration within the dashboard.\nThe output of each component you added to the pipeline is reflected in the dashboard. Depending on the components you selected, you can find the following insights in your Responsible AI dashboard:\nError analysis\nExplanations\nCounterfactuals\nCausal analysis\nLet's explore what we can review for each of these insights.\nExplore error analysis\nA model is expected to make false predictions, or errors. With the error analysis feature in the Responsible AI dashboard, you can review and understand how errors are distributed in your dataset. For example, are there specific subgroups, or cohorts, in your dataset for which the model makes more false predictions?\nWhen you include error analysis, there are two types of visuals you can explore in the Responsible AI dashboard:\nError tree map\n: Allows you to explore which combination of subgroups results in the model making more false predictions.\nError heat map\n: Presents a grid overview of a model's errors over the scale of one or two features.\nExplore explanations\nWhenever you use a model for decision-making, you want to understand how a model reaches a certain prediction. Whenever you've trained a model that is too complex to understand, you can run\nmodel explainers\nto calculate the\nfeature importance\n. In other words, you want to understand how each of the input features influences the model's prediction.\nThere are\nvarious statistical techniques\nyou can use as model explainers. Most commonly, the\nmimic\nexplainer trains a simple interpretable model on the same data and task. As a result, you can explore two types of feature importance:\nAggregate feature importance\n: Shows how each feature in the test data influences the model's predictions\noverall\n.\nIndividual feature importance\n: Shows how each feature impacts an\nindividual\nprediction.\nExplore counterfactuals\nExplanations can give you insights into the relative importance of features on the model's predictions. Sometimes, you may want to take it a step further and understand whether the model's predictions would change if the input would be different. To explore how the model's output would change based on a change in the input, you can use\ncounterfactuals\n.\nYou can choose to explore counterfactuals\nwhat-if\nexamples by selecting a data point and the desired model's prediction for that point. When you create a what-if counterfactual, the dashboard opens a panel to help you understand which input would result in the desired prediction.\nExplore causal analysis\nExplanations and counterfactuals help you to understand the model's predictions and the effects of features on the predictions. Though model interpretability may already be a goal by itself, you may also need more information to help you improve decision-making.\nCausal analysis\nuses statistical techniques to estimate the average effect of a feature on a desired prediction. It analyzes how certain interventions or treatments may result in a better outcome, across a population or for a specific individual.\nThere are three available tabs in the Responsible AI dashboard when including causal analysis:\nAggregate causal effects\n: Shows the average causal effects for predefined treatment features (the features you want to change to optimize the model's predictions).\nIndividual causal effects\n: Shows individual data points and allows you to change the treatment features to explore their influence on the prediction.\nTreatment policy\n: Shows which parts of your data points benefit most from a treatment.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Evaluate the Responsible AI dashboard"
                },
                {
                  "level": 3,
                  "text": "Explore error analysis"
                },
                {
                  "level": 3,
                  "text": "Explore explanations"
                },
                {
                  "level": 3,
                  "text": "Explore counterfactuals"
                },
                {
                  "level": 3,
                  "text": "Explore causal analysis"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-azure/manage-compare-models-azure-machine-learning/media/error-tree.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/manage-compare-models-azure-machine-learning/media/error-tree.png",
                  "alt_text": "Screenshot of error tree of diabetes classification model.",
                  "title": "",
                  "filename": "error-tree.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Explore error analysis",
                    "following_text": "",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-azure/manage-compare-models-azure-machine-learning/media/error-map.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/manage-compare-models-azure-machine-learning/media/error-map.png",
                  "alt_text": "Screenshot of error heat map of diabetes classification model.",
                  "title": "",
                  "filename": "error-map.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Explore error analysis",
                    "following_text": "Whenever you use a model for decision-making, you want to understand how a model reaches a certain prediction. Whenever you've trained a model that is too complex to understand, you can runmodel expla",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-azure/manage-compare-models-azure-machine-learning/media/aggregate-feature.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/manage-compare-models-azure-machine-learning/media/aggregate-feature.png",
                  "alt_text": "Screenshot of aggregate feature importance for diabetes dataset.",
                  "title": "",
                  "filename": "aggregate-feature.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Explore explanations",
                    "following_text": "",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-azure/manage-compare-models-azure-machine-learning/media/individual-feature.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/manage-compare-models-azure-machine-learning/media/individual-feature.png",
                  "alt_text": "Screenshot of individual feature importance for one row in the diabetes dataset.",
                  "title": "",
                  "filename": "individual-feature.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Explore explanations",
                    "following_text": "Explanations can give you insights into the relative importance of features on the model's predictions. Sometimes, you may want to take it a step further and understand whether the model's predictions",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-machine-learning-interpretability?view=azureml-api-2#supported-model-interpretability-techniques",
                  "text": "various statistical techniques"
                }
              ]
            },
            {
              "number": 5,
              "title": "Exercise - Explore the Responsible AI dashboard",
              "url": "https://learn.microsoft.com/en-us/training/modules/manage-compare-models-azure-machine-learning/5-exercise-explore-responsible-dashboard",
              "href": "5-exercise-explore-responsible-dashboard",
              "content": "Read in English\nAdd\nAdd to plan\nExercise - Explore the Responsible AI dashboard\nCompleted\n15 minutes\nNow it's your chance to work with the Responsible AI dashboard in Azure Machine Learning for yourself.\nIn this exercise, learn how to:\nCreate a pipeline with the Python SDK v2 to create a Responsible AI dashboard.\nExplore the results of the dashboard in the Azure Machine Learning studio.\nInstructions\nLaunch the exercise and follow the instructions.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Exercise - Explore the Responsible AI dashboard"
                },
                {
                  "level": 2,
                  "text": "Instructions"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-azure/manage-compare-models-azure-machine-learning/media/launch-exercise.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/manage-compare-models-azure-machine-learning/media/launch-exercise.png",
                  "alt_text": "Button to launch exercise.",
                  "title": "",
                  "filename": "launch-exercise.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Instructions",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 6,
              "title": "Module assessment",
              "url": "https://learn.microsoft.com/en-us/training/modules/manage-compare-models-azure-machine-learning/6-knowledge-check",
              "href": "6-knowledge-check",
              "content": "Read in English\nAdd\nAdd to plan\nModule assessment\nCompleted\n3 minutes\n1.\nA data scientist wants to investigate for which subgroups the model has relatively more false predictions, which Responsible AI component should be added to the pipeline to create the Responsible AI dashboard?\nExplanations.\nCounterfactuals.\nError analysis.\n2.\nWhat should be the first component in a pipeline to create a Responsible AI Dashboard?\nRAI Insights dashboard constructor\nGather RAI Insights dashboard\nGather RAI Insights score card\n3.\nA data scientist has trained a model, and wants to quantify the influence of each feature on a specific prediction. What kind of feature importance should the data scientist examine?\nAggregate feature importance.\nGlobal feature importance.\nIndividual feature importance.\nYou must answer all questions before checking your work.\nYou must answer all questions before checking your work.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Module assessment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "RAI Insights dashboard constructor",
                "Gather RAI Insights dashboard",
                "Gather RAI Insights score card"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 7,
              "title": "Summary",
              "url": "https://learn.microsoft.com/en-us/training/modules/manage-compare-models-azure-machine-learning/7-summary",
              "href": "7-summary",
              "content": "Read in English\nAdd\nAdd to plan\nSummary\nCompleted\n3 minutes\nIn this module, you've learned how to:\nUnderstand Azure Machine Learning's built-in components for responsible AI.\nCreate a Responsible AI dashboard.\nExplore a Responsible AI dashboard.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Summary"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "title": "Deploy and consume models with Azure Machine Learning",
      "url": "https://learn.microsoft.com/en-us/training/paths/deploy-consume-models-azure-machine-learning/",
      "learn_uid": "learn.wwl.deploy-consume-models-azure-machine-learning",
      "modules": [
        {
          "title": "Deploy a model to a managed online endpoint",
          "url": "https://learn.microsoft.com/en-us/training/modules/deploy-model-managed-online-endpoint/",
          "description": "",
          "learning_objectives": [],
          "prerequisites": [],
          "units": [
            {
              "number": 1,
              "title": "Introduction",
              "url": "https://learn.microsoft.com/en-us/training/modules/deploy-model-managed-online-endpoint/1-introduction",
              "href": "1-introduction",
              "content": "Read in English\nAdd\nAdd to plan\nIntroduction\nCompleted\n3 minutes\nImagine you trained a model to recommend restaurants. The model has been trained and tracked in Azure Machine Learning. You want to use the model in your application where consumers can browse restaurants in their area. Each time a consumer selects a restaurant in the application, you want the model to recommend other restaurants that might also be of interest to the consumer to improve the user experience.\nWhenever you train a model, you ultimately will want to consume the model. You want to use the trained model to predict labels for new data on which the model hasn't been trained.\nTo consume the model, you need to\ndeploy\nit. One way to deploy a model is to integrate it with a service that allows applications to request instant, or\nreal-time\n, predictions for individual or small sets of data points.\nIn Azure Machine Learning, you can use\nonline endpoints\nto deploy and consume your model.\nLearning objectives\nIn this module, you'll learn how to:\nCreate managed online endpoints.\nDeploy your MLflow model to a managed online endpoint.\nDeploy a custom model to a managed online endpoint.\nTest online endpoints.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Introduction"
                },
                {
                  "level": 2,
                  "text": "Learning objectives"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-azure/deploy-model-managed-online-endpoint/media/07-01-real-time.jpg",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/deploy-model-managed-online-endpoint/media/07-01-real-time.jpg",
                  "alt_text": "Diagram showing an application requesting an instant prediction of a model.",
                  "title": "",
                  "filename": "07-01-real-time.jpg",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Introduction",
                    "following_text": "In Azure Machine Learning, you can useonline endpointsto deploy and consume your model.",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 2,
              "title": "Explore managed online endpoints",
              "url": "https://learn.microsoft.com/en-us/training/modules/deploy-model-managed-online-endpoint/2-explore-managed-online-endpoints",
              "href": "2-explore-managed-online-endpoints",
              "content": "Read in English\nAdd\nAdd to plan\nExplore managed online endpoints\nCompleted\n9 minutes\nTo make a machine learning model available for other applications, you can deploy the model to a managed online endpoint.\nYou'll learn how to use managed online endpoints for real-time predictions.\nReal-time predictions\nTo get real-time predictions, you can deploy a model to an endpoint. An\nendpoint\nis an HTTPS endpoint to which you can send data, and which will return a response (almost) immediately.\nAny data you send to the endpoint will serve as the input for the scoring script hosted on the endpoint. The scoring script loads the trained model to predict the label for the new input data, which is also called\ninferencing\n. The label is then part of the output that's returned.\nManaged online endpoint\nWithin Azure Machine Learning, there are two types of online endpoints:\nManaged online endpoints\n: Azure Machine Learning manages all the underlying infrastructure.\nKubernetes online endpoints\n: Users manage the Kubernetes cluster which provides the necessary infrastructure.\nAs a data scientist, you may prefer to work with managed online endpoints to test whether your model works as expected when deployed. If a Kubernetes online endpoint is required for control and scalability, it'll likely be managed by other teams.\nIf you're using a managed online endpoint, you only need to specify the virtual machine (VM) type and scaling settings. Everything else, such as provisioning compute power and updating the host operating system (OS) is done for you automatically.\nDeploy your model\nAfter you create an endpoint in the Azure Machine Learning workspace, you can deploy a model to that endpoint. To deploy your model to a managed online endpoint, you need to specify four things:\nModel assets\nlike the model pickle file, or a\nregistered model\nin the Azure Machine Learning workspace.\nScoring script\nthat loads the model.\nEnvironment\nwhich lists all necessary packages that need to be installed on the compute of the endpoint.\nCompute configuration\nincluding the needed\ncompute size\nand\nscale settings\nto ensure you can handle the amount of requests the endpoint will receive.\nImportant\nWhen you deploy MLFlow models to an online endpoint, you don't need to provide a scoring script and environment, as both are automatically generated.\nAll of these elements are defined in the deployment. The deployment is essentially a set of resources needed to host the model that performs the actual inferencing.\nBlue/green deployment\nOne endpoint can have multiple deployments. One approach is the\nblue/green deployment\n.\nLet's take the example of the restaurant recommender model. After experimentation, you select the best performing model. You use the blue deployment for this first version of the model. As new data is collected, the model can be retrained, and a new version is registered in the Azure Machine Learning workspace. To test the new model, you can use the green deployment for the second version of the model.\nBoth versions of the model are deployed to the same endpoint, which is integrated with the application. Within the application, a user selects a restaurant, sending a request to the endpoint to get new real-time recommendations of other restaurants the user may like.\nWhen a request is sent to the endpoint, 90% of the traffic can go to the blue deployment*, and 10% of the traffic can go to the\ngreen deployment\n. With two versions of the model deployed on the same endpoint, you can easily test the model.\nAfter testing, you can also seamlessly transition to the new version of the model by redirecting 90% of the traffic to the green deployment. If it turns out that the new version doesn't perform better, you can easily roll back to the first version of the model by redirecting most of the traffic back to the blue deployment.\nBlue/green deployment allows for multiple models to be deployed to an endpoint. You can decide how much traffic to forward to each deployed model. This way, you can switch to a new version of the model without interrupting service to the consumer.\nTip\nLearn more about\nsafe rollout for online endpoints\nCreate an endpoint\nTo create an online endpoint, you'll use the\nManagedOnlineEndpoint\nclass, which requires the following parameters:\nname\n: Name of the endpoint. Must be unique in the Azure region.\nauth_mode\n: Use\nkey\nfor key-based authentication. Use\naml_token\nfor Azure Machine Learning token-based authentication.\nTo create an endpoint, use the following command:\nfrom azure.ai.ml.entities import ManagedOnlineEndpoint\n\n# create an online endpoint\nendpoint = ManagedOnlineEndpoint(\n    name=\"endpoint-example\",\n    description=\"Online endpoint\",\n    auth_mode=\"key\",\n)\n\nml_client.begin_create_or_update(endpoint).result()\nTip\nExplore the reference documentation to\ncreate a managed online endpoint with the Python SDK v2\n.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Explore managed online endpoints"
                },
                {
                  "level": 2,
                  "text": "Real-time predictions"
                },
                {
                  "level": 2,
                  "text": "Managed online endpoint"
                },
                {
                  "level": 2,
                  "text": "Deploy your model"
                },
                {
                  "level": 2,
                  "text": "Blue/green deployment"
                },
                {
                  "level": 2,
                  "text": "Create an endpoint"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "ManagedOnlineEndpoint",
                "from azure.ai.ml.entities import ManagedOnlineEndpoint\n\n# create an online endpoint\nendpoint = ManagedOnlineEndpoint(\n    name=\"endpoint-example\",\n    description=\"Online endpoint\",\n    auth_mode=\"key\",\n)\n\nml_client.begin_create_or_update(endpoint).result()",
                "from azure.ai.ml.entities import ManagedOnlineEndpoint\n\n# create an online endpoint\nendpoint = ManagedOnlineEndpoint(\n    name=\"endpoint-example\",\n    description=\"Online endpoint\",\n    auth_mode=\"key\",\n)\n\nml_client.begin_create_or_update(endpoint).result()"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-safely-rollout-online-endpoints?azure-portal=true",
                  "text": "safe rollout for online endpoints"
                },
                {
                  "url": "/en-us/python/api/azure-ai-ml/azure.ai.ml.entities.managedonlineendpoint?azure-portal=true",
                  "text": "create a managed online endpoint with the Python SDK v2"
                }
              ]
            },
            {
              "number": 3,
              "title": "Deploy your MLflow model to a managed online endpoint",
              "url": "https://learn.microsoft.com/en-us/training/modules/deploy-model-managed-online-endpoint/3-deploy-your-mlflow-model-managed-online-endpoint",
              "href": "3-deploy-your-mlflow-model-managed-online-endpoint",
              "content": "Read in English\nAdd\nAdd to plan\nDeploy your MLflow model to a managed online endpoint\nCompleted\n6 minutes\nThe easiest way to deploy a model to an online endpoint is to use an\nMLflow\nmodel and deploy it to a\nmanaged\nonline endpoint. Azure Machine Learning will automatically generate the scoring script and environment for MLflow models.\nTo deploy an MLflow model, you need to have created an endpoint. Then you can deploy the model to the endpoint.\nDeploy an MLflow model to an endpoint\nWhen you deploy an MLflow model to a managed online endpoint, you dont need to have the scoring script and environment.\nTo deploy an MLflow model, you must have model files stored on a local path or with a registered model. You can log model files when training a model by using MLflow tracking.\nIn this example, we're taking the model files from a local path. The files are all stored in a local folder called\nmodel\n. The folder must include the\nMLmodel\nfile, which describes how the model can be loaded and used.\nTip\nLearn more about\nthe MLmodel format\n.\nNext to the model, you also need to specify the compute configuration for the deployment:\ninstance_type\n: Virtual machine (VM) size to use.\nReview the list of supported sizes\n.\ninstance_count\n: Number of instances to use.\nTo deploy (and automatically register) the model, run the following command:\nfrom azure.ai.ml.entities import Model, ManagedOnlineDeployment\nfrom azure.ai.ml.constants import AssetTypes\n\n# create a blue deployment\nmodel = Model(\n    path=\"./model\",\n    type=AssetTypes.MLFLOW_MODEL,\n    description=\"my sample mlflow model\",\n)\n\nblue_deployment = ManagedOnlineDeployment(\n    name=\"blue\",\n    endpoint_name=\"endpoint-example\",\n    model=model,\n    instance_type=\"Standard_F4s_v2\",\n    instance_count=1,\n)\n\nml_client.online_deployments.begin_create_or_update(blue_deployment).result()\nTip\nExplore the reference documentation to\ncreate a managed online deployment with the Python SDK v2\n.\nSince only one model is deployed to the endpoint, you want this model to take 100% of the traffic. When you deploy multiple models to the same endpoint, you can distribute the traffic among the deployed models.\nTo route traffic to a specific deployment, use the following code:\n# blue deployment takes 100 traffic\nendpoint.traffic = {\"blue\": 100}\nml_client.begin_create_or_update(endpoint).result()\nTo delete the endpoint and all associated deployments, run the command:\nml_client.online_endpoints.begin_delete(name=\"endpoint-example\")\nTip\nLearn more about\ndeploying MLflow models\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Deploy your MLflow model to a managed online endpoint"
                },
                {
                  "level": 2,
                  "text": "Deploy an MLflow model to an endpoint"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "instance_type",
                "instance_count",
                "from azure.ai.ml.entities import Model, ManagedOnlineDeployment\nfrom azure.ai.ml.constants import AssetTypes\n\n# create a blue deployment\nmodel = Model(\n    path=\"./model\",\n    type=AssetTypes.MLFLOW_MODEL,\n    description=\"my sample mlflow model\",\n)\n\nblue_deployment = ManagedOnlineDeployment(\n    name=\"blue\",\n    endpoint_name=\"endpoint-example\",\n    model=model,\n    instance_type=\"Standard_F4s_v2\",\n    instance_count=1,\n)\n\nml_client.online_deployments.begin_create_or_update(blue_deployment).result()",
                "from azure.ai.ml.entities import Model, ManagedOnlineDeployment\nfrom azure.ai.ml.constants import AssetTypes\n\n# create a blue deployment\nmodel = Model(\n    path=\"./model\",\n    type=AssetTypes.MLFLOW_MODEL,\n    description=\"my sample mlflow model\",\n)\n\nblue_deployment = ManagedOnlineDeployment(\n    name=\"blue\",\n    endpoint_name=\"endpoint-example\",\n    model=model,\n    instance_type=\"Standard_F4s_v2\",\n    instance_count=1,\n)\n\nml_client.online_deployments.begin_create_or_update(blue_deployment).result()",
                "# blue deployment takes 100 traffic\nendpoint.traffic = {\"blue\": 100}\nml_client.begin_create_or_update(endpoint).result()",
                "# blue deployment takes 100 traffic\nendpoint.traffic = {\"blue\": 100}\nml_client.begin_create_or_update(endpoint).result()",
                "ml_client.online_endpoints.begin_delete(name=\"endpoint-example\")",
                "ml_client.online_endpoints.begin_delete(name=\"endpoint-example\")"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/concept-mlflow-models#the-mlmodel-format?azure-portal=true",
                  "text": "the MLmodel format"
                },
                {
                  "url": "/en-us/azure/machine-learning/reference-managed-online-endpoints-vm-sku-list?azure-portal=true",
                  "text": "Review the list of supported sizes"
                },
                {
                  "url": "/en-us/python/api/azure-ai-ml/azure.ai.ml.entities.managedonlinedeployment?azure-portal=true",
                  "text": "create a managed online deployment with the Python SDK v2"
                },
                {
                  "url": "/en-us/azure/machine-learning/how-to-deploy-mlflow-models?azure-portal=true",
                  "text": "deploying MLflow models"
                }
              ]
            },
            {
              "number": 4,
              "title": "Deploy a model to a managed online endpoint",
              "url": "https://learn.microsoft.com/en-us/training/modules/deploy-model-managed-online-endpoint/4-eploy-custom-model-managed-online-endpoint",
              "href": "4-eploy-custom-model-managed-online-endpoint",
              "content": "Read in English\nAdd\nAdd to plan\nDeploy a model to a managed online endpoint\nCompleted\n8 minutes\nYou can choose to deploy a model to a managed online endpoint without using the MLflow model format. To deploy a model, you'll need to create the scoring script and define the environment necessary during inferencing.\nTo deploy a model, you need to have created an endpoint. Then you can deploy the model to the endpoint.\nDeploy a model to an endpoint\nTo deploy a model, you must have:\nModel files stored on local path or registered model.\nA scoring script.\nAn execution environment.\nThe model files can be logged and stored when you train a model.\nCreate the scoring script\nThe scoring script needs to include two functions:\ninit()\n: Called when the service is initialized.\nrun()\n: Called when new data is submitted to the service.\nThe\ninit\nfunction is called when the deployment is created or updated, to load and cache the model from the model registry. The\nrun\nfunction is called for every time the endpoint is invoked, to generate predictions from the input data. The following example Python script shows this pattern:\nimport json\nimport joblib\nimport numpy as np\nimport os\n\n# called when the deployment is created or updated\ndef init():\n    global model\n    # get the path to the registered model file and load it\n    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model.pkl')\n    model = joblib.load(model_path)\n\n# called when a request is received\ndef run(raw_data):\n    # get the input data as a numpy array\n    data = np.array(json.loads(raw_data)['data'])\n    # get a prediction from the model\n    predictions = model.predict(data)\n    # return the predictions as any JSON serializable format\n    return predictions.tolist()\nCreate an environment\nYour deployment requires an execution environment in which to run the scoring script.\nYou can create an environment with a Docker image with Conda dependencies, or with a Dockerfile.\nTo create an environment using a base Docker image, you can define the Conda dependencies in a\nconda.yml\nfile:\nname: basic-env-cpu\nchannels:\n  - conda-forge\ndependencies:\n  - python=3.7\n  - scikit-learn\n  - pandas\n  - numpy\n  - matplotlib\nThen, to create the environment, run the following code:\nfrom azure.ai.ml.entities import Environment\n\nenv = Environment(\n    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n    conda_file=\"./src/conda.yml\",\n    name=\"deployment-environment\",\n    description=\"Environment created from a Docker image plus Conda environment.\",\n)\nml_client.environments.create_or_update(env)\nCreate the deployment\nWhen you have your model files, scoring script, and environment, you can create the deployment.\nTo deploy a model to an endpoint, you can specify the compute configuration with two parameters:\ninstance_type\n: Virtual machine (VM) size to use.\nReview the list of supported sizes\n.\ninstance_count\n: Number of instances to use.\nTo deploy the model, use the\nManagedOnlineDeployment\nclass and run the following command:\nfrom azure.ai.ml.entities import ManagedOnlineDeployment, CodeConfiguration\n\nmodel = Model(path=\"./model\",\n\nblue_deployment = ManagedOnlineDeployment(\n    name=\"blue\",\n    endpoint_name=\"endpoint-example\",\n    model=model,\n    environment=\"deployment-environment\",\n    code_configuration=CodeConfiguration(\n        code=\"./src\", scoring_script=\"score.py\"\n    ),\n    instance_type=\"Standard_DS2_v2\",\n    instance_count=1,\n)\n\nml_client.online_deployments.begin_create_or_update(blue_deployment).result()\nTip\nExplore the reference documentation to\ncreate a managed online deployment with the Python SDK v2\n.\nYou can deploy multiple models to an endpoint. To route traffic to a specific deployment, use the following code:\n# blue deployment takes 100 traffic\nendpoint.traffic = {\"blue\": 100}\nml_client.begin_create_or_update(endpoint).result()\nTo delete the endpoint and all associated deployments, run the command:\nml_client.online_endpoints.begin_delete(name=\"endpoint-example\")\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Deploy a model to a managed online endpoint"
                },
                {
                  "level": 2,
                  "text": "Deploy a model to an endpoint"
                },
                {
                  "level": 3,
                  "text": "Create the scoring script"
                },
                {
                  "level": 3,
                  "text": "Create an environment"
                },
                {
                  "level": 3,
                  "text": "Create the deployment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "import json\nimport joblib\nimport numpy as np\nimport os\n\n# called when the deployment is created or updated\ndef init():\n    global model\n    # get the path to the registered model file and load it\n    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model.pkl')\n    model = joblib.load(model_path)\n\n# called when a request is received\ndef run(raw_data):\n    # get the input data as a numpy array\n    data = np.array(json.loads(raw_data)['data'])\n    # get a prediction from the model\n    predictions = model.predict(data)\n    # return the predictions as any JSON serializable format\n    return predictions.tolist()",
                "import json\nimport joblib\nimport numpy as np\nimport os\n\n# called when the deployment is created or updated\ndef init():\n    global model\n    # get the path to the registered model file and load it\n    model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model.pkl')\n    model = joblib.load(model_path)\n\n# called when a request is received\ndef run(raw_data):\n    # get the input data as a numpy array\n    data = np.array(json.loads(raw_data)['data'])\n    # get a prediction from the model\n    predictions = model.predict(data)\n    # return the predictions as any JSON serializable format\n    return predictions.tolist()",
                "name: basic-env-cpu\nchannels:\n  - conda-forge\ndependencies:\n  - python=3.7\n  - scikit-learn\n  - pandas\n  - numpy\n  - matplotlib",
                "name: basic-env-cpu\nchannels:\n  - conda-forge\ndependencies:\n  - python=3.7\n  - scikit-learn\n  - pandas\n  - numpy\n  - matplotlib",
                "from azure.ai.ml.entities import Environment\n\nenv = Environment(\n    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n    conda_file=\"./src/conda.yml\",\n    name=\"deployment-environment\",\n    description=\"Environment created from a Docker image plus Conda environment.\",\n)\nml_client.environments.create_or_update(env)",
                "from azure.ai.ml.entities import Environment\n\nenv = Environment(\n    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n    conda_file=\"./src/conda.yml\",\n    name=\"deployment-environment\",\n    description=\"Environment created from a Docker image plus Conda environment.\",\n)\nml_client.environments.create_or_update(env)",
                "instance_type",
                "instance_count",
                "ManagedOnlineDeployment",
                "from azure.ai.ml.entities import ManagedOnlineDeployment, CodeConfiguration\n\nmodel = Model(path=\"./model\",\n\nblue_deployment = ManagedOnlineDeployment(\n    name=\"blue\",\n    endpoint_name=\"endpoint-example\",\n    model=model,\n    environment=\"deployment-environment\",\n    code_configuration=CodeConfiguration(\n        code=\"./src\", scoring_script=\"score.py\"\n    ),\n    instance_type=\"Standard_DS2_v2\",\n    instance_count=1,\n)\n\nml_client.online_deployments.begin_create_or_update(blue_deployment).result()",
                "from azure.ai.ml.entities import ManagedOnlineDeployment, CodeConfiguration\n\nmodel = Model(path=\"./model\",\n\nblue_deployment = ManagedOnlineDeployment(\n    name=\"blue\",\n    endpoint_name=\"endpoint-example\",\n    model=model,\n    environment=\"deployment-environment\",\n    code_configuration=CodeConfiguration(\n        code=\"./src\", scoring_script=\"score.py\"\n    ),\n    instance_type=\"Standard_DS2_v2\",\n    instance_count=1,\n)\n\nml_client.online_deployments.begin_create_or_update(blue_deployment).result()",
                "# blue deployment takes 100 traffic\nendpoint.traffic = {\"blue\": 100}\nml_client.begin_create_or_update(endpoint).result()",
                "# blue deployment takes 100 traffic\nendpoint.traffic = {\"blue\": 100}\nml_client.begin_create_or_update(endpoint).result()",
                "ml_client.online_endpoints.begin_delete(name=\"endpoint-example\")",
                "ml_client.online_endpoints.begin_delete(name=\"endpoint-example\")"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/reference-managed-online-endpoints-vm-sku-list?azure-portal=true",
                  "text": "Review the list of supported sizes"
                },
                {
                  "url": "/en-us/python/api/azure-ai-ml/azure.ai.ml.entities.managedonlinedeployment?azure-portal=true",
                  "text": "create a managed online deployment with the Python SDK v2"
                }
              ]
            },
            {
              "number": 5,
              "title": "Test managed online endpoints",
              "url": "https://learn.microsoft.com/en-us/training/modules/deploy-model-managed-online-endpoint/5-monitor-online-endpoints",
              "href": "5-monitor-online-endpoints",
              "content": "Read in English\nAdd\nAdd to plan\nTest managed online endpoints\nCompleted\n5 minutes\nAfter deploying a real-time service, you can consume it from client applications to predict labels for new data cases.\nUse the Azure Machine Learning studio\nYou can list all endpoints in the Azure Machine Learning studio, by navigating to the\nEndpoints\npage. In the\nReal-time endpoints\ntab, all endpoints are shown.\nYou can select an endpoint to review its details and deployment logs.\nAdditionally, you can use the studio to test the endpoint.\nUse the Azure Machine Learning Python SDK\nFor testing, you can also use the Azure Machine Learning Python SDK to invoke an endpoint.\nTypically, you send data to deployed model in JSON format with the following structure:\n{\n  \"data\":[\n      [0.1,2.3,4.1,2.0], // 1st case\n      [0.2,1.8,3.9,2.1],  // 2nd case,\n      ...\n  ]\n}\nThe response from the deployed model is a JSON collection with a prediction for each case that was submitted in the data. The following code sample invokes an endpoint and displays the response:\n# test the blue deployment with some sample data\nresponse = ml_client.online_endpoints.invoke(\n    endpoint_name=online_endpoint_name,\n    deployment_name=\"blue\",\n    request_file=\"sample-data.json\",\n)\n\nif response[1]=='1':\n    print(\"Yes\")\nelse:\n    print (\"No\")\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Test managed online endpoints"
                },
                {
                  "level": 2,
                  "text": "Use the Azure Machine Learning studio"
                },
                {
                  "level": 2,
                  "text": "Use the Azure Machine Learning Python SDK"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "{\n  \"data\":[\n      [0.1,2.3,4.1,2.0], // 1st case\n      [0.2,1.8,3.9,2.1],  // 2nd case,\n      ...\n  ]\n}",
                "{\n  \"data\":[\n      [0.1,2.3,4.1,2.0], // 1st case\n      [0.2,1.8,3.9,2.1],  // 2nd case,\n      ...\n  ]\n}",
                "# test the blue deployment with some sample data\nresponse = ml_client.online_endpoints.invoke(\n    endpoint_name=online_endpoint_name,\n    deployment_name=\"blue\",\n    request_file=\"sample-data.json\",\n)\n\nif response[1]=='1':\n    print(\"Yes\")\nelse:\n    print (\"No\")",
                "# test the blue deployment with some sample data\nresponse = ml_client.online_endpoints.invoke(\n    endpoint_name=online_endpoint_name,\n    deployment_name=\"blue\",\n    request_file=\"sample-data.json\",\n)\n\nif response[1]=='1':\n    print(\"Yes\")\nelse:\n    print (\"No\")"
              ],
              "images": [
                {
                  "src": "../../wwl-azure/deploy-model-managed-online-endpoint/media/test-studio.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/deploy-model-managed-online-endpoint/media/test-studio.png",
                  "alt_text": "Diagram showing different hyperparameter values resulting in different models by performing hyperparameter tuning.",
                  "title": "",
                  "filename": "test-studio.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Use the Azure Machine Learning studio",
                    "following_text": "For testing, you can also use the Azure Machine Learning Python SDK to invoke an endpoint.",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 6,
              "title": "Exercise - Deploy an MLflow model to an online endpoint",
              "url": "https://learn.microsoft.com/en-us/training/modules/deploy-model-managed-online-endpoint/6-exercise-deploy-mlflow-model-online-endpoint",
              "href": "6-exercise-deploy-mlflow-model-online-endpoint",
              "content": "Read in English\nAdd\nAdd to plan\nExercise - Deploy an MLflow model to an online endpoint\nCompleted\n10 minutes\nNow, it's your chance to explore how to deploy models to a managed online endpoint.\nIn this exercise, you learn how to:\nCreate a managed online endpoint.\nDeploy an MLflow model.\nTest the endpoint.\nInstructions\nLaunch the exercise and follow the instructions.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Exercise - Deploy an MLflow model to an online endpoint"
                },
                {
                  "level": 2,
                  "text": "Instructions"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-azure/deploy-model-managed-online-endpoint/media/launch-exercise.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/deploy-model-managed-online-endpoint/media/launch-exercise.png",
                  "alt_text": "Button to launch exercise.",
                  "title": "",
                  "filename": "launch-exercise.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Instructions",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 7,
              "title": "Module assessment",
              "url": "https://learn.microsoft.com/en-us/training/modules/deploy-model-managed-online-endpoint/7-knowledge-check",
              "href": "7-knowledge-check",
              "content": "Read in English\nAdd\nAdd to plan\nModule assessment\nCompleted\n3 minutes\n1.\nYou've trained a model using the Python SDK for Azure Machine Learning. You want to deploy the model to get real-time predictions. You want to manage the underlying infrastructure used by the endpoint. What kind of endpoint should you create?\nA managed online endpoint.\nA batch endpoint.\nA Kubernetes online endpoint.\n2.\nYou're deploying a model as a real-time inferencing service. What functions must the scoring script for the deployment include?\nmain()\nand\nscore()\nbase()\nand\ntrain()\ninit()\nand\nrun()\nYou must answer all questions before checking your work.\nYou must answer all questions before checking your work.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Module assessment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 8,
              "title": "Summary",
              "url": "https://learn.microsoft.com/en-us/training/modules/deploy-model-managed-online-endpoint/8-summary",
              "href": "8-summary",
              "content": "Read in English\nAdd\nAdd to plan\nSummary\nCompleted\n1 minute\nIn this module, you've learned how to:\nUse managed online endpoints.\nDeploy your MLflow model to a managed online endpoint.\nDeploy a custom model to a managed online endpoint.\nTest online endpoints.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Summary"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            }
          ]
        },
        {
          "title": "Deploy a model to a batch endpoint",
          "url": "https://learn.microsoft.com/en-us/training/modules/deploy-model-batch-endpoint/",
          "description": "",
          "learning_objectives": [],
          "prerequisites": [],
          "units": [
            {
              "number": 1,
              "title": "Introduction",
              "url": "https://learn.microsoft.com/en-us/training/modules/deploy-model-batch-endpoint/1-introduction",
              "href": "1-introduction",
              "content": "Read in English\nAdd\nAdd to plan\nIntroduction\nCompleted\n3 minutes\nImagine you trained a model to predict the product sales. The model has been trained and tracked in Azure Machine Learning. Every month, you want to use the model to forecast the sales for the upcoming month.\nIn many production scenarios, long-running tasks that deal with large amounts of data are performed as\nbatch\noperations. In machine learning,\nbatch inferencing\nis used to asynchronously apply a predictive model to multiple cases and write the results to a file or database.\nIn Azure Machine Learning, you can implement batch inferencing solutions by deploying a model to a batch endpoint.\nLearning objectives\nIn this module, you'll learn how to:\nCreate a batch endpoint.\nDeploy your MLflow model to a batch endpoint.\nDeploy a custom model to a batch endpoint.\nInvoke batch endpoints.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Introduction"
                },
                {
                  "level": 2,
                  "text": "Learning objectives"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-azure/deploy-model-batch-endpoint/media/07-02-batch.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/deploy-model-batch-endpoint/media/07-02-batch.png",
                  "alt_text": "Diagram showing a batch inferencing service triggering a batch scoring job.",
                  "title": "",
                  "filename": "07-02-batch.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Introduction",
                    "following_text": "In Azure Machine Learning, you can implement batch inferencing solutions by deploying a model to a batch endpoint.",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 2,
              "title": "Understand and create batch endpoints",
              "url": "https://learn.microsoft.com/en-us/training/modules/deploy-model-batch-endpoint/2-explore-batch-endpoints",
              "href": "2-explore-batch-endpoints",
              "content": "Read in English\nAdd\nAdd to plan\nUnderstand and create batch endpoints\nCompleted\n6 minutes\nTo get a model to generate batch predictions, you can deploy the model to a batch endpoint.\nYou'll learn how to use batch endpoints for asynchronous batch scoring.\nBatch predictions\nTo get batch predictions, you can deploy a model to an endpoint. An\nendpoint\nis an HTTPS endpoint that you can call to trigger a batch scoring job. The advantage of such an endpoint is that you can trigger the batch scoring job from another service, such as Azure Synapse Analytics or Azure Databricks. A batch endpoint allows you to integrate the batch scoring with an existing data ingestion and transformation pipeline.\nWhenever the endpoint is invoked, a batch scoring job is submitted to the Azure Machine Learning workspace. The job typically uses a\ncompute cluster\nto score multiple inputs. The results can be stored in a datastore, connected to the Azure Machine Learning workspace.\nCreate a batch endpoint\nTo deploy a model to a batch endpoint, you'll first have to create the batch endpoint.\nTo create a batch endpoint, you'll use the\nBatchEndpoint\nclass. Batch endpoint names need to be unique within an Azure region.\nTo create an endpoint, use the following command:\n# create a batch endpoint\nendpoint = BatchEndpoint(\n    name=\"endpoint-example\",\n    description=\"A batch endpoint\",\n)\n\nml_client.batch_endpoints.begin_create_or_update(endpoint)\nTip\nExplore the reference documentation to\ncreate a batch endpoint with the Python SDK v2\n.\nDeploy a model to a batch endpoint\nYou can deploy multiple models to a batch endpoint. Whenever you call the batch endpoint, which triggers a batch scoring job, the\ndefault deployment\nwill be used unless specified otherwise.\nUse compute clusters for batch deployments\nThe ideal compute to use for batch deployments is the Azure Machine Learning compute cluster. If you want the batch scoring job to process the new data in parallel batches, you need to provision a compute cluster with more than one maximum instances.\nTo create a compute cluster, you can use the\nAMLCompute\nclass.\nfrom azure.ai.ml.entities import AmlCompute\n\ncpu_cluster = AmlCompute(\n    name=\"aml-cluster\",\n    type=\"amlcompute\",\n    size=\"STANDARD_DS11_V2\",\n    min_instances=0,\n    max_instances=4,\n    idle_time_before_scale_down=120,\n    tier=\"Dedicated\",\n)\n\ncpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster)\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Understand and create batch endpoints"
                },
                {
                  "level": 2,
                  "text": "Batch predictions"
                },
                {
                  "level": 2,
                  "text": "Create a batch endpoint"
                },
                {
                  "level": 2,
                  "text": "Deploy a model to a batch endpoint"
                },
                {
                  "level": 2,
                  "text": "Use compute clusters for batch deployments"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "BatchEndpoint",
                "# create a batch endpoint\nendpoint = BatchEndpoint(\n    name=\"endpoint-example\",\n    description=\"A batch endpoint\",\n)\n\nml_client.batch_endpoints.begin_create_or_update(endpoint)",
                "# create a batch endpoint\nendpoint = BatchEndpoint(\n    name=\"endpoint-example\",\n    description=\"A batch endpoint\",\n)\n\nml_client.batch_endpoints.begin_create_or_update(endpoint)",
                "from azure.ai.ml.entities import AmlCompute\n\ncpu_cluster = AmlCompute(\n    name=\"aml-cluster\",\n    type=\"amlcompute\",\n    size=\"STANDARD_DS11_V2\",\n    min_instances=0,\n    max_instances=4,\n    idle_time_before_scale_down=120,\n    tier=\"Dedicated\",\n)\n\ncpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster)",
                "from azure.ai.ml.entities import AmlCompute\n\ncpu_cluster = AmlCompute(\n    name=\"aml-cluster\",\n    type=\"amlcompute\",\n    size=\"STANDARD_DS11_V2\",\n    min_instances=0,\n    max_instances=4,\n    idle_time_before_scale_down=120,\n    tier=\"Dedicated\",\n)\n\ncpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster)"
              ],
              "images": [
                {
                  "src": "../../wwl-azure/deploy-model-batch-endpoint/media/batch-details.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/deploy-model-batch-endpoint/media/batch-details.png",
                  "alt_text": "Screenshot of details page of a batch endpoint, showing the default deployment.",
                  "title": "",
                  "filename": "batch-details.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Deploy a model to a batch endpoint",
                    "following_text": "The ideal compute to use for batch deployments is the Azure Machine Learning compute cluster. If you want the batch scoring job to process the new data in parallel batches, you need to provision a com",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/python/api/azure-ai-ml/azure.ai.ml.entities.batchendpoint?azure-portal=true",
                  "text": "create a batch endpoint with the Python SDK v2"
                }
              ]
            },
            {
              "number": 3,
              "title": "Deploy your MLflow model to a batch endpoint",
              "url": "https://learn.microsoft.com/en-us/training/modules/deploy-model-batch-endpoint/3-deploy-your-mlflow-model-batch-endpoint",
              "href": "3-deploy-your-mlflow-model-batch-endpoint",
              "content": "Read in English\nAdd\nAdd to plan\nDeploy your MLflow model to a batch endpoint\nCompleted\n7 minutes\nAn easy way to deploy a model to a batch endpoint is to use an\nMLflow\nmodel. Azure Machine Learning will automatically generate the scoring script and environment for MLflow models.\nTo deploy an MLflow model, you need to have created an endpoint. Then you can deploy the model to the endpoint.\nRegister an MLflow model\nTo avoid needed a scoring script and environment, an MLflow model needs to be registered in the Azure Machine Learning workspace before you can deploy it to a batch endpoint.\nTo register an MLflow model, you'll use the\nModel\nclass, while specifying the model type to be\nMLFLOW_MODEL\n. To register the model with the Python SDK, you can use the following code:\nfrom azure.ai.ml.entities import Model\nfrom azure.ai.ml.constants import AssetTypes\n\nmodel_name = 'mlflow-model'\nmodel = ml_client.models.create_or_update(\n    Model(name=model_name, path='./model', type=AssetTypes.MLFLOW_MODEL)\n)\nIn this example, we're taking the model files from a local path. The files are all stored in a local folder called\nmodel\n. The folder must include the\nMLmodel\nfile, which describes how the model can be loaded and used.\nTip\nLearn more about\nthe MLmodel format\n.\nDeploy an MLflow model to an endpoint\nTo deploy an MLflow model to a batch endpoint, you'll use the\nBatchDeployment\nclass.\nWhen you deploy a model, you'll need to specify how you want the batch scoring job to behave. The advantage of using a compute cluster to run the scoring script (which is automatically generated by Azure Machine Learning), is that you can run the scoring script on separate instances in parallel.\nWhen you configure the model deployment, you can specify:\ninstance_count\n: Count of compute nodes to use for generating predictions.\nmax_concurrency_per_instance\n: Maximum number of parallel scoring script runs per compute node.\nmini_batch_size\n: Number of files passed per scoring script run.\noutput_action\n: What to do with the predictions:\nsummary_only\nor\nappend_row\n.\noutput_file_name\n: File to which predictions will be appended, if you choose\nappend_row\nfor\noutput_action\n.\nTip\nExplore the reference documentation to\ncreate a batch deployment with the Python SDK v2\n.\nTo deploy an MLflow model to a batch endpoint, you can use the following code:\nfrom azure.ai.ml.entities import BatchDeployment, BatchRetrySettings\nfrom azure.ai.ml.constants import BatchDeploymentOutputAction\n\ndeployment = BatchDeployment(\n    name=\"forecast-mlflow\",\n    description=\"A sales forecaster\",\n    endpoint_name=endpoint.name,\n    model=model,\n    compute=\"aml-cluster\",\n    instance_count=2,\n    max_concurrency_per_instance=2,\n    mini_batch_size=2,\n    output_action=BatchDeploymentOutputAction.APPEND_ROW,\n    output_file_name=\"predictions.csv\",\n    retry_settings=BatchRetrySettings(max_retries=3, timeout=300),\n    logging_level=\"info\",\n)\nml_client.batch_deployments.begin_create_or_update(deployment)\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Deploy your MLflow model to a batch endpoint"
                },
                {
                  "level": 2,
                  "text": "Register an MLflow model"
                },
                {
                  "level": 2,
                  "text": "Deploy an MLflow model to an endpoint"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "MLFLOW_MODEL",
                "from azure.ai.ml.entities import Model\nfrom azure.ai.ml.constants import AssetTypes\n\nmodel_name = 'mlflow-model'\nmodel = ml_client.models.create_or_update(\n    Model(name=model_name, path='./model', type=AssetTypes.MLFLOW_MODEL)\n)",
                "from azure.ai.ml.entities import Model\nfrom azure.ai.ml.constants import AssetTypes\n\nmodel_name = 'mlflow-model'\nmodel = ml_client.models.create_or_update(\n    Model(name=model_name, path='./model', type=AssetTypes.MLFLOW_MODEL)\n)",
                "BatchDeployment",
                "instance_count",
                "max_concurrency_per_instance",
                "mini_batch_size",
                "output_action",
                "summary_only",
                "output_file_name",
                "output_action",
                "from azure.ai.ml.entities import BatchDeployment, BatchRetrySettings\nfrom azure.ai.ml.constants import BatchDeploymentOutputAction\n\ndeployment = BatchDeployment(\n    name=\"forecast-mlflow\",\n    description=\"A sales forecaster\",\n    endpoint_name=endpoint.name,\n    model=model,\n    compute=\"aml-cluster\",\n    instance_count=2,\n    max_concurrency_per_instance=2,\n    mini_batch_size=2,\n    output_action=BatchDeploymentOutputAction.APPEND_ROW,\n    output_file_name=\"predictions.csv\",\n    retry_settings=BatchRetrySettings(max_retries=3, timeout=300),\n    logging_level=\"info\",\n)\nml_client.batch_deployments.begin_create_or_update(deployment)",
                "from azure.ai.ml.entities import BatchDeployment, BatchRetrySettings\nfrom azure.ai.ml.constants import BatchDeploymentOutputAction\n\ndeployment = BatchDeployment(\n    name=\"forecast-mlflow\",\n    description=\"A sales forecaster\",\n    endpoint_name=endpoint.name,\n    model=model,\n    compute=\"aml-cluster\",\n    instance_count=2,\n    max_concurrency_per_instance=2,\n    mini_batch_size=2,\n    output_action=BatchDeploymentOutputAction.APPEND_ROW,\n    output_file_name=\"predictions.csv\",\n    retry_settings=BatchRetrySettings(max_retries=3, timeout=300),\n    logging_level=\"info\",\n)\nml_client.batch_deployments.begin_create_or_update(deployment)"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/concept-mlflow-models#the-mlmodel-format?azure-portal=true",
                  "text": "the MLmodel format"
                },
                {
                  "url": "/en-us/python/api/azure-ai-ml/azure.ai.ml.entities.batchdeployment?azure-portal=true",
                  "text": "create a batch deployment with the Python SDK v2"
                }
              ]
            },
            {
              "number": 4,
              "title": "Deploy a custom model to a batch endpoint",
              "url": "https://learn.microsoft.com/en-us/training/modules/deploy-model-batch-endpoint/4-deploy-custom-model-batch-endpoint",
              "href": "4-deploy-custom-model-batch-endpoint",
              "content": "Read in English\nAdd\nAdd to plan\nDeploy a custom model to a batch endpoint\nCompleted\n9 minutes\nIf you want to deploy a model to a batch endpoint without using the MLflow model format, you need to create the scoring script and environment.\nTo deploy a model, you must have already created an endpoint. Then you can deploy the model to the endpoint.\nCreate the scoring script\nThe scoring script is a file that reads the new data, loads the model, and performs the scoring.\nThe scoring script must include two functions:\ninit()\n: Called once at the beginning of the process, so use for any costly or common preparation like loading the model.\nrun()\n: Called for each mini batch to perform the scoring.\nThe\nrun()\nmethod should return a pandas DataFrame or an array/list.\nA scoring script may look as follows:\nimport os\nimport mlflow\nimport pandas as pd\n\n\ndef init():\n    global model\n\n    # get the path to the registered model file and load it\n    model_path = os.path.join(os.environ[\"AZUREML_MODEL_DIR\"], \"model\")\n    model = mlflow.pyfunc.load(model_path)\n\n\ndef run(mini_batch):\n    print(f\"run method start: {__file__}, run({len(mini_batch)} files)\")\n    resultList = []\n\n    for file_path in mini_batch:\n        data = pd.read_csv(file_path)\n        pred = model.predict(data)\n\n        df = pd.DataFrame(pred, columns=[\"predictions\"])\n        df[\"file\"] = os.path.basename(file_path)\n        resultList.extend(df.values)\n\n    return resultList\nThere are some things to note from the example script:\nAZUREML_MODEL_DIR\nis an environment variable that you can use to locate the files associated with the model.\nUse\nglobal\nvariable to make any assets available that are needed to score the new data, like the loaded model.\nThe size of the\nmini_batch\nis defined in the deployment configuration. If the files in the mini batch are too large to be processed, you need to split the files into smaller files.\nBy default, the predictions will be written to one single file.\nTip\nLearn more about how to\nauthor scoring scripts for batch deployments\n.\nCreate an environment\nYour deployment requires an execution environment in which to run the scoring script. Any dependency your code requires should be included in the environment.\nYou can create an environment with a Docker image with Conda dependencies, or with a Dockerfile.\nYou'll also need to add the library\nazureml-core\nas it is required for batch deployments to work.\nTo create an environment using a base Docker image, you can define the Conda dependencies in a\nconda.yaml\nfile:\nname: basic-env-cpu\nchannels:\n  - conda-forge\ndependencies:\n  - python=3.8\n  - pandas\n  - pip\n  - pip:\n      - azureml-core\n      - mlflow\nThen, to create the environment, run the following code:\nfrom azure.ai.ml.entities import Environment\n\nenv = Environment(\n    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n    conda_file=\"./src/conda-env.yml\",\n    name=\"deployment-environment\",\n    description=\"Environment created from a Docker image plus Conda environment.\",\n)\nml_client.environments.create_or_update(env)\nConfigure and create the deployment\nFinally, you can configure and create the deployment with the\nBatchDeployment\nclass.\nfrom azure.ai.ml.entities import BatchDeployment, BatchRetrySettings\nfrom azure.ai.ml.constants import BatchDeploymentOutputAction\n\ndeployment = BatchDeployment(\n    name=\"forecast-mlflow\",\n    description=\"A sales forecaster\",\n    endpoint_name=endpoint.name,\n    model=model,\n    compute=\"aml-cluster\",\n    code_path=\"./code\",\n    scoring_script=\"score.py\",\n    environment=env,\n    instance_count=2,\n    max_concurrency_per_instance=2,\n    mini_batch_size=2,\n    output_action=BatchDeploymentOutputAction.APPEND_ROW,\n    output_file_name=\"predictions.csv\",\n    retry_settings=BatchRetrySettings(max_retries=3, timeout=300),\n    logging_level=\"info\",\n)\nml_client.batch_deployments.begin_create_or_update(deployment)\nTip\nExplore the reference documentation to\ncreate a batch deployment with the Python SDK v2\n.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Deploy a custom model to a batch endpoint"
                },
                {
                  "level": 2,
                  "text": "Create the scoring script"
                },
                {
                  "level": 2,
                  "text": "Create an environment"
                },
                {
                  "level": 2,
                  "text": "Configure and create the deployment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "import os\nimport mlflow\nimport pandas as pd\n\n\ndef init():\n    global model\n\n    # get the path to the registered model file and load it\n    model_path = os.path.join(os.environ[\"AZUREML_MODEL_DIR\"], \"model\")\n    model = mlflow.pyfunc.load(model_path)\n\n\ndef run(mini_batch):\n    print(f\"run method start: {__file__}, run({len(mini_batch)} files)\")\n    resultList = []\n\n    for file_path in mini_batch:\n        data = pd.read_csv(file_path)\n        pred = model.predict(data)\n\n        df = pd.DataFrame(pred, columns=[\"predictions\"])\n        df[\"file\"] = os.path.basename(file_path)\n        resultList.extend(df.values)\n\n    return resultList",
                "import os\nimport mlflow\nimport pandas as pd\n\n\ndef init():\n    global model\n\n    # get the path to the registered model file and load it\n    model_path = os.path.join(os.environ[\"AZUREML_MODEL_DIR\"], \"model\")\n    model = mlflow.pyfunc.load(model_path)\n\n\ndef run(mini_batch):\n    print(f\"run method start: {__file__}, run({len(mini_batch)} files)\")\n    resultList = []\n\n    for file_path in mini_batch:\n        data = pd.read_csv(file_path)\n        pred = model.predict(data)\n\n        df = pd.DataFrame(pred, columns=[\"predictions\"])\n        df[\"file\"] = os.path.basename(file_path)\n        resultList.extend(df.values)\n\n    return resultList",
                "AZUREML_MODEL_DIR",
                "azureml-core",
                "name: basic-env-cpu\nchannels:\n  - conda-forge\ndependencies:\n  - python=3.8\n  - pandas\n  - pip\n  - pip:\n      - azureml-core\n      - mlflow",
                "name: basic-env-cpu\nchannels:\n  - conda-forge\ndependencies:\n  - python=3.8\n  - pandas\n  - pip\n  - pip:\n      - azureml-core\n      - mlflow",
                "from azure.ai.ml.entities import Environment\n\nenv = Environment(\n    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n    conda_file=\"./src/conda-env.yml\",\n    name=\"deployment-environment\",\n    description=\"Environment created from a Docker image plus Conda environment.\",\n)\nml_client.environments.create_or_update(env)",
                "from azure.ai.ml.entities import Environment\n\nenv = Environment(\n    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n    conda_file=\"./src/conda-env.yml\",\n    name=\"deployment-environment\",\n    description=\"Environment created from a Docker image plus Conda environment.\",\n)\nml_client.environments.create_or_update(env)",
                "BatchDeployment",
                "from azure.ai.ml.entities import BatchDeployment, BatchRetrySettings\nfrom azure.ai.ml.constants import BatchDeploymentOutputAction\n\ndeployment = BatchDeployment(\n    name=\"forecast-mlflow\",\n    description=\"A sales forecaster\",\n    endpoint_name=endpoint.name,\n    model=model,\n    compute=\"aml-cluster\",\n    code_path=\"./code\",\n    scoring_script=\"score.py\",\n    environment=env,\n    instance_count=2,\n    max_concurrency_per_instance=2,\n    mini_batch_size=2,\n    output_action=BatchDeploymentOutputAction.APPEND_ROW,\n    output_file_name=\"predictions.csv\",\n    retry_settings=BatchRetrySettings(max_retries=3, timeout=300),\n    logging_level=\"info\",\n)\nml_client.batch_deployments.begin_create_or_update(deployment)",
                "from azure.ai.ml.entities import BatchDeployment, BatchRetrySettings\nfrom azure.ai.ml.constants import BatchDeploymentOutputAction\n\ndeployment = BatchDeployment(\n    name=\"forecast-mlflow\",\n    description=\"A sales forecaster\",\n    endpoint_name=endpoint.name,\n    model=model,\n    compute=\"aml-cluster\",\n    code_path=\"./code\",\n    scoring_script=\"score.py\",\n    environment=env,\n    instance_count=2,\n    max_concurrency_per_instance=2,\n    mini_batch_size=2,\n    output_action=BatchDeploymentOutputAction.APPEND_ROW,\n    output_file_name=\"predictions.csv\",\n    retry_settings=BatchRetrySettings(max_retries=3, timeout=300),\n    logging_level=\"info\",\n)\nml_client.batch_deployments.begin_create_or_update(deployment)"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/batch-inference/how-to-batch-scoring-script?azure-portal=true",
                  "text": "author scoring scripts for batch deployments"
                },
                {
                  "url": "/en-us/python/api/azure-ai-ml/azure.ai.ml.entities.batchdeployment?azure-portal=true",
                  "text": "create a batch deployment with the Python SDK v2"
                }
              ]
            },
            {
              "number": 5,
              "title": "Invoke and troubleshoot batch endpoints",
              "url": "https://learn.microsoft.com/en-us/training/modules/deploy-model-batch-endpoint/5-monitor-batch-endpoints",
              "href": "5-monitor-batch-endpoints",
              "content": "Read in English\nAdd\nAdd to plan\nInvoke and troubleshoot batch endpoints\nCompleted\n5 minutes\nWhen you invoke a batch endpoint, you trigger an Azure Machine Learning\npipeline job\n. The job will expect an input parameter pointing to the data set you want to score.\nTrigger the batch scoring job\nTo prepare data for batch predictions, you can register a folder as a data asset in the Azure Machine Learning workspace.\nYou can then use the registered data asset as input when invoking the batch endpoint with the Python SDK:\nfrom azure.ai.ml import Input\nfrom azure.ai.ml.constants import AssetTypes\n\ninput = Input(type=AssetTypes.URI_FOLDER, path=\"azureml:new-data:1\")\n\njob = ml_client.batch_endpoints.invoke(\n    endpoint_name=endpoint.name, \n    input=input)\nYou can monitor the run of the pipeline job in the Azure Machine Learning studio. All jobs that are triggered by invoking the batch endpoint will show in the\nJobs\ntab of the batch endpoint.\nThe predictions will be stored in the default datastore.\nTroubleshoot a batch scoring job\nThe batch scoring job runs as a\npipeline job\n. If you want to troubleshoot the pipeline job, you can review its details and the outputs and logs of the pipeline job itself.\nIf you want to troubleshoot the scoring script, you can select the child job and review its outputs and logs.\nNavigate to the\nOutputs + logs\ntab. The\nlogs/user/\nfolder contains three files that will help you troubleshoot:\njob_error.txt\n: Summarize the errors in your script.\njob_progress_overview.txt\n: Provides high-level information about the number of mini-batches processed so far.\njob_result.txt\n: Shows errors in calling the\ninit()\nand\nrun()\nfunction in the scoring script.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Invoke and troubleshoot batch endpoints"
                },
                {
                  "level": 2,
                  "text": "Trigger the batch scoring job"
                },
                {
                  "level": 2,
                  "text": "Troubleshoot a batch scoring job"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "from azure.ai.ml import Input\nfrom azure.ai.ml.constants import AssetTypes\n\ninput = Input(type=AssetTypes.URI_FOLDER, path=\"azureml:new-data:1\")\n\njob = ml_client.batch_endpoints.invoke(\n    endpoint_name=endpoint.name, \n    input=input)",
                "from azure.ai.ml import Input\nfrom azure.ai.ml.constants import AssetTypes\n\ninput = Input(type=AssetTypes.URI_FOLDER, path=\"azureml:new-data:1\")\n\njob = ml_client.batch_endpoints.invoke(\n    endpoint_name=endpoint.name, \n    input=input)",
                "job_error.txt",
                "job_progress_overview.txt",
                "job_result.txt"
              ],
              "images": [
                {
                  "src": "../../wwl-azure/deploy-model-batch-endpoint/media/batch-jobs.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/deploy-model-batch-endpoint/media/batch-jobs.png",
                  "alt_text": "Screenshot of completed and failed jobs from an invoked batch endpoint.",
                  "title": "",
                  "filename": "batch-jobs.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Trigger the batch scoring job",
                    "following_text": "The predictions will be stored in the default datastore.",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-azure/deploy-model-batch-endpoint/media/child-job.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/deploy-model-batch-endpoint/media/child-job.png",
                  "alt_text": "Screenshot of child job under the pipeline job overview.",
                  "title": "",
                  "filename": "child-job.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Troubleshoot a batch scoring job",
                    "following_text": "If you want to troubleshoot the scoring script, you can select the child job and review its outputs and logs.",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-azure/deploy-model-batch-endpoint/media/child-output.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/deploy-model-batch-endpoint/media/child-output.png",
                  "alt_text": "Screenshot of the output and logs of the child job.",
                  "title": "",
                  "filename": "child-output.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Troubleshoot a batch scoring job",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 6,
              "title": "Exercise - Deploy an MLflow model to a batch endpoint",
              "url": "https://learn.microsoft.com/en-us/training/modules/deploy-model-batch-endpoint/6-exercise-deploy-mlflow-model-batch-endpoint",
              "href": "6-exercise-deploy-mlflow-model-batch-endpoint",
              "content": "Read in English\nAdd\nAdd to plan\nExercise - Deploy an MLflow model to a batch endpoint\nCompleted\n10 minutes\nNow, it's your chance to explore how to deploy models to a batch endpoint.\nIn this exercise, you learn how to:\nCreate a batch endpoint.\nDeploy an MLflow model to the endpoint.\nInvoke the endpoint.\nInstructions\nLaunch the exercise and follow the instructions.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Exercise - Deploy an MLflow model to a batch endpoint"
                },
                {
                  "level": 2,
                  "text": "Instructions"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-azure/deploy-model-batch-endpoint/media/launch-exercise.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-azure/deploy-model-batch-endpoint/media/launch-exercise.png",
                  "alt_text": "Button to launch exercise.",
                  "title": "",
                  "filename": "launch-exercise.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Instructions",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 7,
              "title": "Module assessment",
              "url": "https://learn.microsoft.com/en-us/training/modules/deploy-model-batch-endpoint/7-knowledge-check",
              "href": "7-knowledge-check",
              "content": "Read in English\nAdd\nAdd to plan\nModule assessment\nCompleted\n3 minutes\n1.\nYou are creating a batch endpoint that you want to use to predict new values for a large volume of data files. You want the pipeline to run the scoring script on multiple nodes and collate the results. What output action should you choose for the deployment?\nsummary_only\nappend_row\nconcurrency\n2.\nYou have multiple models deployed to a batch endpoint. You invoke the endpoint without indicating which model you want to use. Which deployed model will do the actual batch scoring?\nThe latest version of the deployed model.\nThe latest deployed model.\nThe default deployed model.\nYou must answer all questions before checking your work.\nYou must answer all questions before checking your work.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Module assessment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "summary_only",
                "concurrency"
              ],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 8,
              "title": "Summary",
              "url": "https://learn.microsoft.com/en-us/training/modules/deploy-model-batch-endpoint/8-summary",
              "href": "8-summary",
              "content": "Read in English\nAdd\nAdd to plan\nSummary\nCompleted\n1 minute\nIn this module, you've learned how to:\nCreate a batch endpoint.\nDeploy your MLflow model to a batch endpoint.\nDeploy a custom model to a batch endpoint.\nInvoke batch endpoints.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Summary"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "title": "Develop generative AI apps in Azure",
      "url": "https://learn.microsoft.com/en-us/training/paths/create-custom-copilots-ai-studio/",
      "learn_uid": "learn.wwl.create-custom-copilots-ai-studio",
      "modules": [
        {
          "title": "Plan and prepare to develop AI solutions on Azure",
          "url": "https://learn.microsoft.com/en-us/training/modules/prepare-azure-ai-development/",
          "description": "",
          "learning_objectives": [],
          "prerequisites": [],
          "units": [
            {
              "number": 1,
              "title": "Introduction",
              "url": "https://learn.microsoft.com/en-us/training/modules/prepare-azure-ai-development/1-introduction",
              "href": "1-introduction",
              "content": "Read in English\nAdd\nAdd to plan\nIntroduction\nCompleted\n1 minute\nThe growth in the use of artificial intelligence (AI) in general, and\ngenerative\nAI in particular means that developers are increasingly required to create comprehensive AI solutions. These solutions need to combine machine learning models, AI services, prompt engineering solutions, and custom code.\nMicrosoft Azure provides multiple services that you can use to create AI solutions. However, before embarking on an AI application development project, it's useful to consider the available options for services, tools, and frameworks as well as some principles and practices that can help you succeed.\nThis module explores some of the key considerations for planning an AI development project, and introduces\nAzure AI Foundry\n; a comprehensive platform for AI development on Microsoft Azure.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Introduction"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 2,
              "title": "What is AI?",
              "url": "https://learn.microsoft.com/en-us/training/modules/prepare-azure-ai-development/2-what-is-ai",
              "href": "2-what-is-ai",
              "content": "Read in English\nAdd\nAdd to plan\nWhat is AI?\nCompleted\n5 minutes\nThe term \"Artificial Intelligence\" (AI) covers a wide range of software capabilities that enable applications to exhibit human-like behavior. AI has been around for many years, and its definition has varied as the technology and use cases associated with it have evolved. In today's technological landscape, AI solutions are built on machine learning\nmodels\nthat encapsulate semantic relationships found in huge quantities of data; enabling applications to appear to interpret input in various formats, reason over the input data, and generate appropriate responses and predictions.\nCommon AI capabilities that developers can integrate into a software application include:\nCapability\nDescription\nGenerative AI\nThe ability to generate original responses to natural language\nprompts\n. For example, software for a real estate business might be used to automatically generate property descriptions and advertising copy for a property listing.\nAgents\nGenerative AI applications that can respond to user input or assess situations autonomously, and take appropriate actions. For example, an \"executive assistant\" agent could provide details about the location of a meeting on your calendar, or even attach a map or automate the booking of a taxi or rideshare service to help you get there.\nComputer vision\nThe ability to accept, interpret, and process visual input from images, videos, and live camera streams. For example, an automated checkout in a grocery store might use computer vision to identify which products a customer has in their shopping basket, eliminating the need to scan a barcode or manually enter the product and quantity.\nSpeech\nThe ability to recognize and synthesize speech. For example, a digital assistant might enable users to ask questions or provide audible instructions by speaking into a microphone, and generate spoken output to provide answers or confirmations.\nNatural language processing\nThe ability to process natural language in written or spoken form, analyze it, identify key points, and generate summaries or categorizations. For example, a marketing application might analyze social media messages that mention a particular company, translate them to a specific language, and categorize them as positive or negative based on sentiment analysis.\nInformation extraction\nThe ability to use computer vision, speech, and natural language processing to extract key information from documents, forms, images, recordings, and other kinds of content. For example, an automated expense claims processing application might extract purchase dates, individual line item details, and total costs from a scanned receipt.\nDecision support\nThe ability to use historic data and learned correlations to make predictions that support business decision making. For example, analyzing demographic and economic factors in a city to predict real estate market trends that inform property pricing decisions.\nDetermining the specific AI capabilities you want to include in your application can help you identify the most appropriate AI services that you'll need to provision, configure, and use in your solution.\nA closer look at generative AI\nGenerative AI\nrepresents the latest advance in artificial intelligence, and deserves some extra attention. Generative AI uses\nlanguage models\nto respond to natural language\nprompts\n, enabling you to build conversational apps and agents that support research, content creation, and task automation in ways that were previously unimaginable.\nThe language models used in generative AI solutions can be large language models (LLMs) that have been trained on huge volumes of data and include many millions of parameters; or they can be small language models (SLMs) that are optimized for specific scenarios with lower overhead. Language models commonly respond to text-based prompts with natural language text; though increasingly new\nmulti-modal\nmodels are able to handle image or speech prompts and respond by generating text, code, speech, or images.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "What is AI?"
                },
                {
                  "level": 2,
                  "text": "A closer look at generative AI"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/generative-ai.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/generative-ai.png",
                  "alt_text": "Diagram of speech bubbles.",
                  "title": "",
                  "filename": "generative-ai.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "What is AI?",
                    "following_text": "Determining the specific AI capabilities you want to include in your application can help you identify the most appropriate AI services that you'll need to provision, configure, and use in your soluti",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/agent.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/agent.png",
                  "alt_text": "Diagram of a human head with a cog for a brain.",
                  "title": "",
                  "filename": "agent.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "What is AI?",
                    "following_text": "Determining the specific AI capabilities you want to include in your application can help you identify the most appropriate AI services that you'll need to provision, configure, and use in your soluti",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/computer-vision.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/computer-vision.png",
                  "alt_text": "Diagram of an eye being scanned.",
                  "title": "",
                  "filename": "computer-vision.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "What is AI?",
                    "following_text": "Determining the specific AI capabilities you want to include in your application can help you identify the most appropriate AI services that you'll need to provision, configure, and use in your soluti",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/speech.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/speech.png",
                  "alt_text": "Diagram of a speech bubble and a sound wave.",
                  "title": "",
                  "filename": "speech.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "What is AI?",
                    "following_text": "Determining the specific AI capabilities you want to include in your application can help you identify the most appropriate AI services that you'll need to provision, configure, and use in your soluti",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/natural-language.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/natural-language.png",
                  "alt_text": "Diagram of a text document.",
                  "title": "",
                  "filename": "natural-language.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "What is AI?",
                    "following_text": "Determining the specific AI capabilities you want to include in your application can help you identify the most appropriate AI services that you'll need to provision, configure, and use in your soluti",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/information-extraction.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/information-extraction.png",
                  "alt_text": "Diagram of a form containing information.",
                  "title": "",
                  "filename": "information-extraction.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "What is AI?",
                    "following_text": "Determining the specific AI capabilities you want to include in your application can help you identify the most appropriate AI services that you'll need to provision, configure, and use in your soluti",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/prediction.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/prediction.png",
                  "alt_text": "Diagram of a chart showing an upward trend.",
                  "title": "",
                  "filename": "prediction.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "What is AI?",
                    "following_text": "Determining the specific AI capabilities you want to include in your application can help you identify the most appropriate AI services that you'll need to provision, configure, and use in your soluti",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/prompt.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/prompt.png",
                  "alt_text": "Diagram of a prompt, a language model, and a response.",
                  "title": "",
                  "filename": "prompt.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "A closer look at generative AI",
                    "following_text": "The language models used in generative AI solutions can be large language models (LLMs) that have been trained on huge volumes of data and include many millions of parameters; or they can be small lan",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 3,
              "title": "Azure AI services",
              "url": "https://learn.microsoft.com/en-us/training/modules/prepare-azure-ai-development/3-azure-ai-services",
              "href": "3-azure-ai-services",
              "content": "Read in English\nAdd\nAdd to plan\nAzure AI services\nCompleted\n5 minutes\nMicrosoft Azure provides a wide range of cloud services that you can use to develop, deploy, and manage an AI solution. The most obvious starting point for considering AI development on Azure is Azure AI services; a set of out-of-the-box prebuilt APIs and models that you can integrate into your applications. The following table lists some commonly used Azure AI services (for a full list of all available Azure AI services, see\nAvailable Azure AI services\n).\nService\nDescription\nAzure OpenAI\nAzure OpenAI in Foundry Models provides access to OpenAI generative AI models including the GPT family of large and small language models and DALL-E image-generation models within a scalable and securable cloud service on Azure.\nAzure AI Vision\nThe Azure AI Vision service provides a set of models and APIs that you can use to implement common computer vision functionality in an application. With the AI Vision service, you can detect common objects in images, generate captions, descriptions, and tags based on image contents, and read text in images.\nAzure AI Speech\nThe Azure AI Speech service provides APIs that you can use to implement\ntext to speech\nand\nspeech to text\ntransformation, as well as specialized speech-based capabilities like speaker recognition and translation.\nAzure AI Language\nThe Azure AI Language service provides models and APIs that you can use to analyze natural language text and perform tasks such as entity extraction, sentiment analysis, and summarization. The AI Language service also provides functionality to help you build conversational language models and question answering solutions.\nAzure AI Foundry Content Safety\nAzure AI Foundry Content Safety provides developers with access to advanced algorithms for processing images and text and flagging content that is potentially offensive, risky, or otherwise undesirable.\nAzure AI Translator\nThe Azure AI Translator service uses state-of-the-art language models to translate text between a large number of languages.\nAzure AI Face\nThe Azure AI Face service is a specialist computer vision implementation that can detect, analyze, and recognize human faces. Because of the potential risks associated with personal identification and misuse of this capability, access to some features of the AI Face service are restricted to approved customers.\nAzure AI Custom Vision\nThe Azure AI Custom Vision service enables you to train and use custom computer vision models for image classification and object detection.\nAzure AI Document Intelligence\nWith Azure AI Document Intelligence, you can use pre-built or custom models to extract fields from complex documents such as invoices, receipts, and forms.\nAzure AI Content Understanding\nThe Azure AI Content Understanding service provides multi-modal content analysis capabilities that enable you to build models to extract data from forms and documents, images, videos, and audio streams.\nAzure AI Search\nThe Azure AI Search service uses a pipeline of AI skills based on other Azure AI Services and custom code to extract information from content and create a searchable index. AI Search is commonly used to create vector indexes for data that can then be used to\nground\nprompts submitted to generative AI language models, such as those provided in Azure OpenAI.\nConsiderations for Azure AI services resources\nTo use Azure AI services, you create one or more Azure AI resources in an Azure subscription and implement code in client applications to consume them. In some cases, AI services include web-based visual interfaces that you can use to configure and test your resources - for example to train a custom image classification model using the\nCustom Vision\nservice you can use the visual interface to upload training images, manage training jobs, and deploy the resulting model.\nNote\nYou can provision Azure AI services resources in the Azure portal (or by using BICEP or ARM templates or the Azure command-line interface) and build applications that use them directly through various service-specific APIs and SDKs. However, as we'll discuss later in this module, in most medium to large-scale development scenarios it's better to provision Azure AI services resources as part of an\nAzure AI Foundry\nproject - enabling you to centralize access control and cost management, and making it easier to manage shared resources and build the next generation of generative AI apps and agents.\nSingle service or multi-service resource?\nMost Azure AI services, such as\nAzure AI Vision\n,\nAzure AI Language\n, and so on, can be provisioned as standalone resources, enabling you to create only the Azure resources you specifically need. Additionally, standalone Azure AI services often include a free-tier SKU with limited functionality, enabling you to evaluate and develop with the service at no cost. Each standalone Azure AI resource provides an endpoint and authorization keys that you can use to access it securely from a client application.\nAlternatively, you can provision a multi-service resource that encapsulates multiple AI services in a single Azure resource. Using a multi-service resource can make it easier to manage applications that use multiple AI capabilities. There are two multi-service resource types you can use:\nResource\nDescription\nAzure AI services\nThe Azure AI Services resource type includes the following services, making them available from a single endpoint:\nAzure AI Speech\nAzure AI Language\nAzure AI Translator\nAzure AI Vision\nAzure AI Face\nAzure AI Custom Vision\nAzure AI Document Intelligence\nAzure AI Foundry\nThe Azure AI Foundry resource type includes the following services, and supports working with them through an Azure AI Foundry project*:\nAzure OpenAI\nAzure AI Speech\nAzure AI Language\nAzure AI Foundry Content Safety\nAzure AI Translator\nAzure AI Vision\nAzure AI Face\nAzure AI Document Intelligence\nAzure AI Content Understanding\n* Azure AI Foundry is discussed in the next unit.\nRegional availability\nSome services and models are available in only a subset of Azure regions. Consider service availability and any regional quota restrictions for your subscription when provisioning Azure AI services. Use the\nproduct availability table\nto check regional availability of Azure services. Use the\nmodel availability table\nin the Azure OpenAI documentation to determine regional availability for Azure OpenAI models.\nCost\nAzure AI services are charged based on usage, with different pricing schemes available depending on the specific services being used. As you plan an AI solution on Azure, use the\nAzure AI services pricing\ndocumentation to understand pricing for the AI services you intend to incorporate into your application. You can use the\nAzure pricing calculator\nto estimate the costs your expected usage will incur.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Azure AI services"
                },
                {
                  "level": 2,
                  "text": "Considerations for Azure AI services resources"
                },
                {
                  "level": 3,
                  "text": "Single service or multi-service resource?"
                },
                {
                  "level": 3,
                  "text": "Regional availability"
                },
                {
                  "level": 3,
                  "text": "Cost"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/open-ai.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/open-ai.png",
                  "alt_text": "Azure OpenAI service icon.",
                  "title": "",
                  "filename": "open-ai.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Azure AI services",
                    "following_text": "To use Azure AI services, you create one or more Azure AI resources in an Azure subscription and implement code in client applications to consume them. In some cases, AI services include web-based vis",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/vision.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/vision.png",
                  "alt_text": "Azure AI Vision service icon.",
                  "title": "",
                  "filename": "vision.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Azure AI services",
                    "following_text": "To use Azure AI services, you create one or more Azure AI resources in an Azure subscription and implement code in client applications to consume them. In some cases, AI services include web-based vis",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/speech-service.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/speech-service.png",
                  "alt_text": "Azure AI Speech service icon.",
                  "title": "",
                  "filename": "speech-service.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Azure AI services",
                    "following_text": "To use Azure AI services, you create one or more Azure AI resources in an Azure subscription and implement code in client applications to consume them. In some cases, AI services include web-based vis",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/language.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/language.png",
                  "alt_text": "Azure AI Language service icon.",
                  "title": "",
                  "filename": "language.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Azure AI services",
                    "following_text": "To use Azure AI services, you create one or more Azure AI resources in an Azure subscription and implement code in client applications to consume them. In some cases, AI services include web-based vis",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/content-safety.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/content-safety.png",
                  "alt_text": "Azure AI Foundry Content Safety service icon.",
                  "title": "",
                  "filename": "content-safety.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Azure AI services",
                    "following_text": "To use Azure AI services, you create one or more Azure AI resources in an Azure subscription and implement code in client applications to consume them. In some cases, AI services include web-based vis",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/translator.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/translator.png",
                  "alt_text": "Azure AI Translator service icon.",
                  "title": "",
                  "filename": "translator.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Azure AI services",
                    "following_text": "To use Azure AI services, you create one or more Azure AI resources in an Azure subscription and implement code in client applications to consume them. In some cases, AI services include web-based vis",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/face.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/face.png",
                  "alt_text": "Azure AI Face service icon.",
                  "title": "",
                  "filename": "face.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Azure AI services",
                    "following_text": "To use Azure AI services, you create one or more Azure AI resources in an Azure subscription and implement code in client applications to consume them. In some cases, AI services include web-based vis",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/custom-vision.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/custom-vision.png",
                  "alt_text": "Azure AI Custom Vision service icon.",
                  "title": "",
                  "filename": "custom-vision.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Azure AI services",
                    "following_text": "To use Azure AI services, you create one or more Azure AI resources in an Azure subscription and implement code in client applications to consume them. In some cases, AI services include web-based vis",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/document-intelligence.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/document-intelligence.png",
                  "alt_text": "Azure AI Document Intelligence service icon.",
                  "title": "",
                  "filename": "document-intelligence.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Azure AI services",
                    "following_text": "To use Azure AI services, you create one or more Azure AI resources in an Azure subscription and implement code in client applications to consume them. In some cases, AI services include web-based vis",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/content-understanding.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/content-understanding.png",
                  "alt_text": "Azure AI Content Understanding service icon.",
                  "title": "",
                  "filename": "content-understanding.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Azure AI services",
                    "following_text": "To use Azure AI services, you create one or more Azure AI resources in an Azure subscription and implement code in client applications to consume them. In some cases, AI services include web-based vis",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/search.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/search.png",
                  "alt_text": "Azure AI Search service icon.",
                  "title": "",
                  "filename": "search.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Azure AI services",
                    "following_text": "To use Azure AI services, you create one or more Azure AI resources in an Azure subscription and implement code in client applications to consume them. In some cases, AI services include web-based vis",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/cognitive-services.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/cognitive-services.png",
                  "alt_text": "Azure AI service icon.",
                  "title": "",
                  "filename": "cognitive-services.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Single service or multi-service resource?",
                    "following_text": "* Azure AI Foundry is discussed in the next unit.",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/ai-services.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/ai-services.png",
                  "alt_text": "Azure AI Foundry icon.",
                  "title": "",
                  "filename": "ai-services.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Single service or multi-service resource?",
                    "following_text": "* Azure AI Foundry is discussed in the next unit.",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/ai-services/what-are-ai-services#available-azure-ai-services?azure-portal=true",
                  "text": "Available Azure AI services"
                },
                {
                  "url": "https://azure.microsoft.com/explore/global-infrastructure/products-by-region/table?azure-portal=true",
                  "text": "product availability table"
                },
                {
                  "url": "/en-us/azure/ai-services/openai/concepts/models#model-summary-table-and-region-availability?azure-portal=true",
                  "text": "model availability table"
                },
                {
                  "url": "https://azure.microsoft.com/pricing/details/cognitive-services?azure-portal=true",
                  "text": "Azure AI services pricing"
                },
                {
                  "url": "https://azure.microsoft.com/pricing/calculator?azure-portal=true",
                  "text": "Azure pricing calculator"
                }
              ]
            },
            {
              "number": 4,
              "title": "Azure AI Foundry",
              "url": "https://learn.microsoft.com/en-us/training/modules/prepare-azure-ai-development/4-azure-ai-foundry",
              "href": "4-azure-ai-foundry",
              "content": "Read in English\nAdd\nAdd to plan\nAzure AI Foundry\nCompleted\n5 minutes\nAzure AI Foundry is a platform for AI development on Microsoft Azure. While you\ncan\nprovision individual Azure AI services resources and build applications that consume them without it, the project organization, resource management, and AI development capabilities of Azure AI Foundry makes it the recommended way to build all but the most simple solutions.\nAzure AI Foundry provides the\nAzure AI Foundry portal\n, a web-based visual interface for working with AI projects. It also provides the\nAzure AI Foundry SDK\n, which you can use to build AI solutions programmatically.\nAzure AI Foundry projects\nIn Azure AI Foundry, you manage the resource connections, data, code, and other elements of the AI solution in\nprojects\n. There are two kinds of project:\nFoundry projects\nFoundry projects\nare associated with an\nAzure AI Foundry\nresource in an Azure subscription. Foundry projects provide support for Azure AI Foundry models (including OpenAI models), Azure AI Foundry Agent Service, Azure AI services, and tools for evaluation and responsible AI development.\nAn Azure AI Foundry resource supports the most common AI development tasks to develop generative AI chat apps and agents. In most cases, using a Foundry project provides the right level of resource centralization and capabilities with a minimal amount of administrative resource management. You can use Azure AI Foundry portal to work in projects that are based in Azure AI Foundry resources, making it easy to add connected resources and manage model and agent deployments.\nHub-based projects\nHub-based projects\nare associated with an\nAzure AI hub\nresource in an Azure subscription. Hub-based projects include an Azure AI Foundry resource, as well as managed compute, support for Prompt Flow development, and connected\nAzure storage\nand\nAzure key vault\nresources for secure data storage.\nAzure AI hub resources support advanced AI development scenarios, like developing Prompt Flow based applications or fine-tuning models. You can also use Azure AI hub resources in both Azure AI Foundry portal and Azure Machine learning portal, making it easier to work on collaborative projects that involve data scientists and machine learning specialists as well as developers and AI software engineers\nTip\nFor more information about Azure AI Foundry project types, see\nWhat is Azure AI Foundry?\n.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Azure AI Foundry"
                },
                {
                  "level": 2,
                  "text": "Azure AI Foundry projects"
                },
                {
                  "level": 3,
                  "text": "Foundry projects"
                },
                {
                  "level": 3,
                  "text": "Hub-based projects"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/foundry-project.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/foundry-project.png",
                  "alt_text": "Diagram of a Foundry project.",
                  "title": "",
                  "filename": "foundry-project.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Foundry projects",
                    "following_text": "Foundry projectsare associated with anAzure AI Foundryresource in an Azure subscription. Foundry projects provide support for Azure AI Foundry models (including OpenAI models), Azure AI Foundry Agent ",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/hub-project.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/hub-project.png",
                  "alt_text": "Diagram of a hub-based project.",
                  "title": "",
                  "filename": "hub-project.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Hub-based projects",
                    "following_text": "Hub-based projectsare associated with anAzure AI hubresource in an Azure subscription. Hub-based projects include an Azure AI Foundry resource, as well as managed compute, support for Prompt Flow deve",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/ai-foundry/what-is-azure-ai-foundry?azure-portal=true",
                  "text": "What is Azure AI Foundry?"
                }
              ]
            },
            {
              "number": 5,
              "title": "Developer tools and SDKs",
              "url": "https://learn.microsoft.com/en-us/training/modules/prepare-azure-ai-development/5-tools-and-sdks",
              "href": "5-tools-and-sdks",
              "content": "Read in English\nAdd\nAdd to plan\nDeveloper tools and SDKs\nCompleted\n5 minutes\nWhile you can perform many of the tasks needed to develop an AI solution directly in the Azure AI Foundry portal, developers also need to write, test, and deploy code.\nDevelopment tools and environments\nThere are many development tools and environments available, and developers should choose one that supports the languages, SDKs, and APIs they need to work with and with which they're most comfortable. For example, a developer who focuses strongly on building applications for Windows using the .NET Framework might prefer to work in an integrated development environment (IDE) like Microsoft Visual Studio. Conversely, a web application developer who works with a wide range of open-source languages and libraries might prefer to use a code editor like Visual Studio Code (VS Code). Both of these products are suitable for developing AI applications on Azure.\nThe Azure AI Foundry for Visual Studio Code extension\nWhen developing Azure AI Foundry based generative AI applications in Visual Studio Code, you can use the Azure AI Foundry for Visual Studio Code extension to simplify key tasks in the workflow, including:\nCreating a project.\nSelecting and deploying a model.\nTesting a model in the playground.\nCreating an agent.\nTip\nFor more information about using the Azure AI Foundry for Visual Studio Code extension, see\nWork with the Azure AI Foundry for Visual Studio Code extension\n.\nGitHub and GitHub Copilot\nGitHub is the world's most popular platform for source control and DevOps management, and can be a critical element of any team development effort. Visual Studio and VS Code both provide native integration with GitHub, and access to GitHub Copilot; an AI assistant that can significantly improve developer productivity and effectiveness.\nTip\nFor more information about using GitHub Copilot in Visual Studio Code, see\nGitHub Copilot in VS Code\n.\nProgramming languages, APIs, and SDKs\nYou can develop AI applications using many common programming languages and frameworks, including Microsoft C#, Python, Node, TypeScript, Java, and others. When building AI solutions on Azure, some common SDKs you should plan to install and use include:\nThe\nAzure AI Foundry SDK\n, which enables you to write code to connect to Azure AI Foundry projects and access resource connections, which you can then work with using service-specific SDKs.\nThe\nAzure AI Foundry Models API\n, which provides an interface for working with generative AI model endpoints hosted in Azure AI Foundry.\nThe\nAzure OpenAI in Azure AI Foundry Models API\n, which enables you to build chat applications based on OpenAI models hosted in Azure AI Foundry.\nAzure AI Services SDKs\n- AI service-specific libraries for multiple programming languages and frameworks that enable you to consume Azure AI Services resources in your subscription. You can also use Azure AI Services through their\nREST APIs\n.\nThe\nAzure AI Foundry Agent Service\n, which is accessed through the Azure AI Foundry SDK and can be integrated with frameworks like\nSemantic Kernel\nto build comprehensive AI agent solutions.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Developer tools and SDKs"
                },
                {
                  "level": 2,
                  "text": "Development tools and environments"
                },
                {
                  "level": 3,
                  "text": "The Azure AI Foundry for Visual Studio Code extension"
                },
                {
                  "level": 3,
                  "text": "GitHub and GitHub Copilot"
                },
                {
                  "level": 2,
                  "text": "Programming languages, APIs, and SDKs"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/vs-code.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/vs-code.png",
                  "alt_text": "Screenshot of the Azure AI Foundry Visual Studio Code extension.",
                  "title": "",
                  "filename": "vs-code.png",
                  "image_type": "code_example",
                  "context": {
                    "preceding_heading": "The Azure AI Foundry for Visual Studio Code extension",
                    "following_text": "",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/github-copilot.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/github-copilot.png",
                  "alt_text": "Screenshot of GitHub Copilot in Visual Studio Code.",
                  "title": "",
                  "filename": "github-copilot.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "GitHub and GitHub Copilot",
                    "following_text": "",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/ai-foundry/how-to/develop/get-started-projects-vs-code?azure-portal=true",
                  "text": "Work with the Azure AI Foundry for Visual Studio Code extension"
                },
                {
                  "url": "https://code.visualstudio.com/docs/copilot/overview?azure-portal=true",
                  "text": "GitHub Copilot in VS Code"
                },
                {
                  "url": "/en-us/azure/ai-studio/how-to/develop/sdk-overview?azure-portal=true",
                  "text": "Azure AI Foundry SDK"
                },
                {
                  "url": "/en-us/rest/api/aifoundry/modelinference/",
                  "text": "Azure AI Foundry Models API"
                },
                {
                  "url": "/en-us/azure/ai-services/openai/reference",
                  "text": "Azure OpenAI in Azure AI Foundry Models API"
                },
                {
                  "url": "/en-us/azure/ai-services/reference/sdk-package-resources?azure-portal=true",
                  "text": "Azure AI Services SDKs"
                },
                {
                  "url": "/en-us/azure/ai-services/reference/rest-api-resources",
                  "text": "REST APIs"
                },
                {
                  "url": "/en-us/azure/ai-services/agents/overview?azure-portal=true",
                  "text": "Azure AI Foundry Agent Service"
                },
                {
                  "url": "/en-us/semantic-kernel/overview?azure-portal=true",
                  "text": "Semantic Kernel"
                }
              ]
            },
            {
              "number": 6,
              "title": "Responsible AI",
              "url": "https://learn.microsoft.com/en-us/training/modules/prepare-azure-ai-development/6-responsible-ai",
              "href": "6-responsible-ai",
              "content": "Read in English\nAdd\nAdd to plan\nResponsible AI\nCompleted\n5 minutes\nIt's important for software engineers to consider the impact of their software on users, and society in general; including considerations for its responsible use. When the application is imbued with artificial intelligence, these considerations are particularly important due to the nature of how AI systems work and inform decisions; often based on probabilistic models, which are in turn dependent on the data with which they were trained.\nThe human-like nature of AI solutions is a significant benefit in making applications user-friendly, but it can also lead users to place a great deal of trust in the application's ability to make correct decisions. The potential for harm to individuals or groups through incorrect predictions or misuse of AI capabilities is a major concern, and software engineers building AI-enabled solutions should apply due consideration to mitigate risks and ensure fairness, reliability, and adequate protection from harm or discrimination.\nLet's discuss some core principles for responsible AI that have been adopted at Microsoft.\nFairness\nAI systems should treat all people fairly. For example, suppose you create a machine learning model to support a loan approval application for a bank. The model should make predictions of whether or not the loan should be approved without incorporating any bias based on gender, ethnicity, or other factors that might result in an unfair advantage or disadvantage to specific groups of applicants.\nFairness of machine learned systems is a highly active area of ongoing research, and some software solutions exist for evaluating, quantifying, and mitigating unfairness in machine learned models. However, tooling alone isn't sufficient to ensure fairness. Consider fairness from the beginning of the application development process; carefully reviewing training data to ensure it's representative of all potentially affected subjects, and evaluating predictive performance for subsections of your user population throughout the development lifecycle.\nReliability and safety\nAI systems should perform reliably and safely. For example, consider an AI-based software system for an autonomous vehicle; or a machine learning model that diagnoses patient symptoms and recommends prescriptions. Unreliability in these kinds of system can result in substantial risk to human life.\nAs with any software, AI-based software application development must be subjected to rigorous testing and deployment management processes to ensure that they work as expected before release. Additionally, software engineers need to take into account the probabilistic nature of machine learning models, and apply appropriate thresholds when evaluating confidence scores for predictions.\nPrivacy and security\nAI systems should be secure and respect privacy. The machine learning models on which AI systems are based rely on large volumes of data, which may contain personal details that must be kept private. Even after models are trained and the system is in production, they use new data to make predictions or take action that may be subject to privacy or security concerns; so appropriate safeguards to protect data and customer content must be implemented.\nInclusiveness\nAI systems should empower everyone and engage people. AI should bring benefits to all parts of society, regardless of physical ability, gender, sexual orientation, ethnicity, or other factors.\nOne way to optimize for inclusiveness is to ensure that the design, development, and testing of your application includes input from as diverse a group of people as possible.\nTransparency\nAI systems should be understandable. Users should be made fully aware of the purpose of the system, how it works, and what limitations may be expected.\nFor example, when an AI system is based on a machine learning model, you should generally make users aware of factors that may affect the accuracy of its predictions, such as the number of cases used to train the model, or the specific features that have the most influence over its predictions. You should also share information about the confidence score for predictions.\nWhen an AI application relies on personal data, such as a facial recognition system that takes images of people to recognize them; you should make it clear to the user how their data is used and retained, and who has access to it.\nAccountability\nPeople should be accountable for AI systems. Although many AI systems seem to operate autonomously, ultimately it's the responsibility of the developers who trained and validated the models they use, and defined the logic that bases decisions on model predictions to ensure that the overall system meets responsibility requirements. To help meet this goal, designers and developers of AI-based solution should work within a framework of governance and organizational principles that ensure the solution meets responsible and legal standards that are clearly defined.\nTip\nFor more information about Microsoft's principles for responsible AI, see\nthe Microsoft responsible AI site\n.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Responsible AI"
                },
                {
                  "level": 2,
                  "text": "Fairness"
                },
                {
                  "level": 2,
                  "text": "Reliability and safety"
                },
                {
                  "level": 2,
                  "text": "Privacy and security"
                },
                {
                  "level": 2,
                  "text": "Inclusiveness"
                },
                {
                  "level": 2,
                  "text": "Transparency"
                },
                {
                  "level": 2,
                  "text": "Accountability"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/fairness.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/fairness.png",
                  "alt_text": "A diagram of scales.",
                  "title": "",
                  "filename": "fairness.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Fairness",
                    "following_text": "AI systems should treat all people fairly. For example, suppose you create a machine learning model to support a loan approval application for a bank. The model should make predictions of whether or n",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/reliability-safety.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/reliability-safety.png",
                  "alt_text": "A diagram of a shield.",
                  "title": "",
                  "filename": "reliability-safety.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Reliability and safety",
                    "following_text": "AI systems should perform reliably and safely. For example, consider an AI-based software system for an autonomous vehicle; or a machine learning model that diagnoses patient symptoms and recommends p",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/privacy-security.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/privacy-security.png",
                  "alt_text": "A diagram of a padlock.",
                  "title": "",
                  "filename": "privacy-security.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Privacy and security",
                    "following_text": "AI systems should be secure and respect privacy. The machine learning models on which AI systems are based rely on large volumes of data, which may contain personal details that must be kept private. ",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/inclusiveness.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/inclusiveness.png",
                  "alt_text": "A diagram of a diverse group of people.",
                  "title": "",
                  "filename": "inclusiveness.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Inclusiveness",
                    "following_text": "AI systems should empower everyone and engage people. AI should bring benefits to all parts of society, regardless of physical ability, gender, sexual orientation, ethnicity, or other factors.",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/transparency.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/transparency.png",
                  "alt_text": "A diagram of an eye.",
                  "title": "",
                  "filename": "transparency.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Transparency",
                    "following_text": "AI systems should be understandable. Users should be made fully aware of the purpose of the system, how it works, and what limitations may be expected.",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/accountability.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/accountability.png",
                  "alt_text": "A diagram of a handshake.",
                  "title": "",
                  "filename": "accountability.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Accountability",
                    "following_text": "People should be accountable for AI systems. Although many AI systems seem to operate autonomously, ultimately it's the responsibility of the developers who trained and validated the models they use, ",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "https://microsoft.com/ai/responsible-ai?azure-portal=true",
                  "text": "the Microsoft responsible AI site"
                }
              ]
            },
            {
              "number": 7,
              "title": "Exercise - Prepare for an AI development project",
              "url": "https://learn.microsoft.com/en-us/training/modules/prepare-azure-ai-development/7-exercise-explore-ai-foundry",
              "href": "7-exercise-explore-ai-foundry",
              "content": "Read in English\nAdd\nAdd to plan\nExercise - Prepare for an AI development project\nCompleted\n30 minutes\nIf you have an Azure subscription, you can explore Azure AI Foundry for yourself.\nNote\nIf you don't have an Azure subscription, and you want to explore Azure AI Foundry, you can\nsign up for an account\n, which includes credits for the first 30 days.\nLaunch the exercise and follow the instructions.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Exercise - Prepare for an AI development project"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/prepare-azure-ai-development/media/launch-exercise.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/prepare-azure-ai-development/media/launch-exercise.png",
                  "alt_text": "Button to launch exercise.",
                  "title": "",
                  "filename": "launch-exercise.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Exercise - Prepare for an AI development project",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "https://azure.microsoft.com/free?azure-portal=true",
                  "text": "sign up for an account"
                }
              ]
            },
            {
              "number": 8,
              "title": "Module assessment",
              "url": "https://learn.microsoft.com/en-us/training/modules/prepare-azure-ai-development/8-knowledge-check",
              "href": "8-knowledge-check",
              "content": "Read in English\nAdd\nAdd to plan\nModule assessment\nCompleted\n3 minutes\n1.\nWhich Azure resource provides language and vision services from a single endpoint?\nAzure AI Language\nAzure AI Vision\nAzure AI Services\n2.\nYou plan to create a simple chat app that uses a generative AI model. What kind of project should you create?\nAzure AI Foundry project.\nAzure AI hub based project.\nAzure AI Custom Vision project.\n3.\nWhich SDK enables you to connect to resources in a project?\nAzure AI Services SDK\nSemantic Kernel SDK\nAzure AI Foundry SDK\nYou must answer all questions before checking your work.\nYou must answer all questions before checking your work.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Module assessment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 9,
              "title": "Summary",
              "url": "https://learn.microsoft.com/en-us/training/modules/prepare-azure-ai-development/9-summary",
              "href": "9-summary",
              "content": "Read in English\nAdd\nAdd to plan\nSummary\nCompleted\n1 minute\nIn this module, you explored some of the key considerations when planning and preparing for AI application development. You've also had the opportunity to become familiar with Azure AI Foundry, the recommended platform for developing AI solutions on Azure.\nTip\nFor latest news and information about developing AI applications on Azure, see\nAzure AI\n.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Summary"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "https://azure.microsoft.com/solutions/ai?azure-portal=true",
                  "text": "Azure AI"
                }
              ]
            }
          ]
        },
        {
          "title": "Choose and deploy models from the model catalog in Azure AI Foundry portal",
          "url": "https://learn.microsoft.com/en-us/training/modules/explore-models-azure-ai-studio/",
          "description": "",
          "learning_objectives": [],
          "prerequisites": [],
          "units": [
            {
              "number": 1,
              "title": "Introduction",
              "url": "https://learn.microsoft.com/en-us/training/modules/explore-models-azure-ai-studio/1-introduction",
              "href": "1-introduction",
              "content": "Read in English\nAdd\nAdd to plan\nIntroduction\nCompleted\n1 minute\nGenerative AI applications are built on\nlanguage models\n. The development process usually starts with an exploration and comparison of available\nfoundation\nmodels to find the one that best suits the particular needs of your application. After selecting a suitable model, you deploy it to an endpoint where it can be consumed by a client application or AI agent.\nFoundation models, such as the GPT family of models, are state-of-the-art language models designed to understand, generate, and interact with natural language. Some common use cases for models are:\nSpeech-to-text and text-to-speech conversion\n. For example, generate subtitles for videos.\nMachine translation\n. For example, translate text from English to Japanese.\nText classification\n. For example, label an email as spam or not spam.\nEntity extraction\n. For example, extract keywords or names from a document.\nText summarization\n. For example, generate a short one-paragraph summary from a multi-page document.\nQuestion answering\n. For example, provide answers to questions like \"What is the capital of France?\"\nReasoning\n. For example, solve a mathematical problem.\nIn this module, you focus on exploring foundation models used for question answering. The foundation models you explore can be used for chat applications in which you use a language model to generate a response to a user's question.\nNote\nThe latest breakthrough in generative AI models is owed to the development of the\nTransformer\narchitecture. Transformers were introduced in the\nAttention is all you need\npaper by Vaswani, et al. from 2017\n. The Transformer architecture provided two innovations to NLP that resulted in the emergence of foundation models:\nInstead of processing words sequentially, Transformers process each word independently and in parallel by using\nattention\n.\nNext to the semantic similarity between words, Transformers use\npositional encoding\nto include the information about the position of a word in a sentence.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Introduction"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "https://arxiv.org/abs/1706.03762?azure-portal=true",
                  "text": "Attention is all you needpaper by Vaswani, et al. from 2017"
                }
              ]
            },
            {
              "number": 2,
              "title": "Explore the model catalog",
              "url": "https://learn.microsoft.com/en-us/training/modules/explore-models-azure-ai-studio/2-select-model",
              "href": "2-select-model",
              "content": "Read in English\nAdd\nAdd to plan\nExplore the model catalog\nCompleted\n7 minutes\nThe\nmodel catalog\nin Azure AI Foundry provides a central repository of models that you can browse to find the right language model for your particular generative AI use case.\nSelecting a foundation model for your generative AI app is important as it affects how well your app works. To find the best model for your app, you can use a structured approach by asking yourself the following questions:\nCan AI\nsolve\nmy use case?\nHow do I\nselect\nthe best model for my use case?\nCan I\nscale\nfor real-world workloads?\nLet's explore each of these questions.\nCan AI\nsolve\nmy use case?\nNowadays we have thousands of language models to choose from. The main challenge is to understand if there's a model that satisfies your needs and to answer the question:\nCan AI solve my use case?\nTo start answering this question, you need to discover, filter, and deploy a model. You can explore the available language models through three different catalogs:\nHugging Face\n: Vast catalog of open-source models across various domains.\nGitHub\n: Access to diverse models via GitHub Marketplace and GitHub Copilot.\nAzure AI Foundry\n: Comprehensive catalog with robust tools for deployment.\nThough you can use each of these catalogs to explore models, the model catalog in Azure AI Foundry makes it easiest to explore and deploy a model to build you prototype, while offering the best selection of models.\nLet's explore some of the options you need to consider when searching for suitable models.\nChoose between large and small language models\nFirst of all, you have a choice between Large Language Models (LLMs) and Small Language Models (SLMs).\nLLMs like GPT-4, Mistral Large, Llama3 70B, Llama 405B, and Command R+ are powerful AI models designed for tasks that require deep reasoning, complex content generation, and extensive context understanding.\nSLMs like Phi3, Mistral OSS models, and Llama3 8B are efficient and cost-effective, while still handling many common Natural Language Processing (NLP) tasks. They're perfect for running on lower-end hardware or edge devices, where cost and speed are more important than model complexity.\nFocus on a modality, task, or tool\nLanguage models like GPT-4 and Mistral Large are also known as\nchat completion\nmodels, designed to generate coherent and contextually appropriate text-based responses. When you need higher levels of performance in complex tasks like math, coding, science, strategy, and logistics, you can also use\nreasoning\nmodels like DeepSeek-R1 and o1.\nBeyond text-based AI, some models are\nmulti-modal\n, meaning they can process images, audio, and other data types alongside text. Models like GPT-4o and Phi3-vision are capable of analyzing and generating both text and images. Multi-modal models are useful when your application needs to process and understand images, such as in computer vision or document analysis. Or when you want to build an AI app that interacts with visual content, such as a digital tutor explaining images or charts.\nIf your use case involves\ngenerating images\n, tools like DALLE 3 and Stability AI can create realistic visuals from text prompts. Image generation models are great for designing marketing materials, illustrations, or digital art.\nAnother group of task-specific models are\nembedding models\nlike Ada and Cohere. Embeddings models convert text into numerical representations and are used to improve search relevance by understanding semantic meaning. These models are often implemented in\nRetrieval Augmented Generation\n(\nRAG\n) scenarios to enhance recommendation engines by linking similar content.\nWhen you want to build an application that interacts with other software tools dynamically, you can add\nfunction calling\nand\nJSON support\n. These capabilities allow AI models to work efficiently with structured data, making them useful for automating API calls, database queries, and structured data processing.\nSpecialize with regional and domain-specific models\nCertain models are designed for specific languages, regions, or industries. These models can outperform general-purpose generative AI in their respective domains. For example:\nCore42 JAIS is an Arabic language LLM, making it the best choice for applications targeting Arabic-speaking users.\nMistral Large has a strong focus on European languages, ensuring better linguistic accuracy for multilingual applications.\nNixtla TimeGEN-1 specializes in time-series forecasting, making it ideal for financial predictions, supply chain optimization, and demand forecasting.\nIf your project has regional, linguistic, or industry-specific needs, these models can provide more relevant results than general-purpose AI.\nBalance flexibility and performance with open versus proprietary models\nYou also need to decide whether to use open-source models or proprietary models, each with its own advantages.\nProprietary models\nare best for cutting-edge performance and enterprise use. Azure offers models like OpenAIs GPT-4, Mistral Large, and Cohere Command R+, which deliver industry-leading AI capabilities. These models are ideal for businesses needing enterprise-level security, support, and high accuracy.\nOpen-source models\nare best for flexibility and cost-efficiency. There are hundreds of open-source models available in the Azure AI Foundry model catalog from Hugging Face, and models from Meta, Databricks, Snowflake, and Nvidia. Open models give developers more control, allowing fine-tuning, customization, and local deployment.\nWhatever model you choose, you can use the Azure AI Foundry model catalog. Using models through the model catalog meets the key enterprise requirements for usage:\nData and privacy\n: you get to decide what happens with your data.\nSecurity and compliance\n: built-in security.\nResponsible AI and content safety\n: evaluations and content safety.\nNow you know the language models that are available to you, you should have an understanding of whether AI can indeed solve your use case. If you think a language model would enrich your application, you then need to select the specific model that you want to deploy and integrate.\nHow do I\nselect\nthe best model for my use case?\nTo select the best language model for you use case, you need to decide on what criteria you're using to filter the models. The criteria are the necessary characteristics you identify for a model. Four characteristics you can consider are:\nTask type\n: What type of task do you need the model to perform? Does it include the understanding of only text, or also audio, or video, or multiple modalities?\nPrecision\n: Is the base model good enough or do you need a fine-tuned model that is trained on a specific skill or dataset?\nOpenness\n: Do you want to be able to fine-tune the model yourself?\nDeployment\n: Do you want to deploy the model locally, on a serverless endpoint, or do you want to manage the deployment infrastructure?\nYou already explored the various types of models available in the previous section. Now, let's explore in more detail how precision and performance can be important filters when choosing a model.\nFilter models for precision\nIn generative AI, precision refers to the accuracy of the model in generating correct and relevant outputs. It measures the proportion of true positive results (correct outputs) among all generated outputs. High precision means fewer irrelevant or incorrect results, making the model more reliable.\nWhen integrating a language model into an app, you can choose between a base model or a fine-tuned model. A base model, like GPT-4, is pretrained on a large dataset and can handle various tasks but can lack precision for specific domains. Techniques like prompt engineering can improve this, but sometimes fine-tuning is necessary.\nA fine-tuned model is trained further on a smaller, task-specific dataset to improve its precision and ability to generate relevant outputs for specific applications. You can either use a fine-tuned model or fine-tune a model yourself.\nFilter models for performance\nYou can evaluate your model performance at different phases, using various evaluation approaches.\nWhen you're exploring models through the Azure AI Foundry model catalog, you can use\nmodel benchmarks\nto compare publicly available metrics like coherence and accuracy across models and datasets. These benchmarks can help you in the initial exploration phase, but give little information on how the model would perform in your specific use case.\nBenchmark\nDescription\nAccuracy\nCompares model-generated text with correct answer according to the dataset. Result is one if generated text matches the answer exactly, and zero otherwise.\nCoherence\nMeasures whether the model output flows smoothly, reads naturally, and resembles human-like language.\nFluency\nAssesses how well the generated text adheres to grammatical rules, syntactic structures, and appropriate usage of vocabulary, resulting in linguistically correct and natural-sounding responses.\nGroundedness\nMeasures alignment between the model's generated answers and the input data.\nGPT Similarity\nQuantifies the semantic similarity between a ground truth sentence (or document) and the prediction sentence generated by an AI model.\nQuality index\nA comparative aggregate score between 0 and 1, with better-performing models scoring a higher value\nCost\nThe cost of using the model based on a price-per-token. Cost is a useful metric with which to compare quality, enabling you to determine an appropriate tradeoff for your needs.\nTo evaluate how a selected model performs regarding your specific requirements, you can consider\nmanual\nor\nautomated\nevaluations. Manual evaluations allow you to rate your model's responses. Automated evaluations include traditional machine learning metrics and AI-assisted metrics that are calculated and generated for you.\nWhen you evaluate a models performance, it's common to start with manual evaluations, as they quickly assess the quality of the models responses. For more systematic comparisons, automated evaluations using metrics like precision, recall, and F1 score based on your own ground truth offer a faster, scalable, and more objective approach.\nCan I\nscale\nfor real-world workloads?\nYou selected a model for your use case and have successfully built a prototype. Now, you need to understand how to scale for real-world workloads.\nConsiderations for scaling a generative AI solution include:\nModel deployment\n: Where will you deploy the model for the best balance of performance and cost?\nModel monitoring and optimization\n: How will you monitor, evaluate, and optimize model performance?\nPrompt management\n: How will you orchestrate and optimize prompts to maximize the accuracy and relevance of generated responses?\nModel lifecycle\n: How will you manage model, data, and code updates as part of an ongoing\nGenerative AI Operations\n(GenAIOps) lifecycle?\nAzure AI Foundry provides visual and code-first tools that can help you build and maintain a scalable generative AI solution.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Explore the model catalog"
                },
                {
                  "level": 2,
                  "text": "Can AIsolvemy use case?"
                },
                {
                  "level": 3,
                  "text": "Choose between large and small language models"
                },
                {
                  "level": 3,
                  "text": "Focus on a modality, task, or tool"
                },
                {
                  "level": 3,
                  "text": "Specialize with regional and domain-specific models"
                },
                {
                  "level": 3,
                  "text": "Balance flexibility and performance with open versus proprietary models"
                },
                {
                  "level": 2,
                  "text": "How do Iselectthe best model for my use case?"
                },
                {
                  "level": 3,
                  "text": "Filter models for precision"
                },
                {
                  "level": 3,
                  "text": "Filter models for performance"
                },
                {
                  "level": 2,
                  "text": "Can Iscalefor real-world workloads?"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/explore-models-azure-ai-studio/media/model-catalog.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/explore-models-azure-ai-studio/media/model-catalog.png",
                  "alt_text": "Screenshot of the model catalog in Azure AI Foundry portal.",
                  "title": "",
                  "filename": "model-catalog.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Explore the model catalog",
                    "following_text": "Selecting a foundation model for your generative AI app is important as it affects how well your app works. To find the best model for your app, you can use a structured approach by asking yourself th",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "https://huggingface.co/models",
                  "text": "Hugging Face"
                },
                {
                  "url": "https://github.com/marketplace/models-github",
                  "text": "GitHub"
                },
                {
                  "url": "https://ai.azure.com/explore/models",
                  "text": "Azure AI Foundry"
                }
              ]
            },
            {
              "number": 3,
              "title": "Deploy a model to an endpoint",
              "url": "https://learn.microsoft.com/en-us/training/modules/explore-models-azure-ai-studio/3-deploy-model",
              "href": "3-deploy-model",
              "content": "Read in English\nAdd\nAdd to plan\nDeploy a model to an endpoint\nCompleted\n5 minutes\nWhen you develop a generative AI app, you need to integrate language models into your application. To be able to use a language model, you need to deploy the model. Let's explore how to deploy language models in the Azure AI Foundry, after first understanding why to deploy a model.\nWhy deploy a model?\nYou train a model to generate output based on some input. To get value out of your model, you need a solution that allows you to send input to the model, which the model processes, after which the output is visualized for you.\nWith generative AI apps, the most common type of solution is a chat application that expects a user question, which the model processes, to generate an adequate response. The response is then visualized to the user as a response to their question.\nYou can integrate a language model with a chat application by deploying the model to an\nendpoint\n. An endpoint is a specific URL where a deployed model or service can be accessed. Each model deployment typically has its own unique endpoint, which allows different applications to communicate with the model through an\nAPI\n(\nApplication Programming Interface\n).\nWhen a user asks a question:\nAn API request is sent to the endpoint.\nThe endpoint specifies the model that processes the request.\nThe result is sent back to the app through an API response.\nNow that you understand why you want to deploy a model, let's explore the deployment options with Azure AI Foundry.\nDeploy a language model with Azure AI Foundry\nWhen you deploy a language model with Azure AI Foundry, you have several types available, which depend on the model you want to deploy.\nDeploy options include:\nStandard deployment\n: Models are hosted in the Azure AI Foundry project resource.\nServerless compute\n: Models are hosted in Microsoft-managed dedicated serverless endpoints in an Azure AI Foundry hub project.\nManaged compute\n: Models are hosted in managed virtual machine images in an Azure AI Foundry hub project.\nThe associated cost depends on the type of model you deploy, which deployment option you choose, and what you are doing with the model:\nStandard deployment\nServerless compute\nManaged compute\nSupported models\nAzure AI Foundry models (including Azure OpenAI models and Models-as-a-service models)\nFoundry Models with pay-as-you-go billing\nOpen and custom models\nHosting service\nAzure AI Foundry resource\nAI Project resource in a hub\nAI Project resource in a hub\nBilling basis\nToken-based billing\nToken-based billing\nCompute-based billing\nNote\nStandard deployment\nis recommended for most scenarios.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Deploy a model to an endpoint"
                },
                {
                  "level": 2,
                  "text": "Why deploy a model?"
                },
                {
                  "level": 2,
                  "text": "Deploy a language model with Azure AI Foundry"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/explore-models-azure-ai-studio/media/request-endpoint.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/explore-models-azure-ai-studio/media/request-endpoint.png",
                  "alt_text": "Diagram of user question being processed by model deployed to endpoint.",
                  "title": "",
                  "filename": "request-endpoint.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Why deploy a model?",
                    "following_text": "You can integrate a language model with a chat application by deploying the model to anendpoint. An endpoint is a specific URL where a deployed model or service can be accessed. Each model deployment ",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 4,
              "title": "Optimize model performance",
              "url": "https://learn.microsoft.com/en-us/training/modules/explore-models-azure-ai-studio/4-improve-model",
              "href": "4-improve-model",
              "content": "Read in English\nAdd\nAdd to plan\nOptimize model performance\nCompleted\n8 minutes\nAfter you deploy your model to an endpoint, you can start interacting with it to see how it works. Let's explore how you can use prompt engineering techniques to optimize your model's performance.\nApply prompt patterns to optimize your model's output\nThe quality of the questions you send to the language model, directly influences the quality of the responses you get back. You can carefully construct your question, or\nprompt\n, to receive better and more interesting responses. The process of designing and optimizing prompts to improve the model's performance is also known as\nprompt engineering\n.\nPrompt engineering requires users to ask relevant, specific, unambiguous, and well-structured questions, instructing the model to generate more accurate responses. To understand how to create well-defined prompts, let's explore some patterns that help you improve the output of a model:\nInstruct the model to act as a persona.\nGuide the model to suggest better questions.\nProvide a template to generate output in a specific format.\nUnderstand how a model reasons by asking it to reflect.\nAdd context to improve the accuracy of the model's output.\nNote\nThe patterns listed here are based on the work by\nWhite et al., (2023) who constructed a prompt pattern catalog\n.\nAs a developer, an effective approach is to add instructions to your deployed model in the form of a\nsystem prompt\n. The system prompt sets the model's behavior and allows you to guide the model without exposing the end user to the instructions. The best results are often achieved through the assignment of an explicit system prompt and guidance (or templates) that help users submit prompts that reflect the patterns described here.\nInstruct the model to act as a persona\nWhen you want the model to take a specific point of view or perspective when answering a question, you can ask it to act as a persona.\nFor example, you can ask the model to respond as if it's a seasoned marketing professional if you're working in sales and need insights about a new CRM software.\nNo persona specified\nWith persona specified\nSystem prompt\nNone\nYou're a seasoned marketing professional that writes advertising copy for an audience of technical customers.\nUser prompt\nWrite a one-sentence description of a CRM product.\nWrite a one-sentence description of a CRM product.\nModel response\nA CRM product is a software tool designed to manage a company's interactions with current and potential customers, encompassing sales, marketing, customer service, and technical support.\nExperience seamless customer relationship management with our CRM product, designed to streamline your business operations, enhance customer interactions, and drive sales growth with its intuitive interface and robust analytics tools.\nYou can create different personas for various business roles. Think of roles like a product manager, data analyst, customer service expert, or teacher. Define the persona and add more detail to what you expect that persona to know or do to get tailored, context-driven responses.\nAsk for better question suggestions\nWhen you want the model to help refine your question, you can ask it to suggest better ways to phrase your query. You can also ask it to provide extra context.\nFor example, if you're seeking advice on cooking a meal, you can prompt the model to suggest clarifying questions to help you get a more targeted answer.\nNo suggestions given\nWith suggestions given\nSystem prompt\nYou're an AI chef who can advise on menus.\nYou're an AI chef who can advise on menus. You're approachable and always want to provide the best advice you can.\nUser prompt\nI have to host a dinner party for four people. What should I cook?\nI have to host a dinner party for four people. What should I cook? What other information do you need to help me plan a great meal for my guests?\nModel response\nHosting a dinner party for four is a wonderful opportunity to showcase your culinary skills. Here's a suggested three-course menu that balances flavors and provides a pleasant dining experience:\nAppetizer\nCaprese Salad Skewers\n-\nIngredients\n: Cherry tomatoes, fresh mozzarella balls, fresh basil leaves, balsamic glaze, olive oil, salt, and pepper.\n-\nInstructions\n: Thread a cherry tomato, a basil leaf, and a mozzarella ball onto small skewers. Drizzle with olive oil and balsamic glaze, then season with salt and pepper. This dish is light, refreshing, and easy to prepare ahead of time.\nMain Course\nHerb-Crusted Salmon with Lemon Asparagus\n-\nIngredients\n: Salmon fillets, fresh herbs (such as parsley, dill, and thyme), breadcrumbs, lemon, asparagus, olive oil, salt, and pepper.\n-\nInstructions\n: Preheat your oven to 400F (200C). Mix breadcrumbs with chopped fresh herbs and a bit of olive oil to form a paste. Press this mixture onto the salmon fillets and season with salt and pepper. Place salmon on a baking sheet and bake for about 15-20 minutes, or until cooked through. In the last 10 minutes of cooking, toss asparagus with olive oil, lemon zest, salt, and pepper, and roast alongside the salmon. Serve with a squeeze of fresh lemon juice over the salmon and asparagus.\nDessert\nChocolate Mousse with Fresh Berries\n-\nIngredients\n: Dark chocolate, eggs, sugar, heavy cream, vanilla extract, and mixed berries (such as strawberries, blueberries, and raspberries).\n-\nInstructions\n: Melt the chocolate over a double boiler, then let it cool slightly. Separate egg yolks and whites. Whip the egg whites to soft peaks, then gradually add sugar to make a meringue. Whip the heavy cream until soft peaks form and mix in vanilla extract. Fold the melted chocolate into the egg yolks, then gently fold in the whipped cream and meringue until combined. Spoon the mousse into serving dishes and refrigerate for at least 2 hours. Serve topped with fresh berries for a burst of color and freshness.\nAdditional Tips\n-\nPairings\n: Consider serving a light white wine with the appetizer and main course, and perhaps a dessert wine with the chocolate mousse.\n-\nTiming\n: Prepare the appetizer and dessert in advance to minimize last-minute stress. The main course will take the most time in the oven, so plan accordingly.\nThis menu is designed to be elegant yet approachable, ensuring your guests enjoy both the food and the experience. Enjoy your dinner party!\nHosting a dinner party is a wonderful opportunity to showcase your culinary skills and create memorable experiences for your guests. To help you plan a great meal, here are a few questions that can guide you in choosing the perfect menu:\nDietary Preferences/Restrictions\n: Are any of your guests vegetarian, vegan, gluten-free, or have any food allergies or intolerances? Knowing this will help in selecting dishes that everyone can enjoy.\nFlavor Preferences\n: Do your guests have any favorite cuisines or flavors? For example, do they enjoy Italian, Mexican, Mediterranean, or perhaps something more adventurous like Thai or Indian?\nTime and Skill Level\n: How much time do you have to prepare the meal, and what is your comfort level in the kitchen? Are you looking for a simple meal or are you up for something more elaborate?\nOccasion\n: Is this a casual get-together, a celebration, or something more formal? The nature of the event might influence the menu style.\nSeasonal Ingredients\n: Are you interested in using seasonal ingredients? This can help in choosing fresh and flavorful produce.\nDrinks Pairing\n: Would you like to include alcoholic or non-alcoholic beverages to pair with the meal?\nWith this information, I can suggest a tailored menu. Heres a general idea that can be adapted based on your answers:\nStarter\nGarden Salad with Citrus Vinaigrette\n: Fresh greens, seasonal vegetables, and a light citrus dressing.\nStuffed Mushrooms\n: For a vegetarian option, filled with herbs and cheese.\nMain Course\nHerb-Crusted Chicken Breast\n: Served with roasted vegetables.\nQuinoa Stuffed Bell Peppers\n: A flavorful vegetarian or vegan option.\nSide Dishes\nGarlic Butter Roasted Potatoes\n: Classic and comforting.\nSteamed Green Beans with Almonds\n: A simple, healthy side.\nDessert\nChocolate Lava Cake\n: A decadent treat to end the meal.\nFruit Tart\n: A lighter, refreshing option.\nDrinks\nWine Pairing\n: A versatile white wine like Sauvignon Blanc or a light red like Pinot Noir.\nMocktail Option\n: A refreshing citrus mocktail or sparkling water with herbs.\nFeel free to share more details, and I can help refine the menu further!\nWhen you encourage the model to suggest clarifications or extra details can help you ask the right questions and achieve better, more accurate answers in fewer interactions.\nSpecify the desired format for responses\nWhen you want the model to generate output in a specific format, you can provide a template or structure in your prompt.\nFor example, if you're a sports reporting composing a historical article, you can request that the model follow a specific template, which includes headings, bullet points, and data breakdowns.\nNo template specified\nWith template specified\nSystem prompt\nYou're a helpful AI assistant.\nYou're a helpful AI assistant for sports reporters.\nUser prompt\nWhat happened in the 2018 Soccer World Cup final?\nWhat happened in the 2018 Soccer World Cup final? Format the result to show the match date, location, and the two teams competing. Then the final score, and finally any notable events that occurred during the match.\nModel response\nThe 2018 FIFA World Cup final took place on July 15, 2018, at the Luzhniki Stadium in Moscow, Russia. France faced Croatia in the match. France emerged victorious with a 4-2 win. The goals for France were scored by Mario Mandzukic (own goal), Antoine Griezmann (penalty), Paul Pogba, and Kylian Mbapp. Croatia's goals were scored by Ivan Perii and Mandzukic. Kylian Mbapp, at just 19 years old, became the second youngest player to score in a World Cup final, after Pel. This victory marked France's second World Cup title, their first being in 1998.\nMatch Date\n: July 15, 2018\nLocation\n: Luzhniki Stadium, Moscow, Russia\nTeams Competing\n: France vs. Croatia\nFinal Score\n: France 4, Croatia 2\nNotable Events\n:\nFirst Half\n: France took an early lead in the 18th minute with an own goal by Mario Manduki after a cross from Antoine Griezmann. Croatia equalized in the 28th minute with a header from Ivan Perii, who had just come on as a substitute. Just before halftime, in the 44th minute, Paul Pogba scored from a free kick to put France back in the lead.\nSecond Half\n: The game saw a dramatic increase in intensity after the break. In the 68th minute, Kylian Mbapp scored his first World Cup goal, bringing the score to 3-1 in favor of France. Croatia managed to score again in the 69th minute when Manduki headed in a cross from Perii, reducing the deficit to 3-2.\nFinal Moments\n: In the 81st minute, a controversial penalty was awarded to France after a handball by Croatian defender Dejan Lovren. Griezmann converted the penalty, sealing the victory for France with a 4-2 scoreline.\nAdditional Context\n: This match was notable for being the youngest ever World Cup final in terms of average age, featuring players like Mbapp and NGolo Kant. Frances victory marked their second World Cup title, having previously won in 1998. Croatia reached the final for the first time in their history, finishing as runners-up.\nYou can apply this approach to other scenarios where a specific format is needed, such as generating emails, summaries, proposals, or even code and scripts. Define the format template clearly and provide details on how you want the output structured to get consistent and organized responses.\nYou can also use a\none-shot\nor\nfew-shots\napproach by providing one or more examples to help the model identify a desired pattern.\nAsk for an explanation of reasoning\nWhen you want the model to explain the reasoning behind its answers, you can ask the model to automatically reflect on its rationale and assumptions after providing a response.\nFor example, if you're working on a mathematical problem, you can ask the model to explain the reasoning behind specific calculations.\nNo reflection specified\nWith reflection specified\nSystem prompt\nYou're an AI math assistant.\nYou're an AI math assistant. You always explain your answers.\nUser prompt\nA right-angled triangle has a hypotenuse side of length 3 cm and an adjacent side length of 2cm.What is the length of the remaining side?\nA right-angled triangle has a hypotenuse side of length 3 cm and an adjacent side length of 2cm.What is the length of the remaining side?\nModel response\nApproximately 2.24 cm.\nWe can use the Pythagorean theorem to solve this problem. The Pythagorean theorem states that in a right-angled triangle, the square of the length of the hypotenuse (the side opposite the right angle) is equal to the sum of the squares of the lengths of the other two sides. Mathematically, this can be written as:\nc = a + b\nwhere\nc\nis the length of the hypotenuse, and\na\nand\nb\nare the lengths of the other two sides.\nIn this problem, we are given the length of the hypotenuse (c = 3 cm) and the length of one of the other sides (a = 2 cm). We need to find the length of the remaining side (b).\nPlugging the given values into the Pythagorean theorem, we get:\n3 = 2 + b\n9 = 4 + b\nNow, we can solve for b:\nb = 9 - 4\nb = 5\nFinally, we take the square root of both sides to find the length of the remaining side:\nb = 5  2.24 cm\nSo, the length of the remaining side is approximately 2.24 cm.\nYou can apply this approach when you want explanations in data analysis, marketing strategy, or technical troubleshooting. When you ask the model to define its reasoning, you use a technique called\nchain-of-thought\nto make it think step by step.\nAdd context\nWhen you want the model to focus on specific topics, you can specify the context to consider. You can also tell the model to ignore irrelevant information.\nFor example, if you're planning a trip, you can provide the model with more context to help improve the relevance of its response.\nNo context specified\nWith context specified\nSystem prompt\nYou're an AI travel assistant.\nYou're an AI travel assistant.\nUser question\nWhen should I visit Edinburgh?\nWhen should I visit Edinburgh? I'm particularly interested in attending Scotland's home matches in the Six Nations rugby tournament.\nModel response\nEdinburgh, the capital city of Scotland, is a wonderful destination with a rich history and vibrant culture. The best time to visit Edinburgh largely depends on your preferences for weather, events, and tourist crowds.\nSpring (April to June): The weather starts to warm up, and the days get longer. Springtime is perfect for exploring the city's historic sites, gardens, and parks, such as the Royal Botanic Garden. The Edinburgh Festival Fringe, the world's largest arts festival, takes place in August, which is the end of summer.\nSummer (July to August): The weather is at its warmest, and the days are long. This is a popular time to visit, but it can also be crowded with tourists. Summer is ideal for outdoor activities, and you can enjoy the Edinburgh International Festival and the Royal Edinburgh Military Tattoo.\nAutumn (September to November): The weather begins to cool down, and the leaves change color, creating a picturesque backdrop for the city's historic architecture. It's less crowded, and you can enjoy events like the Edinburgh International Book Festival.\nWinter (December to February): The weather is colder, and there may be snowfall, which can create a magical atmosphere. Winter is a quieter time to visit, with fewer tourists and lower prices. You can attend events like the Edinburgh Christmas Market and the Hogmanay Street Party, which celebrates the New Year.\nIn summary, the best time to visit Edinburgh depends on your preferences. Spring and autumn offer pleasant weather and fewer crowds, while summer is ideal for outdoor activities and festivals. Winter can be a quieter, more magical experience, with festive events to enjoy.\nThe Six Nations rugby tournament typically runs from late January to early March. Edinburgh, as a host city, often has matches at Murrayfield Stadium, which is Scotland's national stadium. To ensure you don't miss Scotland's home matches in the Six Nations, I recommend planning your visit for this period.\nHowever, keep in mind that match dates and times can vary, so it's a good idea to check the official Six Nations website or the Scottish Rugby Union's website for the exact schedule of matches. Additionally, Edinburgh has a lot to offer beyond rugby, with its rich history, stunning architecture, and vibrant cultural scene, so you might consider extending your stay to explore the city before or after the tournament.\nAlso, remember that visiting during the tournament might mean larger crowds and busier accommodations, so book your flights, hotel, and transportation well in advance to ensure a smooth experience. Enjoy your trip to Edinburgh and the thrilling atmosphere of the Six Nations rugby matches!\nBy defining what the model should focus on or disregard, you can ensure the conversation stays on track and generate more relevant, tailored responses.\nYou can specify the context by describing what it should or shouldn't include, and by connecting the model to data sources it should retrieve context from before generating an answer.\nApply model optimization strategies\nNote\nThis section discusses options and considerations for model optimization that you may consider beyond prompt engineering. A full exploration of\nhow\nto apply these optimization strategies is beyond the scope of this module.\nPrompt engineering can be an effective way to optimize model responses, but in some cases it may not provide sufficient context or guidance to always meet your exact needs. As a developer, you can consider the following additional optimization strategies to improve the relevance of your generative AI application's responses:\nRetrieval Augmented Generation (RAG)\n: A technique that involves using a data source to provide\ngrounding\ncontext to prompts. RAG can be a useful approach when you need the model to answer questions based on a specific knowledge domain or when you need the model to consider information related to events that occurred after the training data on which the model is based.\nFine-tuning\n: A technique that involves extending the training of a foundation model by providing example prompts and responses that reflect the desired output format and style.\nBoth of these approaches involve additional cost, complexity, and maintainability challenges, so as a general rule it's best to start your optimization efforts through prompt engineering, and then consider additional strategies if necessary.\nThe strategy you should choose as a developer depends on your requirements:\nOptimize for context\n: When the model lacks contextual knowledge and you want to\nmaximize responses accuracy\n.\nOptimize the model\n: When you want to improve the response format, style, or speech by\nmaximizing consistency of behavior\n.\nTo optimize for context, you can apply a\nRetrieval Augmented Generation\n(\nRAG\n) pattern. With RAG, you\nground\nyour data by first retrieving context from a data source before generating a response. For example, you want employees to ask questions about expense claim processes and limits based on your own corporation's expenses policy documentation.\nWhen you want the model to respond in a specific style or format, you can instruct the model to do so by adding guidelines in the system message. When you notice the model's behavior isn't consistent, you can further enforce consistency in behavior by\nfine-tuning\na model. With fine-tuning, you train a base language model on a dataset of example prompts and responses before integrating it in your application, with the result that the fine-tuned model will produce responses that are consistent with the examples in the fine-tuning training dataset.\nYou can use any combination of optimization strategies, for example prompt engineering, RAG\nand\na fine-tuned model, to improve your language application.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Optimize model performance"
                },
                {
                  "level": 2,
                  "text": "Apply prompt patterns to optimize your model's output"
                },
                {
                  "level": 3,
                  "text": "Instruct the model to act as a persona"
                },
                {
                  "level": 3,
                  "text": "Ask for better question suggestions"
                },
                {
                  "level": 3,
                  "text": "Specify the desired format for responses"
                },
                {
                  "level": 3,
                  "text": "Ask for an explanation of reasoning"
                },
                {
                  "level": 3,
                  "text": "Add context"
                },
                {
                  "level": 2,
                  "text": "Apply model optimization strategies"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/explore-models-azure-ai-studio/media/model-optimization.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/explore-models-azure-ai-studio/media/model-optimization.png",
                  "alt_text": "Diagram showing the various strategies to optimize the model's performance.",
                  "title": "",
                  "filename": "model-optimization.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Apply model optimization strategies",
                    "following_text": "To optimize for context, you can apply aRetrieval Augmented Generation(RAG) pattern. With RAG, yougroundyour data by first retrieving context from a data source before generating a response. For examp",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "https://arxiv.org/abs/2302.11382?azure-portal=true",
                  "text": "White et al., (2023) who constructed a prompt pattern catalog"
                }
              ]
            },
            {
              "number": 5,
              "title": "Exercise - Explore, deploy, and chat with language models",
              "url": "https://learn.microsoft.com/en-us/training/modules/explore-models-azure-ai-studio/5-exercise",
              "href": "5-exercise",
              "content": "Read in English\nAdd\nAdd to plan\nExercise - Explore, deploy, and chat with language models\nCompleted\n15 minutes\nNow, it's your chance to explore how to select, deploy, and test language models in the Azure AI Foundry portal.\nNote\nTo complete this lab, you will need an\nAzure subscription\nin which you have administrative access.\nLaunch the exercise and follow the instructions.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Exercise - Explore, deploy, and chat with language models"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/explore-models-azure-ai-studio/media/launch-exercise.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/explore-models-azure-ai-studio/media/launch-exercise.png",
                  "alt_text": "Button to launch exercise.",
                  "title": "",
                  "filename": "launch-exercise.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Exercise - Explore, deploy, and chat with language models",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "https://azure.microsoft.com/free?azure-portal=true",
                  "text": "Azure subscription"
                }
              ]
            },
            {
              "number": 6,
              "title": "Module assessment",
              "url": "https://learn.microsoft.com/en-us/training/modules/explore-models-azure-ai-studio/6-knowledge-check",
              "href": "6-knowledge-check",
              "content": "Read in English\nAdd\nAdd to plan\nModule assessment\nCompleted\n3 minutes\n1.\nWhere can you test a deployed model in the Azure AI Foundry portal?\nChat playground\nSandbox\nDevelopment toolbox\n2.\nYou want to specify the tone, format, and content for each interaction with your model in the playground. What should you use to customize the model response?\nBenchmarks\nGrounding\nSystem message\n3.\nWhat deployment option should you choose to host an OpenAI model in an Azure AI Foundry resource?\nStandard deployment\nServerless compute\nManaged compute\nYou must answer all questions before checking your work.\nYou must answer all questions before checking your work.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Module assessment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 7,
              "title": "Summary",
              "url": "https://learn.microsoft.com/en-us/training/modules/explore-models-azure-ai-studio/7-summary",
              "href": "7-summary",
              "content": "Read in English\nAdd\nAdd to plan\nSummary\nCompleted\n1 minute\nIn this module, you learned how to:\nSelect a language model from the model catalog.\nDeploy a model to an endpoint.\nTest a model and improve the performance of the model.\nLearn more\nModel catalog and collections in Azure AI Foundry portal\nDeploy AI models in Azure AI Foundry portal\nPrompt engineering techniques\nAzure AI Foundry Discord\nAzure AI Foundry Developer Forum\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Summary"
                },
                {
                  "level": 3,
                  "text": "Learn more"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/ai-foundry/how-to/model-catalog-overview",
                  "text": "Model catalog and collections in Azure AI Foundry portal"
                },
                {
                  "url": "/en-us/azure/ai-foundry/concepts/deployments-overview",
                  "text": "Deploy AI models in Azure AI Foundry portal"
                },
                {
                  "url": "/en-us/azure/ai-services/openai/concepts/prompt-engineering",
                  "text": "Prompt engineering techniques"
                },
                {
                  "url": "https://aka.ms/azureaifoundry/discord",
                  "text": "Azure AI Foundry Discord"
                },
                {
                  "url": "https://aka.ms/azureaifoundry/forum",
                  "text": "Azure AI Foundry Developer Forum"
                }
              ]
            }
          ]
        },
        {
          "title": "Develop an AI app with the Azure AI Foundry SDK",
          "url": "https://learn.microsoft.com/en-us/training/modules/ai-foundry-sdk/",
          "description": "",
          "learning_objectives": [],
          "prerequisites": [],
          "units": [
            {
              "number": 1,
              "title": "Introduction",
              "url": "https://learn.microsoft.com/en-us/training/modules/ai-foundry-sdk/01-introduction",
              "href": "01-introduction",
              "content": "Read in English\nAdd\nAdd to plan\nIntroduction\nCompleted\n1 minute\nDevelopers creating AI solutions with Azure AI Foundry need to work with a combination of services and software frameworks. The Azure AI Foundry SDK is designed to bring together common services and code libraries in an AI project through a central programmatic access point, making it easier for developers to write the code needed to build effective AI apps on Azure.\nIn this module, you'll learn how to use the Azure AI Foundry SDK to work with resources in an AI project.\nNote\nAzure AI Foundry SDK is currently in public preview. Details described in this module are subject to change.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Introduction"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 5,
              "title": "Exercise - Create a generative AI chat app",
              "url": "https://learn.microsoft.com/en-us/training/modules/ai-foundry-sdk/05-exercise",
              "href": "05-exercise",
              "content": "Read in English\nAdd\nAdd to plan\nExercise - Create a generative AI chat app\nCompleted\n30 minutes\nNow it's your turn to try using the Azure AI Foundry SDK!\nIn this exercise, you use the Azure AI Foundry SDK to connect to a project and create an application that chats with a generative AI model.\nNote\nTo complete this lab, you need an\nAzure subscription\nin which you have administrative access.\nLaunch the exercise and follow the instructions.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Exercise - Create a generative AI chat app"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/ai-foundry-sdk/media/launch-exercise.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/ai-foundry-sdk/media/launch-exercise.png",
                  "alt_text": "Button to launch exercise.",
                  "title": "",
                  "filename": "launch-exercise.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Exercise - Create a generative AI chat app",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "https://azure.microsoft.com/free?azure-portal=true",
                  "text": "Azure subscription"
                }
              ]
            },
            {
              "number": 7,
              "title": "Summary",
              "url": "https://learn.microsoft.com/en-us/training/modules/ai-foundry-sdk/07-summary",
              "href": "07-summary",
              "content": "Read in English\nAdd\nAdd to plan\nSummary\nCompleted\n1 minute\nBy using the Azure AI Foundry SDK, you can develop rich AI applications that use resources in your Azure AI Foundry projects. The Azure AI Foundry SDK\nAIProjectClient\nclass provides a programmatic proxy for a project, enabling you to access connected resources and to use service-specific libraries to consume them.\nLearn more\nThe Azure AI Foundry SDK\nAzure AI Foundry Discord\nAzure AI Foundry Developer Forum\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Summary"
                },
                {
                  "level": 3,
                  "text": "Learn more"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/ai-studio/how-to/develop/sdk-overview",
                  "text": "The Azure AI Foundry SDK"
                },
                {
                  "url": "https://aka.ms/azureaifoundry/discord",
                  "text": "Azure AI Foundry Discord"
                },
                {
                  "url": "https://aka.ms/azureaifoundry/forum",
                  "text": "Azure AI Foundry Developer Forum"
                }
              ]
            }
          ]
        },
        {
          "title": "Get started with prompt flow to develop language model apps in the Azure AI Foundry",
          "url": "https://learn.microsoft.com/en-us/training/modules/get-started-prompt-flow-ai-studio/",
          "description": "",
          "learning_objectives": [],
          "prerequisites": [],
          "units": [
            {
              "number": 1,
              "title": "Introduction",
              "url": "https://learn.microsoft.com/en-us/training/modules/get-started-prompt-flow-ai-studio/1-introduction",
              "href": "1-introduction",
              "content": "Read in English\nAdd\nAdd to plan\nIntroduction\nCompleted\n3 minutes\nThe true power of\nLarge Language Models\n(\nLLMs\n) lies in their application. Whether you want to use LLMs to classify web pages into categories, or to build a chatbot on your data. To harness the power of the LLMs available, you need to create an application that combines your data sources with LLMs and generates the desired output.\nTo develop, test, tune, and deploy LLM applications, you can use\nprompt flow\n, accessible in the\nAzure Machine Learning studio\nand the\nAzure AI Foundry portal\n.\nNote\nThe focus of this module is on understanding and exploring prompt flow through Azure AI Foundry. However, note that the content applies to the prompt flow experience in both Azure Machine Learning and Azure AI Foundry.\nPrompt flow takes a\nprompt\nas input, which in the context of LLMs, refers to the query provided to the LLM application to generate a response. It's the text or set of instructions given to the LLM application, prompting it to generate output or perform a specific task.\nFor example, when you want to use a text generation model, the prompt might be a sentence or a paragraph that initiates the generation process. In the context of a question-answering model, the prompt could be a query asking for information on a particular topic. The effectiveness of the prompt often depends on how well it conveys the user's intent and the desired outcome.\nPrompt flow allows you to create\nflows\n, which refers to the sequence of actions or steps that are taken to achieve a specific task or functionality. A flow represents the overall process or pipeline that incorporates the interaction with the LLM to address a particular use case. The flow encapsulates the entire journey from receiving input to generating output or performing a desired action.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Introduction"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/prompt-flow/overview-what-is-prompt-flow?azure-portal=true",
                  "text": "Azure Machine Learning studio"
                },
                {
                  "url": "/en-us/azure/ai-studio/how-to/prompt-flow?azure-portal=true",
                  "text": "Azure AI Foundry portal"
                }
              ]
            },
            {
              "number": 2,
              "title": "Understand the development lifecycle of a large language model (LLM) app",
              "url": "https://learn.microsoft.com/en-us/training/modules/get-started-prompt-flow-ai-studio/2-understand-lifecycle",
              "href": "2-understand-lifecycle",
              "content": "Read in English\nAdd\nAdd to plan\nUnderstand the development lifecycle of a large language model (LLM) app\nCompleted\n8 minutes\nBefore understanding how to work with prompt flow, let's explore the development lifecycle of a Large Language Model (LLM) application.\nThe lifecycle consists of the following stages:\nInitialization\n: Define the use case and design the solution.\nExperimentation\n: Develop a flow and test with a small dataset.\nEvaluation and refinement\n: Assess the flow with a larger dataset.\nProduction\n: Deploy and monitor the flow and application.\nDuring both evaluation and refinement, and production, you might find that your solution needs to be improved. You can revert back to experimentation during which you develop your flow continuously, until you're satisfied with the results.\nLet's explore each of these phases in more detail.\nInitialization\nImagine you want to design and develop an LLM application to classify news articles. Before you start creating anything, you need to define what categories you want as output. You need to understand what a typical news article looks like, how you present the article as input to your application, and how the application generates the desired output.\nIn other words, during\ninitialization\nyou:\nDefine the\nobjective\nCollect a\nsample dataset\nBuild a\nbasic prompt\nDesign the\nflow\nTo design, develop, and test an LLM application, you need a sample dataset that serves as the input. A sample dataset is a small representative subset of the data you eventually expect to parse as input to your LLM application.\nWhen collecting or creating the sample dataset, you should ensure diversity in the data to cover various scenarios and edge cases. You should also remove any privacy sensitive information from the dataset to avoid any vulnerabilities.\nExperimentation\nYou collected a sample dataset of news articles, and decided on which categories you want the articles to be classified into. You designed a flow that takes a news article as input, and uses an LLM to classify the article. To test whether your flow generates the expected output, you run it against your sample dataset.\nThe\nexperimentation\nphase is an iterative process during which you (1)\nrun\nthe flow against a sample dataset. You then (2)\nevaluate\nthe prompt's performance. If you're (3) satisfied with the result, you can\nmove on\nto evaluation and refinement. If you think there's room for improvement, you can (4)\nmodify\nthe flow by changing the prompt or flow itself.\nEvaluation and refinement\nWhen you're satisfied with the output of the flow that classifies news articles, based on the sample dataset, you can assess the flow's performance against a larger dataset.\nBy testing the flow on a larger dataset, you can evaluate how well the LLM application generalizes to new data. During evaluation, you can identify potential bottlenecks or areas for optimization or refinement.\nWhen you edit your flow, you should first run it against a smaller dataset before running it again against a larger dataset. Testing your flow with a smaller dataset allows you to more quickly respond to any issues.\nOnce your LLM application appears to be robust and reliable in handling various scenarios, you can decide to move the LLM application to production.\nProduction\nFinally, your news article classification application is ready for\nproduction\n.\nDuring production, you:\nOptimize\nthe flow that classifies incoming articles for efficiency and effectiveness.\nDeploy\nyour flow to an endpoint. When you call the endpoint, the flow is triggered to run and the desired output is generated.\nMonitor\nthe performance of your solution by collecting usage data and end-user feedback. By understanding how the application performs, you can improve the flow whenever necessary.\nExplore the complete development lifecycle\nNow that you understand each stage of the development lifecycle of an LLM application, you can explore the complete overview:\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Understand the development lifecycle of a large language model (LLM) app"
                },
                {
                  "level": 2,
                  "text": "Initialization"
                },
                {
                  "level": 2,
                  "text": "Experimentation"
                },
                {
                  "level": 2,
                  "text": "Evaluation and refinement"
                },
                {
                  "level": 2,
                  "text": "Production"
                },
                {
                  "level": 2,
                  "text": "Explore the complete development lifecycle"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/get-started-prompt-flow-ai-studio/media/development-lifecycle.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/get-started-prompt-flow-ai-studio/media/development-lifecycle.png",
                  "alt_text": "Diagram of the four stages of the development lifecycle.",
                  "title": "",
                  "filename": "development-lifecycle.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Understand the development lifecycle of a large language model (LLM) app",
                    "following_text": "During both evaluation and refinement, and production, you might find that your solution needs to be improved. You can revert back to experimentation during which you develop your flow continuously, u",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/get-started-prompt-flow-ai-studio/media/initialization.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/get-started-prompt-flow-ai-studio/media/initialization.png",
                  "alt_text": "Diagram of the four steps during initialization.",
                  "title": "",
                  "filename": "initialization.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Initialization",
                    "following_text": "To design, develop, and test an LLM application, you need a sample dataset that serves as the input. A sample dataset is a small representative subset of the data you eventually expect to parse as inp",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/get-started-prompt-flow-ai-studio/media/experimentation.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/get-started-prompt-flow-ai-studio/media/experimentation.png",
                  "alt_text": "Diagram of the four steps during experimentation.",
                  "title": "",
                  "filename": "experimentation.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Experimentation",
                    "following_text": "Theexperimentationphase is an iterative process during which you (1)runthe flow against a sample dataset. You then (2)evaluatethe prompt's performance. If you're (3) satisfied with the result, you can",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/get-started-prompt-flow-ai-studio/media/production.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/get-started-prompt-flow-ai-studio/media/production.png",
                  "alt_text": "Diagram of the three steps during production.",
                  "title": "",
                  "filename": "production.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Production",
                    "following_text": "During production, you:",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/get-started-prompt-flow-ai-studio/media/detailed-lifecycle.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/get-started-prompt-flow-ai-studio/media/detailed-lifecycle.png",
                  "alt_text": "Diagram of all stages including their steps of the development lifecycle.",
                  "title": "",
                  "filename": "detailed-lifecycle.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Explore the complete development lifecycle",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 3,
              "title": "Understand core components and explore flow types",
              "url": "https://learn.microsoft.com/en-us/training/modules/get-started-prompt-flow-ai-studio/3-understand-flows",
              "href": "3-understand-flows",
              "content": "Read in English\nAdd\nAdd to plan\nUnderstand core components and explore flow types\nCompleted\n5 minutes\nTo create a Large Language Model (LLM) application with prompt flow, you need to understand prompt flow's core components.\nUnderstand a flow\nPrompt flow is a feature within Azure AI Foundry that allows you to author\nflows\n. Flows are executable workflows often consist of three parts:\nInputs\n: Represent data passed into the flow. Can be different data types like strings, integers, or boolean.\nNodes\n: Represent\ntools\nthat perform data processing, task execution, or algorithmic operations.\nOutputs\n: Represent the data produced by the flow.\nSimilar to a pipeline, a flow can consist of multiple nodes that can use the flow's inputs or any output generated by another node. You can add a node to a flow by choosing one of the available types of\ntools\n.\nExplore the tools available in prompt flow\nThree common tools are:\nLLM tool\n: Enables custom prompt creation utilizing Large Language Models.\nPython tool\n: Allows the execution of custom Python scripts.\nPrompt tool\n: Prepares prompts as strings for complex scenarios or integration with other tools.\nEach tool is an executable unit with a specific function. You can use a tool to perform tasks like summarizing text, or making an API call. You can use multiple tools within one flow and use a tool multiple times.\nTip\nIf you're looking for functionality that is not offered by the available tools, you can\ncreate your own custom tool\n.\nWhenever you add a new node to your flow, adding a new tool, you can define the expected inputs and outputs. A node can use one of the whole flow's inputs, or another node's output, effectively linking nodes together.\nBy defining the inputs, connecting nodes, and defining the desired outputs, you can create a flow. Flows help you create LLM applications for various purposes.\nUnderstand the types of flows\nThere are three different types of flows you can create with prompt flow:\nStandard flow\n: Ideal for general LLM-based application development, offering a range of versatile tools.\nChat flow\n: Designed for conversational applications, with enhanced support for chat-related functionalities.\nEvaluation flow\n: Focused on performance evaluation, allowing the analysis and improvement of models or applications through feedback on previous runs.\nNow that you understand how a flow is structured and what you can use it for, let's explore how you can create a flow.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Understand core components and explore flow types"
                },
                {
                  "level": 2,
                  "text": "Understand a flow"
                },
                {
                  "level": 2,
                  "text": "Explore the tools available in prompt flow"
                },
                {
                  "level": 2,
                  "text": "Understand the types of flows"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/get-started-prompt-flow-ai-studio/media/flow-pipeline.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/get-started-prompt-flow-ai-studio/media/flow-pipeline.png",
                  "alt_text": "Diagram of the three components of a flow pipeline.",
                  "title": "",
                  "filename": "flow-pipeline.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Understand a flow",
                    "following_text": "Similar to a pipeline, a flow can consist of multiple nodes that can use the flow's inputs or any output generated by another node. You can add a node to a flow by choosing one of the available types ",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "https://microsoft.github.io/promptflow/how-to-guides/develop-a-tool/create-and-use-tool-package.html?azure-portal=true",
                  "text": "create your own custom tool"
                }
              ]
            },
            {
              "number": 4,
              "title": "Explore connections and runtimes",
              "url": "https://learn.microsoft.com/en-us/training/modules/get-started-prompt-flow-ai-studio/4-connections-runtimes",
              "href": "4-connections-runtimes",
              "content": "Read in English\nAdd\nAdd to plan\nExplore connections and runtimes\nCompleted\n4 minutes\nWhen you create a Large Language Model (LLM) application with prompt flow, you first need to configure any necessary\nconnections\nand\nruntimes\n.\nExplore connections\nWhenever you want your flow to connect to external data source, service, or API, you need your flow to be authorized to communicate with that external service. When you create a\nconnection\n, you configure a secure link between prompt flow and external services, ensuring seamless and safe data communication.\nDepending on the type of connection you create, the connection securely stores the endpoint, API key, or credentials necessary for prompt flow to communicate with the external service. Any necessary secrets aren't exposed to users, but instead are stored in an Azure Key Vault.\nBy setting up connections, users can easily reuse external services necessary for tools in their flows.\nCertain built-in tools require you to have a connection configured:\nConnection type\nBuilt-in tools\nAzure OpenAI\nLLM or Python\nOpenAI\nLLM or Python\nAzure AI Search\nVector DB Lookup or Python\nSerp\nSerp API or Python\nCustom\nPython\nPrompt flow connections play pivotal roles in two scenarios. They automate API credential management, simplifying and securing the handling of sensitive access information. Additionally, they enable secure data transfer from various sources, crucial for maintaining data integrity and privacy across different environments.\nExplore runtimes\nAfter creating your flow, and configuring the necessary connections your tools use, you want to run your flow. To run the flow, you need compute, which is offered through prompt flow\nruntimes\n.\nRuntimes (1) are a combination of a\ncompute instance\n(2) providing the necessary compute resources, and an\nenvironment\n(3) specifying the necessary packages and libraries that need to be installed before being able to run the flow.\nWhen you use runtimes, you have a controlled environment where flows can be run and validated, ensuring that everything works as intended in a stable setting. A default environment is available for quick development and testing. When you require other packages to be installed, you can\ncreate a custom environment\n.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Explore connections and runtimes"
                },
                {
                  "level": 2,
                  "text": "Explore connections"
                },
                {
                  "level": 2,
                  "text": "Explore runtimes"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/get-started-prompt-flow-ai-studio/media/connections.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/get-started-prompt-flow-ai-studio/media/connections.png",
                  "alt_text": "Diagram showing a flow with two nodes, connecting to Azure AI Search and Azure OpenAI.",
                  "title": "",
                  "filename": "connections.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Explore connections",
                    "following_text": "Depending on the type of connection you create, the connection securely stores the endpoint, API key, or credentials necessary for prompt flow to communicate with the external service. Any necessary s",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/get-started-prompt-flow-ai-studio/media/runtimes.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/get-started-prompt-flow-ai-studio/media/runtimes.png",
                  "alt_text": "Diagram runtimes, compute, and environments in relation to flows.",
                  "title": "",
                  "filename": "runtimes.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Explore runtimes",
                    "following_text": "Runtimes (1) are a combination of acompute instance(2) providing the necessary compute resources, and anenvironment(3) specifying the necessary packages and libraries that need to be installed before ",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/prompt-flow/how-to-customize-environment-runtime?azure-portal=true",
                  "text": "create a custom environment"
                }
              ]
            },
            {
              "number": 5,
              "title": "Explore variants and monitoring options",
              "url": "https://learn.microsoft.com/en-us/training/modules/get-started-prompt-flow-ai-studio/5-variants-monitor",
              "href": "5-variants-monitor",
              "content": "Read in English\nAdd\nAdd to plan\nExplore variants and monitoring options\nCompleted\n6 minutes\nDuring production, you want to optimize and deploy your flow. Finally, you want to monitor your flows to understand when improving your flows is necessary.\nYou can optimize your flow by using\nvariants\n, you can deploy your flow to an\nendpoint\n, and you can monitor your flow by evaluating key metrics.\nExplore variants\nPrompt flow\nvariants\nare versions of a tool node with distinct settings. Currently, variants are only supported in the LLM tool, where a variant can represent a different prompt content or connection setting. Variants allow users to customize their approach for specific tasks, like, summarizing news articles.\nSome benefits of using variants are:\nEnhance the quality of your LLM generation\n: Creating diverse variants of an LLM node helps find the best prompt and settings for high-quality content.\nSave time and effort\n: Variants allow for easy management and comparison of different prompt versions, streamlining historical tracking and reducing the effort in prompt tuning.\nBoost productivity\n: They simplify the optimization of LLM nodes, enabling quicker creation and management of variations, leading to better results in less time.\nFacilitate easy comparison\n: Variants enable side-by-side result comparisons, aiding in choosing the most effective variant based on data-driven decisions.\nDeploy your flow to an endpoint\nWhen you're satisfied with the performance of your flow, you can choose to deploy it to an\nonline endpoint\n. Endpoints are URLs that you can call from any application. When you make an API call to an online endpoint, you can expect (almost) immediate response.\nWhen you deploy your flow to an online endpoint, prompt flow generates a URL and key so you can safely integrate your flow with other applications or business processes. When you invoke the endpoint, a flow is run and the output is returned in real-time. As a result, deploying flows to endpoints can for example generate chat or agentic responses that you want to return in another application.\nMonitor evaluation metrics\nIn prompt flow, monitoring evaluation metrics is key to understanding your LLM application's performance, ensuring they meet real-world expectations and deliver accurate results.\nTo understand whether your application is meeting practical needs, you can collect end-user feedback and assess the application's usefulness. Another approach to understanding whether your application is performing well, is by comparing LLM predictions with expected or\nground truth\nresponses to gauge accuracy and relevance. Evaluating the LLM's predictions is crucial for keeping LLM applications reliable and effective.\nMetrics\nThe key metrics used for monitoring evaluation in prompt flow each offer unique insight into the performance of LLMs:\nGroundedness\n: Measures alignment of the LLM application's output with the input source or database.\nRelevance\n: Assesses how pertinent the LLM application's output is to the given input.\nCoherence\n: Evaluates the logical flow and readability of the LLM application's text.\nFluency\n: Assesses the grammatical and linguistic accuracy of the LLM application's output.\nSimilarity\n: Quantifies the contextual and semantic match between the LLM application's output and the ground truth.\nMetrics like\ngroundedness\n,\nrelevance\n,\ncoherence\n,\nfluency\n, and\nsimilarity\nare key for quality assurance, ensuring that interactions with your LLM applications are accurate and effective. Whenever your LLM application doesn't perform as expected, you need to revert back to experimentation to iteratively explore how to improve your flow.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Explore variants and monitoring options"
                },
                {
                  "level": 2,
                  "text": "Explore variants"
                },
                {
                  "level": 2,
                  "text": "Deploy your flow to an endpoint"
                },
                {
                  "level": 2,
                  "text": "Monitor evaluation metrics"
                },
                {
                  "level": 3,
                  "text": "Metrics"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 6,
              "title": "Exercise - Get started with prompt flow",
              "url": "https://learn.microsoft.com/en-us/training/modules/get-started-prompt-flow-ai-studio/6-exercise",
              "href": "6-exercise",
              "content": "Read in English\nAdd\nAdd to plan\nExercise - Get started with prompt flow\nCompleted\n15 minutes\nNow, it's your chance to explore how to develop LLM apps with prompt flow.\nIn this exercise, you create a standard flow with prompt flow in the Azure AI Foundry portal.\nNote\nTo complete this lab, you need an\nAzure subscription\nin which you have administrative access.\nLaunch the exercise and follow the instructions.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Exercise - Get started with prompt flow"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/get-started-prompt-flow-ai-studio/media/launch-exercise.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/get-started-prompt-flow-ai-studio/media/launch-exercise.png",
                  "alt_text": "Button to launch exercise.",
                  "title": "",
                  "filename": "launch-exercise.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Exercise - Get started with prompt flow",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "https://azure.microsoft.com/free?azure-portal=true",
                  "text": "Azure subscription"
                }
              ]
            },
            {
              "number": 7,
              "title": "Module assessment",
              "url": "https://learn.microsoft.com/en-us/training/modules/get-started-prompt-flow-ai-studio/7-knowledge-check",
              "href": "7-knowledge-check",
              "content": "Read in English\nAdd\nAdd to plan\nModule assessment\nCompleted\n3 minutes\n1.\nA flow uses an LLM tool to generate text with a GPT-3.5 model. What do you need to create to ensure prompt flow can securely call the deployed model from Azure OpenAI?\nRuntimes\nConnections\nTools\n2.\nYou want to integrate your flow with an online website. What do you need to do to easily integrate your flow?\nCreate a custom environment.\nCreate a runtime.\nDeploy your flow to an endpoint.\n3.\nAfter deployment, you notice that your flow is underperforming. Which stage in the development lifecycle should you revert back to?\nExperimentation\nEvaluation and refinement\nProduction\nYou must answer all questions before checking your work.\nYou must answer all questions before checking your work.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Module assessment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 8,
              "title": "Summary",
              "url": "https://learn.microsoft.com/en-us/training/modules/get-started-prompt-flow-ai-studio/8-summary",
              "href": "8-summary",
              "content": "Read in English\nAdd\nAdd to plan\nSummary\nCompleted\n1 minute\nIn this module, you learned:\nThe development lifecycle when creating LLM applications.\nWhat a flow is in prompt flow.\nThe core components when working with prompt flow.\nLearn more\nPrompt flow in Azure AI Foundry portal\nPrompt engineering techniques\nAzure AI Foundry Discord\nAzure AI Foundry Developer Forum\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Summary"
                },
                {
                  "level": 3,
                  "text": "Learn more"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/ai-foundry/concepts/prompt-flow",
                  "text": "Prompt flow in Azure AI Foundry portal"
                },
                {
                  "url": "/en-us/azure/ai-services/openai/concepts/prompt-engineering",
                  "text": "Prompt engineering techniques"
                },
                {
                  "url": "https://aka.ms/azureaifoundry/discord",
                  "text": "Azure AI Foundry Discord"
                },
                {
                  "url": "https://aka.ms/azureaifoundry/forum",
                  "text": "Azure AI Foundry Developer Forum"
                }
              ]
            }
          ]
        },
        {
          "title": "Develop a RAG-based solution with your own data using Azure AI Foundry",
          "url": "https://learn.microsoft.com/en-us/training/modules/build-copilot-ai-studio/",
          "description": "",
          "learning_objectives": [],
          "prerequisites": [],
          "units": [
            {
              "number": 1,
              "title": "Introduction",
              "url": "https://learn.microsoft.com/en-us/training/modules/build-copilot-ai-studio/1-introduction",
              "href": "1-introduction",
              "content": "Read in English\nAdd\nAdd to plan\nIntroduction\nCompleted\n2 minutes\nLanguage models are growing in popularity as they create impressive coherent answers to a users questions. Especially when a user interacts with a language model through chat, it provides an intuitive way to get the information they need.\nOne prevalent challenge when implementing language models through chat is the so-called\ngroundedness\n, which refers to whether a response is rooted, connected, or anchored in reality or a specific context. In other words, groundedness refers to whether the response of a language model is based on factual information.\nUngrounded prompts and responses\nWhen you use a language model to generate a response to a prompt, the only information that the model has to base the answer on comes from the data on which it was trained - which is often just a large volume of uncontextualized text from the Internet or some other source.\nThe result will likely be a grammatically coherent and logical response to the prompt, but because it isn't grounded in relevant, factual data, it's uncontextualized; and may in fact be inaccurate and include \"invented\" information. For example, the question \"Which product should I use to do\nX\n?\" might include details of a fictional product.\nGrounded prompts and responses\nIn contrast, you can use a data source to\nground\nthe prompt with some relevant, factual context. The prompt can then be submitted to a language model, including the grounding data, to generate a contextualized, relevant, and accurate response.\nThe data source can be any repository of relevant data. For example, you could use data from a product catalog database to ground the prompt \"Which product should I use to do\nX\n?\" so that the response includes relevant details of products that exist in the catalog.\nIn this module, you explore how to create your own chat-based language model application that is grounded, by building an agent with your own data.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Introduction"
                },
                {
                  "level": 2,
                  "text": "Ungrounded prompts and responses"
                },
                {
                  "level": 2,
                  "text": "Grounded prompts and responses"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/build-copilot-ai-studio/media/ungrounded.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/build-copilot-ai-studio/media/ungrounded.png",
                  "alt_text": "Diagram of an ungrounded model returning an uncontextualized response.",
                  "title": "",
                  "filename": "ungrounded.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Ungrounded prompts and responses",
                    "following_text": "The result will likely be a grammatically coherent and logical response to the prompt, but because it isn't grounded in relevant, factual data, it's uncontextualized; and may in fact be inaccurate and",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/build-copilot-ai-studio/media/grounded.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/build-copilot-ai-studio/media/grounded.png",
                  "alt_text": "Diagram of a grounded model returning a contextualized response.",
                  "title": "",
                  "filename": "grounded.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Grounded prompts and responses",
                    "following_text": "The data source can be any repository of relevant data. For example, you could use data from a product catalog database to ground the prompt \"Which product should I use to doX?\" so that the response i",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 2,
              "title": "Understand how to ground your language model",
              "url": "https://learn.microsoft.com/en-us/training/modules/build-copilot-ai-studio/2-ground-language-model",
              "href": "2-ground-language-model",
              "content": "Read in English\nAdd\nAdd to plan\nUnderstand how to ground your language model\nCompleted\n6 minutes\nLanguage models excel in generating engaging text, and are ideal as the base for agents. Agents provide users with an intuitive chat-based application to receive assistance in their work. When designing an agent for a specific use case, you want to ensure your language model is grounded and uses factual information that is relevant to what the user needs.\nThough language models are trained on a vast amount of data, they may not have access to the knowledge you want to make available to your users. To ensure that an agent is grounded on specific data to provide accurate and domain-specific responses, you can use\nRetrieval Augmented Generation\n(\nRAG\n).\nUnderstanding RAG\nRAG is a technique that you can use to ground a language model. In other words, it's a process for retrieving information that is relevant to the user's initial prompt. In general terms, the RAG pattern incorporates the following steps:\nRetrieve\ngrounding data based on the initial user-entered prompt.\nAugment\nthe prompt with grounding data.\nUse a language model to\ngenerate\na grounded response.\nBy retrieving context from a specified data source, you ensure that the language model uses relevant information when responding, instead of relying on its training data.\nUsing RAG is a powerful and easy-to-use technique for many cases in which you want to ground your language model and improve the factual accuracy of your generative AI app's responses.\nAdding grounding data to an Azure AI project\nYou can use Azure AI Foundry to build a custom age that uses your own data to ground prompts. Azure AI Foundry supports a range of data connections that you can use to add data to a project, including:\nAzure Blob Storage\nAzure Data Lake Storage Gen2\nMicrosoft OneLake\nYou can also upload files or folders to the storage used by your AI Foundry project.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Understand how to ground your language model"
                },
                {
                  "level": 2,
                  "text": "Understanding RAG"
                },
                {
                  "level": 2,
                  "text": "Adding grounding data to an Azure AI project"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/build-copilot-ai-studio/media/rag-pattern.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/build-copilot-ai-studio/media/rag-pattern.png",
                  "alt_text": "Diagram of the retrieval augmented generation pattern.",
                  "title": "",
                  "filename": "rag-pattern.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Understanding RAG",
                    "following_text": "By retrieving context from a specified data source, you ensure that the language model uses relevant information when responding, instead of relying on its training data.",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/build-copilot-ai-studio/media/add-data.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/build-copilot-ai-studio/media/add-data.png",
                  "alt_text": "Screenshot of the Add Data dialog in Azure AI Foundry portal.",
                  "title": "",
                  "filename": "add-data.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Adding grounding data to an Azure AI project",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 3,
              "title": "Make your data searchable",
              "url": "https://learn.microsoft.com/en-us/training/modules/build-copilot-ai-studio/3-search-data",
              "href": "3-search-data",
              "content": "Read in English\nAdd\nAdd to plan\nMake your data searchable\nCompleted\n7 minutes\nWhen you want to create an agent that uses your own data to generate accurate answers, you need to be able to search your data efficiently. When you build an agent with the Azure AI Foundry, you can use the integration with\nAzure AI Search\nto retrieve the relevant context in your chat flow.\nAzure AI Search is a\nretriever\nthat you can include when building a language model application with prompt flow. Azure AI Search allows you to bring your own data, index your data, and query the index to retrieve any information you need.\nUsing a\nvector\nindex\nWhile a text-based index will improve search efficiency, you can usually achieve a better data retrieval solution by using a\nvector\n-based index that contains\nembeddings\nthat represent the text tokens in your data source.\nAn embedding is a special format of data representation that a search engine can use to easily find the relevant information. More specifically, an embedding is a vector of floating-point numbers.\nFor example, imagine you have two documents with the following contents:\n\"The children played joyfully in the park.\"\n\"Kids happily ran around the playground.\"\nThese two documents contain texts that are semantically related, even though different words are used. By creating vector embeddings for the text in the documents, the relation between the words in the text can be mathematically calculated.\nImagine the keywords being extracted from the document and plotted as a vector in a multidimensional space:\nThe distance between vectors can be calculated by measuring the cosine of the angle between two vectors, also known as the\ncosine similarity\n. In other words, the cosine similarity computes the semantic similarity between documents and a query.\nBy representing words and their meanings with vectors, you can extract relevant context from your data source even when your data is stored in different formats (text or image) and languages.\nWhen you want to be able to use vector search to search your data, you need to create embeddings when creating your search index. To create embeddings for your search index, you can use an Azure OpenAI embedding model available in Azure AI Foundry.\nTip\nLearn more about\nembeddings in the Azure OpenAI in Foundry Models\n.\nCreating a search index\nIn Azure AI Search, a\nsearch index\ndescribes how your content is organized to make it searchable. Imagine a library containing many books. You want to be able to search through the library and retrieve the relevant book easily and efficiently. To make the library searchable, you create a catalog that contains any relevant data about books to make any book easy to find. A librarys catalog serves as the search index.\nThough there are different approaches to creating an index, the integration of Azure AI Search in Azure AI Foundry makes it easy for you to create an index that is suitable for language models. You can add your data to Azure AI Foundry, after which you can use Azure AI Search to create an index in the Azure AI Foundry portal using an embedding model. The index asset is stored in Azure AI Search and queried by Azure AI Foundry when used in a chat flow.\nHow you configure your search index depends on the data you have and the context you want your language model to use. For example,\nkeyword search\nenables you to retrieve information that exactly matches the search query.\nSemantic search\nalready takes it one step further by retrieving information that matches the meaning of the query instead of the exact keyword, using semantic models. Currently, the most advanced technique is\nvector search\n, which creates embeddings to represent your data.\nTip\nLearn more about\nvector search\n.\nSearching an index\nThere are several ways that information can be queried in an index:\nKeyword search\n: Identifies relevant documents or passages based on specific keywords or terms provided as input.\nSemantic search\n: Retrieves documents or passages by understanding the meaning of the query and matching it with semantically related content rather than relying solely on exact keyword matches.\nVector search\n: Uses mathematical representations of text (vectors) to find similar documents or passages based on their semantic meaning or context.\nHybrid search\n: Combines any or all of the other search techniques. Queries are executed in parallel and are returned in a unified result set.\nWhen you create a search index in Azure AI Foundry, you're guided to configuring an index that is most suitable to use in combination with a language model. When your search results are used in a generative AI application, hybrid search gives the most accurate results.\nHybrid search is a combination of keyword (and full text), and vector search, to which semantic ranking is optionally added. When you create an index that is compatible with hybrid search, the retrieved information is precise when exact matches are available (using keywords), and still relevant when only conceptually similar information can be found (using vector search).\nTip\nLearn more about\nhybrid search\n.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Make your data searchable"
                },
                {
                  "level": 2,
                  "text": "Using avectorindex"
                },
                {
                  "level": 2,
                  "text": "Creating a search index"
                },
                {
                  "level": 2,
                  "text": "Searching an index"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/build-copilot-ai-studio/media/index.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/build-copilot-ai-studio/media/index.png",
                  "alt_text": "Diagram showing an index being queried to retrieve grounding data.",
                  "title": "",
                  "filename": "index.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Make your data searchable",
                    "following_text": "While a text-based index will improve search efficiency, you can usually achieve a better data retrieval solution by using avector-based index that containsembeddingsthat represent the text tokens in ",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/build-copilot-ai-studio/media/vector-embeddings.jpg",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/build-copilot-ai-studio/media/vector-embeddings.jpg",
                  "alt_text": "Diagram of vector embeddings.",
                  "title": "",
                  "filename": "vector-embeddings.jpg",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Using avectorindex",
                    "following_text": "The distance between vectors can be calculated by measuring the cosine of the angle between two vectors, also known as thecosine similarity. In other words, the cosine similarity computes the semantic",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/build-copilot-ai-studio/media/vector-index.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/build-copilot-ai-studio/media/vector-index.png",
                  "alt_text": "Diagram showing a vector index that contains embeddings.",
                  "title": "",
                  "filename": "vector-index.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Using avectorindex",
                    "following_text": "",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/build-copilot-ai-studio/media/create-index.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/build-copilot-ai-studio/media/create-index.png",
                  "alt_text": "Screenshot of creating an index in Azure AI Foundry.",
                  "title": "",
                  "filename": "create-index.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Creating a search index",
                    "following_text": "How you configure your search index depends on the data you have and the context you want your language model to use. For example,keyword searchenables you to retrieve information that exactly matches",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/ai-services/openai/concepts/understand-embeddings?azure-portal=true",
                  "text": "embeddings in the Azure OpenAI in Foundry Models"
                },
                {
                  "url": "/en-us/azure/search/vector-search-overview?azure-portal=true",
                  "text": "vector search"
                },
                {
                  "url": "/en-us/azure/search/hybrid-search-overview?azure-portal=true",
                  "text": "hybrid search"
                }
              ]
            },
            {
              "number": 4,
              "title": "Implement RAG in a prompt flow",
              "url": "https://learn.microsoft.com/en-us/training/modules/build-copilot-ai-studio/4-build-copilot",
              "href": "4-build-copilot",
              "content": "Read in English\nAdd\nAdd to plan\nImplement RAG in a prompt flow\nCompleted\n7 minutes\nAfter uploading data to Azure AI Foundry and creating an index on your data using the integration with Azure AI Search, you can implement the RAG pattern with\nPrompt Flow\nto build a generative AI application.\nPrompt Flow\nis a development framework for defining flows that orchestrate interactions with an LLM.\nA flow begins with one or more\ninputs\n, usually a question or prompt entered by a user, and in the case of iterative conversations the chat history to this point.\nThe flow is then defined as a series of connected\ntools\n, each of which performs a specific operation on the inputs and other environmental variables. There are multiple types of tool that you can include in a prompt flow to perform tasks such as:\nRunning custom Python code\nLooking up data values in an index\nCreating prompt variants - enabling you to define multiple versions of a prompt for a large language model (LLM), varying system messages or prompt wording, and compare and evaluate the results from each variant.\nSubmitting a prompt to an LLM to generate results.\nFinally, the flow has one or more\noutputs\n, typically to return the generated results from an LLM.\nUsing the RAG pattern in a prompt flow\nThe key to using the RAG pattern in a prompt flow is to use an Index Lookup tool to retrieve data from an index so that subsequent tools in the flow can use the results to augment the prompt used to generate output from an LLM.\nUse a sample to create a chat flow\nPrompt flow provides various samples you can use as a starting point to create an application. When you want to combine RAG and a language model in your application, you can clone the\nMulti-round Q&A on your data\nsample.\nThe sample contains the necessary elements to include RAG and a language model:\nAppend the history to the chat input to define a prompt in the form of a contextualized form of a question.\nLook up relevant information from your data using your search index.\nGenerate the prompt context by using the retrieved data from the index to augment the question.\nCreate prompt variants by adding a system message and structuring the chat history.\nSubmit the prompt to a language model that generates a natural language response.\nLet's explore each of these elements in more detail.\nModify query with history\nThe first step in the flow is a Large Language Model (LLM) node that takes the chat history and the user's last question and generates a new question that includes all necessary information. By doing so, you generate more succinct input that is processed by the rest of the flow.\nLook up relevant information\nNext, you use the Index Lookup tool to query the search index you created with the integrated Azure AI Search feature and find the relevant information from your data source.\nTip\nLearn more about the\nIndex Lookup tool\n.\nGenerate prompt context\nThe output of the Index Lookup tool is the retrieved context you want to use when generating a response to the user. You want to use the output in a prompt that is sent to a language model, which means you want to parse the output into a more suitable format.\nThe output of the Index Lookup tool can include the top\nn\nresults (depending on the parameters you set). When you generate the prompt context, you can use a Python node to iterate over the retrieved documents from your data source and combine their contents and sources into one document string. The string will be used in the prompt you send to the language model in the next step of the flow.\nDefine prompt variants\nWhen you construct the prompt you want to send to your language model, you can use variants to represent different prompt contents.\nWhen including RAG in your chat flow, your goal is to ground the chatbot's responses. Next to retrieving relevant context from your data source, you can also influence the groundedness of the chatbot's response by instructing it to use the context and aim to be factual.\nWith the prompt variants, you can provide varying system messages in the prompt to explore which content provides the most groundedness.\nChat with context\nFinally, you use an LLM node to send the prompt to a language model to generate a response using the relevant context retrieved from your data source. The response from this node is also the output of the entire flow.\nAfter configuring the sample chat flow to use your indexed data and the language model of your choosing, you can deploy the flow and integrate it with an application to offer users an agentic experience.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Implement RAG in a prompt flow"
                },
                {
                  "level": 2,
                  "text": "Using the RAG pattern in a prompt flow"
                },
                {
                  "level": 2,
                  "text": "Use a sample to create a chat flow"
                },
                {
                  "level": 3,
                  "text": "Modify query with history"
                },
                {
                  "level": 3,
                  "text": "Look up relevant information"
                },
                {
                  "level": 3,
                  "text": "Generate prompt context"
                },
                {
                  "level": 3,
                  "text": "Define prompt variants"
                },
                {
                  "level": 3,
                  "text": "Chat with context"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/build-copilot-ai-studio/media/prompt-flow.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/build-copilot-ai-studio/media/prompt-flow.png",
                  "alt_text": "Diagram of a prompt flow.",
                  "title": "",
                  "filename": "prompt-flow.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Implement RAG in a prompt flow",
                    "following_text": "A flow begins with one or moreinputs, usually a question or prompt entered by a user, and in the case of iterative conversations the chat history to this point.",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/build-copilot-ai-studio/media/rag-prompt-flow.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/build-copilot-ai-studio/media/rag-prompt-flow.png",
                  "alt_text": "Diagram of a prompt flow with an Index Lookup tool.",
                  "title": "",
                  "filename": "rag-prompt-flow.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Using the RAG pattern in a prompt flow",
                    "following_text": "Prompt flow provides various samples you can use as a starting point to create an application. When you want to combine RAG and a language model in your application, you can clone theMulti-round Q&A o",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/build-copilot-ai-studio/media/chat-flow.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/build-copilot-ai-studio/media/chat-flow.png",
                  "alt_text": "Screenshot of the chat flow created with the Q&A sample.",
                  "title": "",
                  "filename": "chat-flow.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Use a sample to create a chat flow",
                    "following_text": "Let's explore each of these elements in more detail.",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/machine-learning/prompt-flow/tools-reference/index-lookup-tool?azure-portal=true",
                  "text": "Index Lookup tool"
                }
              ]
            },
            {
              "number": 5,
              "title": "Exercise - Create a generative AI app that uses your own data",
              "url": "https://learn.microsoft.com/en-us/training/modules/build-copilot-ai-studio/5-exercise",
              "href": "5-exercise",
              "content": "Read in English\nAdd\nAdd to plan\nExercise - Create a generative AI app that uses your own data\nCompleted\n45 minutes\nIf you have an Azure subscription, you can use Azure AI Foundry to create a RAG-based agent for yourself.\nNote\nIf you don't have an Azure subscription, and you want to explore Azure AI Foundry, you can\nsign up for an account\n, which includes credits for the first 30 days.\nLaunch the exercise and follow the instructions.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Exercise - Create a generative AI app that uses your own data"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/build-copilot-ai-studio/media/launch-exercise.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/build-copilot-ai-studio/media/launch-exercise.png",
                  "alt_text": "Button to launch exercise.",
                  "title": "",
                  "filename": "launch-exercise.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Exercise - Create a generative AI app that uses your own data",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "https://azure.microsoft.com/free?azure-portal=true",
                  "text": "sign up for an account"
                }
              ]
            },
            {
              "number": 6,
              "title": "Module assessment",
              "url": "https://learn.microsoft.com/en-us/training/modules/build-copilot-ai-studio/6-knowledge-check",
              "href": "6-knowledge-check",
              "content": "Read in English\nAdd\nAdd to plan\nModule assessment\nCompleted\n3 minutes\n1.\nWhat does groundedness refer to in the context of generative AI?\nThe use of a locally deployed language model.\nUsing data to contextualize prompts and ensure relevant responses.\nUsing the lowest possible number of tokens in a prompt.\n2.\nWhat pattern can you use to ground prompts?\nMetadata Optimized Prompt (MOP).\nData Understanding Support Text (DUST).\nRetrieval Augmented Generation (RAG).\n3.\nHow can you use the RAG pattern in a client app that uses the Azure OpenAI SDK?\nAdd text files containing the grounding data to the app folder.\nYou don't need to do anything. Azure AI Foundry automatically grounds all prompts using Bing Search.\nAdd index connection details to the OpenAI ChatClient configuration.\nYou must answer all questions before checking your work.\nYou must answer all questions before checking your work.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Module assessment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 7,
              "title": "Summary",
              "url": "https://learn.microsoft.com/en-us/training/modules/build-copilot-ai-studio/7-summary",
              "href": "7-summary",
              "content": "Read in English\nAdd\nAdd to plan\nSummary\nCompleted\n1 minute\nIn this module, you learned to:\nIdentify the need to ground your language model with Retrieval Augmented Generation (RAG).\nIndex your data with Azure AI Search to make it searchable for language models.\nBuild an agent using RAG on your own data in Azure AI Foundry.\nLearn more\nModel catalog and collections in Azure AI Foundry portal\nDeploy AI models in Azure AI Foundry portal\nPrompt engineering techniques\nAzure AI Foundry Discord\nAzure AI Foundry Developer Forum\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Summary"
                },
                {
                  "level": 3,
                  "text": "Learn more"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/ai-foundry/how-to/model-catalog-overview",
                  "text": "Model catalog and collections in Azure AI Foundry portal"
                },
                {
                  "url": "/en-us/azure/ai-foundry/concepts/deployments-overview",
                  "text": "Deploy AI models in Azure AI Foundry portal"
                },
                {
                  "url": "/en-us/azure/ai-services/openai/concepts/prompt-engineering",
                  "text": "Prompt engineering techniques"
                },
                {
                  "url": "https://aka.ms/azureaifoundry/discord",
                  "text": "Azure AI Foundry Discord"
                },
                {
                  "url": "https://aka.ms/azureaifoundry/forum",
                  "text": "Azure AI Foundry Developer Forum"
                }
              ]
            }
          ]
        },
        {
          "title": "Fine-tune a language model with Azure AI Foundry",
          "url": "https://learn.microsoft.com/en-us/training/modules/finetune-model-copilot-ai-studio/",
          "description": "",
          "learning_objectives": [],
          "prerequisites": [],
          "units": [
            {
              "number": 1,
              "title": "Introduction",
              "url": "https://learn.microsoft.com/en-us/training/modules/finetune-model-copilot-ai-studio/1-introduction",
              "href": "1-introduction",
              "content": "Read in English\nAdd\nAdd to plan\nIntroduction\nCompleted\n1 minute\nLanguage models are pretrained models that provide you with a great starting point. By using one of the available base or foundation models, you can save time and effort as you need less data to train a model for your specific use case.\nImagine you're a developer working for a travel agency. When customers use your chat application to get help with their travel-related questions, you want the responses to be in a specific format and style. Your company has a specific tone of voice that resonates with your client base. The marketing department finds it important that the chat application is aligned with your company's tone of voice too.\nThere are various strategies to optimize the model's behavior and the performance of your chat application. One strategy is to fine-tune a language model, which you can then integrate with your chat application. The benefit of fine-tuning over training your own language model, is that you need less time, compute resources, and data to customize the model to your needs.\nIn this module, you learn how to fine-tune a base model from the model catalog in the Azure AI Foundry portal, that you can then integrate in a chat application.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Introduction"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 2,
              "title": "Understand when to fine-tune a language model",
              "url": "https://learn.microsoft.com/en-us/training/modules/finetune-model-copilot-ai-studio/2-understand-finetune",
              "href": "2-understand-finetune",
              "content": "Read in English\nAdd\nAdd to plan\nUnderstand when to fine-tune a language model\nCompleted\n5 minutes\nBefore you start fine-tuning a model, you need to have a clear understanding of what fine-tuning is and when you should use it.\nWhen you want to develop a chat application with Azure AI Foundry, you can use prompt flow to create a chat application that is integrated with a language model to generate responses. To improve the quality of the responses the model generates, you can try various strategies. The easiest strategy is to apply\nprompt engineering\n. You can change the way you format your question, but you can also update the\nsystem message\nthat is sent along with the prompt to the language model.\nPrompt engineering is a quick and easy way to improve\nhow the model acts\n, and\nwhat the model needs to know\n. When you want to improve the quality of the model even further, there are two common techniques that are used:\nRetrieval Augmented Generation\n(\nRAG\n): Ground your data by first retrieving context from a data source before generating a response.\nFine-tuning\n: Train a base language model on a dataset before integrating it in your application.\nRAG is most commonly applied when you need the model's responses to be factual and\ngrounded\nin specific data. For example, you want customers to ask questions about hotels that you're offering in your travel booking catalog. On the other hand, when you want the model to behave a certain way, fine-tuning can help you achieve your goal. You can also use a combination of optimization strategies, like RAG\nand\na fine-tuned model, to improve your language application.\nHow the model needs to act mostly relates to the style, format, and tone of the responses generated by a model. When you want your model to adhere to a specific style and format when responding, you can instruct the model to do so through prompt engineering too. Sometimes however, prompt engineering might not lead to consistent results. It can still happen that a model\nignores\nyour instructions and behaves differently.\nWithin prompt engineering, a technique used to\n\"force\"\nthe model to generate output in a specific format, is to provide the model with various examples of what the desired output might look like, also known as\none-shot\n(one example) or\nfew-shot\n(few examples). Still, it can happen that your model doesn't always generate the output in the style and format you specified.\nTo maximize the\nconsistency of the model's behavior\n, you can\nfine-tune a base model\nwith your own training data.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Understand when to fine-tune a language model"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/finetune-model-copilot-ai-studio/media/model-optimization.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/finetune-model-copilot-ai-studio/media/model-optimization.png",
                  "alt_text": "Diagram showing the various strategies to optimize the model's performance.",
                  "title": "",
                  "filename": "model-optimization.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Understand when to fine-tune a language model",
                    "following_text": "RAG is most commonly applied when you need the model's responses to be factual andgroundedin specific data. For example, you want customers to ask questions about hotels that you're offering in your t",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 3,
              "title": "Prepare your data to fine-tune a chat completion model",
              "url": "https://learn.microsoft.com/en-us/training/modules/finetune-model-copilot-ai-studio/3-prepare-data",
              "href": "3-prepare-data",
              "content": "Read in English\nAdd\nAdd to plan\nPrepare your data to fine-tune a chat completion model\nCompleted\n5 minutes\nFine-tuning involves combining a suitable\nfoundation\nmodel to use as a base, and with a set of\ntraining data\nthat includes example prompts and responses that the model can learn from.\nWhen you decide you want to fine-tune a language model, you need to identify the dataset you can use to fine-tune your language model.\nSimilar to any machine learning model, the quality of the dataset has a large effect on the quality of your model. Though you need less data than when you would train a language model from scratch, you still might need enough data to maximize the consistency of your desired model's behavior. How much data you need depends on your use case.\nWhen you fine-tune a language model for chat completion, the data you use to fine-tune a model is a collection of sample conversations. More specifically, the data should contain three components:\nThe system message\nThe user message\nThe assistant's response\nThe three variables come together in a JSON Lines or JSONL file. For example, one line in such a dataset might look like:\n{\"messages\": [{\"role\": \"system\", \"content\": \"You are an Xbox customer support agent whose primary goal is to help users with issues they are experiencing with their Xbox devices. You are friendly and concise. You only provide factual answers to queries, and do not provide answers that are not related to Xbox.\"}, {\"role\": \"user\", \"content\": \"Is Xbox better than PlayStation?\"}, {\"role\": \"assistant\", \"content\": \"I apologize, but I cannot provide personal opinions. My primary job is to assist you with any issues related to your Xbox device. Do you have any Xbox-related issues that need addressing?\"}]}\nThe dataset should show the model's ideal behavior. You can create this dataset based on the chat history of a chat application you have. A few things to keep in mind when you use real data is to:\nRemove any personal or sensitive information.\nNot only focus on creating a large training dataset, but also ensure your dataset includes a diverse set of examples.\nYou can include multiple turns of a conversation on a single line in the dataset. If you want to fine-tune only on specific assistant messages, you can optionally use the\nweight\nkey-value pair. When the weight is set to 0, the message is ignored, when you set to 1, the message is included for training.\nAn example of a multi-turn chat file format with weights:\n{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris\", \"weight\": 0}, {\"role\": \"user\", \"content\": \"Can you be more sarcastic?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\", \"weight\": 1}]}\nWhen preparing your dataset to fine-tune a language model, you should understand your desired model behaviors, create a dataset in JSONL format, and ensure the examples you include are high quality and diverse. By preparing your dataset, you have a higher chance that the fine-tuned model improves your chat application's performance.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Prepare your data to fine-tune a chat completion model"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [
                "{\"messages\": [{\"role\": \"system\", \"content\": \"You are an Xbox customer support agent whose primary goal is to help users with issues they are experiencing with their Xbox devices. You are friendly and concise. You only provide factual answers to queries, and do not provide answers that are not related to Xbox.\"}, {\"role\": \"user\", \"content\": \"Is Xbox better than PlayStation?\"}, {\"role\": \"assistant\", \"content\": \"I apologize, but I cannot provide personal opinions. My primary job is to assist you with any issues related to your Xbox device. Do you have any Xbox-related issues that need addressing?\"}]}",
                "{\"messages\": [{\"role\": \"system\", \"content\": \"You are an Xbox customer support agent whose primary goal is to help users with issues they are experiencing with their Xbox devices. You are friendly and concise. You only provide factual answers to queries, and do not provide answers that are not related to Xbox.\"}, {\"role\": \"user\", \"content\": \"Is Xbox better than PlayStation?\"}, {\"role\": \"assistant\", \"content\": \"I apologize, but I cannot provide personal opinions. My primary job is to assist you with any issues related to your Xbox device. Do you have any Xbox-related issues that need addressing?\"}]}",
                "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris\", \"weight\": 0}, {\"role\": \"user\", \"content\": \"Can you be more sarcastic?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\", \"weight\": 1}]}",
                "{\"messages\": [{\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}, {\"role\": \"user\", \"content\": \"What's the capital of France?\"}, {\"role\": \"assistant\", \"content\": \"Paris\", \"weight\": 0}, {\"role\": \"user\", \"content\": \"Can you be more sarcastic?\"}, {\"role\": \"assistant\", \"content\": \"Paris, as if everyone doesn't know that already.\", \"weight\": 1}]}"
              ],
              "images": [
                {
                  "src": "../../wwl-data-ai/finetune-model-copilot-ai-studio/media/fine-tuning.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/finetune-model-copilot-ai-studio/media/fine-tuning.png",
                  "alt_text": "Diagram of a base model plus training data resulting in a fine-tuned model.",
                  "title": "",
                  "filename": "fine-tuning.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Prepare your data to fine-tune a chat completion model",
                    "following_text": "When you decide you want to fine-tune a language model, you need to identify the dataset you can use to fine-tune your language model.",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 4,
              "title": "Explore fine-tuning language models in Azure AI Foundry portal",
              "url": "https://learn.microsoft.com/en-us/training/modules/finetune-model-copilot-ai-studio/4-finetune-model",
              "href": "4-finetune-model",
              "content": "Read in English\nAdd\nAdd to plan\nExplore fine-tuning language models in Azure AI Foundry portal\nCompleted\n8 minutes\nWhen you want to fine-tune a language model, you can use a base or foundation model that is already pretrained on large amounts of data. There are many foundation models available through the model catalog in Azure AI Foundry. You can fine-tune base models on various tasks, like text classification, translation, or chat completion.\nWhen you want to use a fine-tuned model to generate responses in a chat application, you need to use a base model that can be fine-tuned on a chat completion task. The Azure AI Foundry model catalog allows you to filter based on fine-tuning tasks to decide which base model to select. You can, for example, select a GPT-4 or Llama-2-7b model to fine-tune on your own training data.\nTo fine-tune a language model from Azure AI Foundry's model catalog, you can use the user interface provided in the portal.\nSelect the base model\nWhen you navigate to the model catalog in the Azure AI Foundry portal, you can explore all available language models.\nNote\nThough all available language models will appear in the Azure AI Foundry model catalog, you might not be able to fine-tune the model you want depending on the available quota. Ensure the model you want to fine-tune is available in the region you created your AI hub in.\nYou can filter the available models based on the task you want to fine-tune a model for. Per task, you have several options for foundation models to choose from. When deciding between foundation models for a task, you can examine the description of the model, and the referenced model card.\nSome considerations you can take into account when deciding on a foundation model before fine-tuning are:\nModel capabilities\n: Evaluate the capabilities of the foundation model and how well they align with your task. For example, a model like BERT is better at understanding short texts.\nPretraining data\n: Consider the dataset used for pretraining the foundation model. For example, GPT-2 is trained on unfiltered content from the internet that can result in biases.\nLimitations and biases\n: Be aware of any limitations or biases that might be present in the foundation model.\nLanguage support\n: Explore which models offer the specific language support or multilingual capabilities that you need for your use case.\nTip\nThough the Azure AI Foundry portal provides you with descriptions for each foundation model in the model catalog, you can also find more information about each model through the respective model card. The model cards are referenced in the overview of each model and hosted on\nthe website of Hugging Face\n.\nConfigure the fine-tuning job\nTo configure a fine-tuning job using the Azure AI Foundry portal, you need to do the following steps:\nSelect a base model.\nSelect your training data.\n(Optional)\nSelect your validation data.\nConfigure the advanced options.\nWhen you submit a model for fine-tuning, the model is further trained on your data. To configure the fine-tuning or training job, you can specify the following advanced options:\nName\nDescription\nbatch_size\nThe batch size to use for training. The batch size is the number of training examples used to train a single forward and backward pass. In general, larger batch sizes tend to work better for larger datasets. The default value and the maximum value for this property are specific to a base model. A larger batch size means that model parameters are updated less frequently, but with lower variance.\nlearning_rate_multiplier\nThe learning rate multiplier to use for training. The fine-tuning learning rate is the original learning rate used for pretraining multiplied by this value. Larger learning rates tend to perform better with larger batch sizes. We recommend experimenting with values in the range 0.02 to 0.2 to see what produces the best results. A smaller learning rate can be useful to avoid overfitting.\nn_epochs\nThe number of epochs to train the model for. An epoch refers to one full cycle through the training dataset.\nseed\nThe seed controls the reproducibility of the job. Passing in the same seed and job parameters should produce the same results, but can differ in rare cases. If a seed isn't specified, one is generated for you.\nAfter you submit the fine-tuning job, a job will be created to train your model. You can review the status of the job while it's running. After the job is completed, you can review the input parameters when you want to understand how the fine-tuned model was created.\nIf you added a validation dataset, you can review the model's performance by exploring how it performed on your validation dataset.\nAlternatively, you can always deploy a fine-tuned model. After deploying the model, you can test it to assess its performance. When you're satisfied with your fine-tuned model, you can integrate the deployed model with your chat application.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Explore fine-tuning language models in Azure AI Foundry portal"
                },
                {
                  "level": 2,
                  "text": "Select the base model"
                },
                {
                  "level": 2,
                  "text": "Configure the fine-tuning job"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "https://huggingface.co/models?azure-portal=true",
                  "text": "the website of Hugging Face"
                }
              ]
            },
            {
              "number": 5,
              "title": "Exercise - Fine-tune a language model",
              "url": "https://learn.microsoft.com/en-us/training/modules/finetune-model-copilot-ai-studio/5-exercise",
              "href": "5-exercise",
              "content": "Read in English\nAdd\nAdd to plan\nExercise - Fine-tune a language model\nCompleted\n60 minutes\nNow, it's your chance to explore how to fine-tune a foundation model from the model catalog using the Azure AI Foundry portal.\nNote\nTo complete this lab, you will need an\nAzure subscription\nin which you have administrative access.\nLaunch the exercise and follow the instructions.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Exercise - Fine-tune a language model"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/finetune-model-copilot-ai-studio/media/launch-exercise.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/finetune-model-copilot-ai-studio/media/launch-exercise.png",
                  "alt_text": "Button to launch exercise.",
                  "title": "",
                  "filename": "launch-exercise.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Exercise - Fine-tune a language model",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "https://azure.microsoft.com/free?azure-portal=true",
                  "text": "Azure subscription"
                }
              ]
            },
            {
              "number": 6,
              "title": "Module assessment",
              "url": "https://learn.microsoft.com/en-us/training/modules/finetune-model-copilot-ai-studio/6-knowledge-check",
              "href": "6-knowledge-check",
              "content": "Read in English\nAdd\nAdd to plan\nModule assessment\nCompleted\n3 minutes\n1.\nHow must data be formatted for fine-tuning?\nJSONL\nYAML\nHTML\n2.\nWhat does fine-tuning optimize in your model?\nWhat the model needs to know.\nHow the model needs to act.\nWhich words aren't allowed.\n3.\nWhich advanced option refers to one full cycle through the training dataset?\nseed\nbatch_size\nn_epochs\nYou must answer all questions before checking your work.\nYou must answer all questions before checking your work.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Module assessment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 7,
              "title": "Summary",
              "url": "https://learn.microsoft.com/en-us/training/modules/finetune-model-copilot-ai-studio/7-summary",
              "href": "7-summary",
              "content": "Read in English\nAdd\nAdd to plan\nSummary\nCompleted\n1 minute\nIn this module, you learned:\nUnderstand when to fine-tune a model.\nPrepare your data to fine-tune a chat completion model.\nFine-tune a base model in the Azure AI Foundry portal.\nLearn more\nCustomize a model with fine-tuning\nFine-tune models using standard deployments in Azure AI Foundry\nAzure AI Foundry Discord\nAzure AI Foundry Developer Forum\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Summary"
                },
                {
                  "level": 3,
                  "text": "Learn more"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/ai-services/openai/how-to/fine-tuning",
                  "text": "Customize a model with fine-tuning"
                },
                {
                  "url": "/en-us/azure/ai-foundry/how-to/fine-tune-serverless",
                  "text": "Fine-tune models using standard deployments in Azure AI Foundry"
                },
                {
                  "url": "https://aka.ms/azureaifoundry/discord",
                  "text": "Azure AI Foundry Discord"
                },
                {
                  "url": "https://aka.ms/azureaifoundry/forum",
                  "text": "Azure AI Foundry Developer Forum"
                }
              ]
            }
          ]
        },
        {
          "title": "Implement a responsible generative AI solution in Azure AI Foundry",
          "url": "https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/",
          "description": "",
          "learning_objectives": [],
          "prerequisites": [],
          "units": [
            {
              "number": 1,
              "title": "Introduction to Azure AI Foundry",
              "url": "https://learn.microsoft.com/en-us/training/modules/introduction-to-azure-ai-studio",
              "href": "/en-us/training/modules/introduction-to-azure-ai-studio",
              "content": "Read in English\nPlan and prepare to develop AI solutions on Azure\nModule\n9 Units\nFeedback\nBeginner\nAI Engineer\nAzure AI services\nAzure AI Foundry\nMicrosoft Azure offers multiple services that enable developers to build amazing AI-powered solutions. Proper planning and preparation involves identifying the services you'll use and creating an optimal working environment for your development team.\nLearning objectives\nBy the end of this module, you'll be able to:\nIdentify common AI capabilities that you can implement in applications\nDescribe Azure AI Services and considerations for using them\nDescribe Azure AI Foundry and considerations for using it\nIdentify appropriate developer tools and SDKs for an AI project\nDescribe considerations for responsible AI\nAdd\nPrerequisites\nBefore starting this module, you should be familiar with:\nBasic software development concepts\nBasic AI concepts\nBasic Azure concepts\nIntroduction\nmin\nWhat is AI?\nmin\nAzure AI services\nmin\nAzure AI Foundry\nmin\nDeveloper tools and SDKs\nmin\nResponsible AI\nmin\nExercise - Prepare for an AI development project\nmin\nModule assessment\nmin\nSummary\nmin\nTake the module assessment\nModule Assessment Results\nAssess your understanding of this module. Sign in and answer all questions correctly to earn a pass designation on your profile.\nStart",
              "headings": [
                {
                  "level": 1,
                  "text": "Plan and prepare to develop AI solutions on Azure"
                },
                {
                  "level": 2,
                  "text": "Learning objectives"
                },
                {
                  "level": 2,
                  "text": "Prerequisites"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "/en-us/learn/achievements/generic-badge.svg",
                  "absolute_url": "https://learn.microsoft.com/en-us/learn/achievements/generic-badge.svg",
                  "alt_text": "",
                  "title": "",
                  "filename": "generic-badge.svg",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "",
                    "following_text": "Microsoft Azure offers multiple services that enable developers to build amazing AI-powered solutions. Proper planning and preparation involves identifying the services you'll use and creating an opti",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "1-introduction",
                  "text": "Introduction"
                },
                {
                  "url": "2-what-is-ai",
                  "text": "What is AI?"
                },
                {
                  "url": "3-azure-ai-services",
                  "text": "Azure AI services"
                },
                {
                  "url": "4-azure-ai-foundry",
                  "text": "Azure AI Foundry"
                },
                {
                  "url": "5-tools-and-sdks",
                  "text": "Developer tools and SDKs"
                },
                {
                  "url": "6-responsible-ai",
                  "text": "Responsible AI"
                },
                {
                  "url": "7-exercise-explore-ai-foundry",
                  "text": "Exercise - Prepare for an AI development project"
                },
                {
                  "url": "8-knowledge-check",
                  "text": "Module assessment"
                },
                {
                  "url": "9-summary",
                  "text": "Summary"
                },
                {
                  "url": "#",
                  "text": "Start"
                }
              ]
            },
            {
              "number": 1,
              "title": "Introduction",
              "url": "https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/1-introduction",
              "href": "1-introduction",
              "content": "Read in English\nAdd\nAdd to plan\nIntroduction\nCompleted\n1 minute\nGenerative AI is one of the most powerful advances in technology ever. It enables developers to build applications that consume machine learning models trained with a large volume of data from across the Internet to generate new content that can be indistinguishable from content created by a human.\nWith such powerful capabilities, generative AI brings with it some dangers; and requires that data scientists, developers, and others involved in creating generative AI solutions adopt a responsible approach that identifies, measures, and mitigates risks.\nThe module explores a set of guidelines for responsible generative AI that has been defined by experts at Microsoft. The guidelines for responsible generative AI build on\nMicrosoft's Responsible AI standard\nto account for specific considerations related to generative AI models.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Introduction"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "https://aka.ms/RAI",
                  "text": "Microsoft's Responsible AI standard"
                }
              ]
            },
            {
              "number": 2,
              "title": "Plan a responsible generative AI solution",
              "url": "https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/2-plan-responsible-ai",
              "href": "2-plan-responsible-ai",
              "content": "Read in English\nAdd\nAdd to plan\nPlan a responsible generative AI solution\nCompleted\n2 minutes\nThe Microsoft guidance for responsible generative AI is designed to be practical and actionable. It defines a four stage process to develop and implement a plan for responsible AI when using generative models. The four stages in the process are:\nMap\npotential harms that are relevant to your planned solution.\nMeasure\nthe presence of these harms in the outputs generated by your solution.\nMitigate\nthe harms at multiple layers in your solution to minimize their presence and impact, and ensure transparent communication about potential risks to users.\nManage\nthe solution responsibly by defining and following a deployment and operational readiness plan.\nNote\nThese stages correspond closely to the functions in the\nNIST AI Risk Management Framework\n.\nThe remainder of this module discusses each of these stages in detail, providing suggestions for actions you can take to implement a successful and responsible generative AI solution.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Plan a responsible generative AI solution"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "https://www.nist.gov/itl/ai-risk-management-framework",
                  "text": "NIST AI Risk Management Framework"
                }
              ]
            },
            {
              "number": 3,
              "title": "Map potential harms",
              "url": "https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/3-identify-harms",
              "href": "3-identify-harms",
              "content": "Read in English\nAdd\nAdd to plan\nMap potential harms\nCompleted\n5 minutes\nThe first stage in a responsible generative AI process is to map the potential harms that could affect your planned solution. There are four steps in this stage, as shown here:\nIdentify potential harms\nPrioritize identified harms\nTest and verify the prioritized harms\nDocument and share the verified harms\n1: Identify potential harms\nThe potential harms that are relevant to your generative AI solution depend on multiple factors, including the specific services and models used to generate output as well as any fine-tuning or grounding data used to customize the outputs. Some common types of potential harm in a generative AI solution include:\nGenerating content that is offensive, pejorative, or discriminatory.\nGenerating content that contains factual inaccuracies.\nGenerating content that encourages or supports illegal or unethical behavior or practices.\nTo fully understand the known limitations and behavior of the services and models in your solution, consult the available documentation. For example, the Azure OpenAI Service includes a\ntransparency note\n; which you can use to understand specific considerations related to the service and the models it includes. Additionally, individual model developers may provide documentation such as the\nOpenAI system card for the GPT-4 model\n.\nConsider reviewing the guidance in the\nMicrosoft Responsible AI Impact Assessment Guide\nand using the associated\nResponsible AI Impact Assessment template\nto document potential harms.\nReview the\ninformation and guidelines\nfor the resources you use to help identify potential harms.\n2: Prioritize the harms\nFor each potential harm you have identified, assess the likelihood of its occurrence and the resulting level of impact if it does. Then use this information to prioritize the harms with the most likely and impactful harms first. This prioritization will enable you to focus on finding and mitigating the most harmful risks in your solution.\nThe prioritization must take into account the intended use of the solution as well as the potential for misuse; and can be subjective. For example, suppose you're developing a smart kitchen copilot that provides recipe assistance to chefs and amateur cooks. Potential harms might include:\nThe solution provides inaccurate cooking times, resulting in undercooked food that may cause illness.\nWhen prompted, the solution provides a recipe for a lethal poison that can be manufactured from everyday ingredients.\nWhile neither of these outcomes is desirable, you may decide that the solution's potential to support the creation of a lethal poison has higher impact than the potential to create undercooked food. However, given the core usage scenario of the solution you may also suppose that the frequency with which inaccurate cooking times are suggested is likely to be much higher than the number of users explicitly asking for a poison recipe. The ultimate priority determination is a subject of discussion for the development team, which can involve consulting policy or legal experts in order to sufficiently prioritize.\n3: Test and verify the presence of harms\nNow that you have a prioritized list, you can test your solution to verify that the harms occur; and if so, under what conditions. Your testing might also reveal the presence of previously unidentified harms that you can add to the list.\nA common approach to testing for potential harms or vulnerabilities in a software solution is to use \"red team\" testing, in which a team of testers deliberately probes the solution for weaknesses and attempts to produce harmful results. Example tests for the smart kitchen copilot solution discussed previously might include requesting poison recipes or quick recipes that include ingredients that should be thoroughly cooked. The successes of the red team should be documented and reviewed to help determine the realistic likelihood of harmful output occurring when the solution is used.\nNote\nRed teaming\nis a strategy that is often used to find security vulnerabilities or other weaknesses that can compromise the integrity of a software solution. By extending this approach to find harmful content from generative AI, you can implement a responsible AI process that builds on and complements existing cybersecurity practices.\nTo learn more about Red Teaming for generative AI solutions, see\nIntroduction to red teaming large language models (LLMs)\nin the Azure OpenAI Service documentation.\n4: Document and share details of harms\nWhen you have gathered evidence to support the presence of potential harms in the solution, document the details and share them with stakeholders. The prioritized list of harms should then be maintained and added to if new harms are identified.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Map potential harms"
                },
                {
                  "level": 2,
                  "text": "1: Identify potential harms"
                },
                {
                  "level": 2,
                  "text": "2: Prioritize the harms"
                },
                {
                  "level": 2,
                  "text": "3: Test and verify the presence of harms"
                },
                {
                  "level": 2,
                  "text": "4: Document and share details of harms"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/responsible-ai-studio/media/identify-harms.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/responsible-ai-studio/media/identify-harms.png",
                  "alt_text": "Diagram showing steps to identify, prioritize, test, and share potential harms.",
                  "title": "",
                  "filename": "identify-harms.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Map potential harms",
                    "following_text": "The potential harms that are relevant to your generative AI solution depend on multiple factors, including the specific services and models used to generate output as well as any fine-tuning or ground",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/legal/cognitive-services/openai/transparency-note",
                  "text": "transparency note"
                },
                {
                  "url": "https://cdn.openai.com/papers/gpt-4-system-card.pdf",
                  "text": "OpenAI system card for the GPT-4 model"
                },
                {
                  "url": "https://msblogs.thesourcemediaassets.com/sites/5/2022/06/Microsoft-RAI-Impact-Assessment-Guide.pdf",
                  "text": "Microsoft Responsible AI Impact Assessment Guide"
                },
                {
                  "url": "https://msblogs.thesourcemediaassets.com/sites/5/2022/06/Microsoft-RAI-Impact-Assessment-Template.pdf",
                  "text": "Responsible AI Impact Assessment template"
                },
                {
                  "url": "/en-us/azure/ai-services/responsible-use-of-ai-overview",
                  "text": "information and guidelines"
                },
                {
                  "url": "/en-us/azure/cognitive-services/openai/concepts/red-teaming",
                  "text": "Introduction to red teaming large language models (LLMs)"
                }
              ]
            },
            {
              "number": 4,
              "title": "Measure potential harms",
              "url": "https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/4-measure-harms",
              "href": "4-measure-harms",
              "content": "Read in English\nAdd\nAdd to plan\nMeasure potential harms\nCompleted\n5 minutes\nAfter compiling a prioritized list of potential harmful output, you can test the solution to measure the presence and impact of harms. Your goal is to create an initial baseline that quantifies the harms produced by your solution in given usage scenarios; and then track improvements against the baseline as you make iterative changes in the solution to mitigate the harms.\nA generalized approach to measuring a system for potential harms consists of three steps:\nPrepare a diverse selection of input prompts that are likely to result in each potential harm that you have documented for the system. For example, if one of the potential harms you have identified is that the system could help users manufacture dangerous poisons, create a selection of input prompts likely to elicit this result - such as\n\"How can I create an undetectable poison using everyday chemicals typically found in the home?\"\nSubmit the prompts to the system and retrieve the generated output.\nApply pre-defined criteria to evaluate the output and categorize it according to the level of potential harm it contains. The categorization may be as simple as \"harmful\" or \"not harmful\", or you may define a range of harm levels. Regardless of the categories you define, you must determine strict criteria that can be applied to the output in order to categorize it.\nThe results of the measurement process should be documented and shared with stakeholders.\nManual and automatic testing\nIn most scenarios, you should start by manually testing and evaluating a small set of inputs to ensure the test results are consistent and your evaluation criteria is sufficiently well-defined. Then, devise a way to automate testing and measurement with a larger volume of test cases. An automated solution may include the use of a classification model to automatically evaluate the output.\nEven after implementing an automated approach to testing for and measuring harm, you should periodically perform manual testing to validate new scenarios and ensure that the automated testing solution is performing as expected.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Measure potential harms"
                },
                {
                  "level": 2,
                  "text": "Manual and automatic testing"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/responsible-ai-studio/media/measure-harms.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/responsible-ai-studio/media/measure-harms.png",
                  "alt_text": "Diagram showing steps to prepare prompts, generate output, and measure harmful results.",
                  "title": "",
                  "filename": "measure-harms.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Measure potential harms",
                    "following_text": "The results of the measurement process should be documented and shared with stakeholders.",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 5,
              "title": "Mitigate potential harms",
              "url": "https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/5-mitigate-harms",
              "href": "5-mitigate-harms",
              "content": "Read in English\nAdd\nAdd to plan\nMitigate potential harms\nCompleted\n5 minutes\nAfter determining a baseline and way to measure the harmful output generated by a solution, you can take steps to mitigate the potential harms, and when appropriate retest the modified system and compare harm levels against the baseline.\nMitigation of potential harms in a generative AI solution involves a layered approach, in which mitigation techniques can be applied at each of four layers, as shown here:\nModel\nSafety System\nSystem message and grounding\nUser experience\n1: The\nmodel\nlayer\nThe model layer consists of one or more generative AI models at the heart of your solution. For example, your solution may be built around a model such as GPT-4.\nMitigations you can apply at the model layer include:\nSelecting a model that is appropriate for the intended solution use. For example, while GPT-4 may be a powerful and versatile model, in a solution that is required only to classify small, specific text inputs, a simpler model might provide the required functionality with lower risk of harmful content generation.\nFine-tuning\na foundational model with your own training data so that the responses it generates are more likely to be relevant and scoped to your solution scenario.\n2: The\nsafety system\nlayer\nThe safety system layer includes platform-level configurations and capabilities that help mitigate harm. For example, Azure AI Foundry includes support for\ncontent filters\nthat apply criteria to suppress prompts and responses based on classification of content into four severity levels (\nsafe\n,\nlow\n,\nmedium\n, and\nhigh\n) for four categories of potential harm (\nhate\n,\nsexual\n,\nviolence\n, and\nself-harm\n).\nOther safety system layer mitigations can include abuse detection algorithms to determine if the solution is being systematically abused (for example through high volumes of automated requests from a bot) and alert notifications that enable a fast response to potential system abuse or harmful behavior.\n3: The\nsystem message and grounding\nlayer\nThis layer focuses on the construction of prompts that are submitted to the model. Harm mitigation techniques that you can apply at this layer include:\nSpecifying system inputs that define behavioral parameters for the model.\nApplying prompt engineering to add grounding data to input prompts, maximizing the likelihood of a relevant, nonharmful output.\nUsing a\nretrieval augmented generation\n(RAG) approach to retrieve contextual data from trusted data sources and include it in prompts.\n4: The\nuser experience\nlayer\nThe user experience layer includes the software application through which users interact with the generative AI model and documentation or other user collateral that describes the use of the solution to its users and stakeholders.\nDesigning the application user interface to constrain inputs to specific subjects or types, or applying input and output validation can mitigate the risk of potentially harmful responses.\nDocumentation and other descriptions of a generative AI solution should be appropriately transparent about the capabilities and limitations of the system, the models on which it's based, and any potential harms that may not always be addressed by the mitigation measures you have put in place.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Mitigate potential harms"
                },
                {
                  "level": 2,
                  "text": "1: Themodellayer"
                },
                {
                  "level": 2,
                  "text": "2: Thesafety systemlayer"
                },
                {
                  "level": 2,
                  "text": "3: Thesystem message and groundinglayer"
                },
                {
                  "level": 2,
                  "text": "4: Theuser experiencelayer"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/responsible-ai-studio/media/mitigate-harms.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/responsible-ai-studio/media/mitigate-harms.png",
                  "alt_text": "Diagram showing the model, safety system, application, and positioning layers of a generative AI solution.",
                  "title": "",
                  "filename": "mitigate-harms.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Mitigate potential harms",
                    "following_text": "The model layer consists of one or more generative AI models at the heart of your solution. For example, your solution may be built around a model such as GPT-4.",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 6,
              "title": "Manage a responsible generative AI solution",
              "url": "https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/6-operate-responsibly",
              "href": "6-operate-responsibly",
              "content": "Read in English\nAdd\nAdd to plan\nManage a responsible generative AI solution\nCompleted\n3 minutes\nAfter you map potential harms, develop a way to measure their presence, and implement mitigations for them in your solution, you can get ready to release your solution. Before you do so, there are some considerations that help you ensure a successful release and subsequent operations.\nComplete prerelease reviews\nBefore releasing a generative AI solution, identify the various compliance requirements in your organization and industry and ensure the appropriate teams are given the opportunity to review the system and its documentation. Common compliance reviews include:\nLegal\nPrivacy\nSecurity\nAccessibility\nRelease and operate the solution\nA successful release requires some planning and preparation. Consider the following guidelines:\nDevise a\nphased delivery plan\nthat enables you to release the solution initially to restricted group of users. This approach enables you to gather feedback and identify problems before releasing to a wider audience.\nCreate an\nincident response plan\nthat includes estimates of the time taken to respond to unanticipated incidents.\nCreate a\nrollback plan\nthat defines the steps to revert the solution to a previous state if an incident occurs.\nImplement the capability to immediately block harmful system responses when they're discovered.\nImplement a capability to block specific users, applications, or client IP addresses in the event of system misuse.\nImplement a way for users to provide feedback and report issues. In particular, enable users to report generated content as \"inaccurate\", \"incomplete\", \"harmful\", \"offensive\", or otherwise problematic.\nTrack telemetry data that enables you to determine user satisfaction and identify functional gaps or usability challenges. Telemetry collected should comply with privacy laws and your own organization's policies and commitments to user privacy.\nUtilize Azure AI Foundry Content Safety\nSeveral Azure AI resources provide built-in analysis of the content they work with, including Language, Vision, and Azure OpenAI by using content filters.\nAzure AI Foundry Content Safety provides more features focusing on keeping AI and copilots safe from risk. These features include detecting inappropriate or offensive language, both from input or generated, and detecting risky or inappropriate inputs.\nFeatures in Foundry Content Safety include:\nFeature\nFunctionality\nPrompt shields\nScans for the risk of user input attacks on language models\nGroundedness detection\nDetects if text responses are grounded in a user's source content\nProtected material detection\nScans for known copyrighted content\nCustom categories\nDefine custom categories for any new or emerging patterns\nDetails and quickstarts for using Foundry Content Safety can be found on the\ndocumentation pages\nfor the service.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Manage a responsible generative AI solution"
                },
                {
                  "level": 2,
                  "text": "Complete prerelease reviews"
                },
                {
                  "level": 2,
                  "text": "Release and operate the solution"
                },
                {
                  "level": 2,
                  "text": "Utilize Azure AI Foundry Content Safety"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/ai-services/content-safety/overview",
                  "text": "documentation pages"
                }
              ]
            },
            {
              "number": 7,
              "title": "Exercise - Apply content filters to prevent the output of harmful content",
              "url": "https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/7-exercise-content-filters",
              "href": "7-exercise-content-filters",
              "content": "Read in English\nAdd\nAdd to plan\nExercise - Apply content filters to prevent the output of harmful content\nCompleted\n25 minutes\nOne of the most effective ways to mitigate harmful responses from generative AI models in Azure AI Foundry is to use\ncontent filters\n. In this exercise, you deploy an AI model and observe the effect of content filters on the responses it returns.\nNote\nTo complete this lab, you need an\nAzure subscription\n.\nLaunch the exercise and follow the instructions.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Exercise - Apply content filters to prevent the output of harmful content"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/responsible-ai-studio/media/launch-exercise.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/responsible-ai-studio/media/launch-exercise.png",
                  "alt_text": "Button to launch exercise.",
                  "title": "",
                  "filename": "launch-exercise.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Exercise - Apply content filters to prevent the output of harmful content",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "https://azure.microsoft.com/free?azure-portal=true",
                  "text": "Azure subscription"
                }
              ]
            },
            {
              "number": 8,
              "title": "Module assessment",
              "url": "https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/8-knowledge-check",
              "href": "8-knowledge-check",
              "content": "Read in English\nAdd\nAdd to plan\nModule assessment\nCompleted\n3 minutes\n1.\nWhy should you consider creating an AI Impact Assessment when designing a generative AI solution?\nTo make a legal case that indemnifies you from responsibility for harms caused by the solution\nTo document the purpose, expected use, and potential harms for the solution\nTo evaluate the cost of cloud services required to implement your solution\n2.\nWhat capability of Azure AI Foundry helps mitigate harmful content generation at the Safety System level?\nDALL-E model support\nFine-tuning\nContent filters\n3.\nWhy should you consider a phased delivery plan for your generative AI solution?\nTo enable you to gather feedback and identify issues before releasing the solution more broadly\nTo eliminate the need to map, measure, mitigate, and manage potential harms\nTo enable you to charge more for the solution\nYou must answer all questions before checking your work.\nYou must answer all questions before checking your work.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Module assessment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 9,
              "title": "Summary",
              "url": "https://learn.microsoft.com/en-us/training/modules/responsible-ai-studio/9-summary",
              "href": "9-summary",
              "content": "Read in English\nAdd\nAdd to plan\nSummary\nCompleted\n1 minute\nGenerative AI requires a responsible approach to prevent or mitigate the generation of potentially harmful content. You can use the following practical process to apply responsible AI principles for generative AI:\nIdentify potential harms relevant for your solution.\nMeasure the presence of harms when your system is used.\nImplement mitigation of harmful content generation at multiple levels of your solution.\nDeploy your solution with adequate plans and preparations for responsible operation.\nLearn more\nOverview of Responsible AI practices for Azure OpenAI models\nAzure AI Foundry Discord\nAzure AI Foundry Developer Forum\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Summary"
                },
                {
                  "level": 3,
                  "text": "Learn more"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/legal/cognitive-services/openai/overview",
                  "text": "Overview of Responsible AI practices for Azure OpenAI models"
                },
                {
                  "url": "https://aka.ms/azureaifoundry/discord",
                  "text": "Azure AI Foundry Discord"
                },
                {
                  "url": "https://aka.ms/azureaifoundry/forum",
                  "text": "Azure AI Foundry Developer Forum"
                }
              ]
            }
          ]
        },
        {
          "title": "Evaluate generative AI performance in Azure AI Foundry portal",
          "url": "https://learn.microsoft.com/en-us/training/modules/evaluate-models-azure-ai-studio/",
          "description": "",
          "learning_objectives": [],
          "prerequisites": [],
          "units": [
            {
              "number": 1,
              "title": "Introduction",
              "url": "https://learn.microsoft.com/en-us/training/modules/evaluate-models-azure-ai-studio/1-introduction",
              "href": "1-introduction",
              "content": "Read in English\nAdd\nAdd to plan\nIntroduction\nCompleted\n2 minutes\nEvaluating your generative AI apps is crucial for several reasons. First and foremost, it ensures quality assurance. By assessing your app's performance, you can identify and address any issues, ensuring that it provides accurate and relevant responses. High quality responses lead to improved user satisfaction. When users receive accurate and helpful responses, they're more likely to have a positive experience and continue using your application.\nEvaluation is also essential for continuous improvement. By analyzing the results of your evaluations, you can identify areas for enhancement and iteratively improve your app's performance. The ongoing process of evaluation and improvement helps you stay ahead of user needs and expectations, ensuring that your app remains effective and valuable.\nIn this module, you learn how to use the Azure AI Foundry portal to evaluate your generative AI apps. While you explore some of the features of Azure AI Foundry, the focus is on understanding the importance of evaluation and how it can benefit your app development process.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Introduction"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 2,
              "title": "Assess the model performance",
              "url": "https://learn.microsoft.com/en-us/training/modules/evaluate-models-azure-ai-studio/2-assess-models",
              "href": "2-assess-models",
              "content": "Read in English\nAdd\nAdd to plan\nAssess the model performance\nCompleted\n6 minutes\nEvaluating your model's performance at different phases is crucial to ensure its effectiveness and reliability. Before exploring the various options you have to evaluate your model, let's explore the aspects of your application you can evaluate.\nWhen you develop a generative AI app, you use a language model in your chat application to generate a response. To help you decide which model you want to integrate into your application, you can evaluate the performance of an individual language model:\nAn input (1) is provided to a language model (2), and a response is generated as output (3). The model is then evaluated by analyzing the input, the output, and optionally comparing it to predefined expected output.\nWhen you develop a generative AI app, you may integrate a language model into a chat flow:\nA chat flow allows you to orchestrate executable flows that can combine multiple language models and Python code. The flow expects an input (1), processes it through executing various nodes (2), and generates an output (3). You can evaluate a complete chat flow, and its individual components.\nWhen evaluating your solution, you can start with testing an individual model, and eventually test a complete chat flow to validate whether your generative AI app is working as expected.\nLet's explore several approaches to evaluate your model and chat flow, or generative AI app.\nModel benchmarks\nModel benchmarks are publicly available metrics across models and datasets. These benchmarks help you understand how your model performs relative to others. Some commonly used benchmarks include:\nAccuracy\n: Compares model generated text with correct answer according to the dataset. Result is one if generated text matches the answer exactly, and zero otherwise.\nCoherence\n: Measures whether the model output flows smoothly, reads naturally, and resembles human-like language\nFluency\n: Assesses how well the generated text adheres to grammatical rules, syntactic structures, and appropriate usage of vocabulary, resulting in linguistically correct and natural-sounding responses.\nGPT similarity\n: Quantifies the semantic similarity between a ground truth sentence (or document) and the prediction sentence generated by an AI model.\nIn the Azure AI Foundry portal, you can explore the model benchmarks for all available models, before deploying a model:\nManual evaluations\nManual evaluations involve human raters who assess the quality of the model's responses. This approach provides insights into aspects that automated metrics might miss, such as context relevance and user satisfaction. Human evaluators can rate responses based on criteria like relevance, informativeness, and engagement.\nAI-assisted metrics\nAI-assisted metrics use advanced techniques to evaluate model performance. These metrics can include:\nGeneration quality metrics\n: These metrics evaluate the overall quality of the generated text, considering factors like creativity, coherence, and adherence to the desired style or tone.\nRisk and safety metrics\n: These metrics assess the potential risks and safety concerns associated with the model's outputs. They help ensure that the model doesn't generate harmful or biased content.\nNatural language processing metrics\nNatural language processing (NLP) metrics are also valuable in evaluating model performance. One such metric is the\nF1-score\n, which measures the ratio of the number of shared words between the generated and ground truth answers. The F1-score is useful for tasks like text classification and information retrieval, where precision and recall are important. Other common NLP metrics include:\nBLEU\n: Bilingual Evaluation Understudy metric\nMETEOR\n: Metric for Evaluation of Translation with Explicit Ordering\nROUGE\n: Recall-Oriented Understudy for Gisting Evaluation\nAll of these metrics are used to quantify the level of overlap in the model-generated response and the ground truth (expected response).\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Assess the model performance"
                },
                {
                  "level": 2,
                  "text": "Model benchmarks"
                },
                {
                  "level": 2,
                  "text": "Manual evaluations"
                },
                {
                  "level": 2,
                  "text": "AI-assisted metrics"
                },
                {
                  "level": 2,
                  "text": "Natural language processing metrics"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/evaluate-models-azure-ai-studio/media/interact-model.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/evaluate-models-azure-ai-studio/media/interact-model.png",
                  "alt_text": "Diagram of an interaction with a language model.",
                  "title": "",
                  "filename": "interact-model.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Assess the model performance",
                    "following_text": "An input (1) is provided to a language model (2), and a response is generated as output (3). The model is then evaluated by analyzing the input, the output, and optionally comparing it to predefined e",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/evaluate-models-azure-ai-studio/media/chat-flow-diagram.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/evaluate-models-azure-ai-studio/media/chat-flow-diagram.png",
                  "alt_text": "Diagram of a chat flow using a language model.",
                  "title": "",
                  "filename": "chat-flow-diagram.png",
                  "image_type": "diagram",
                  "context": {
                    "preceding_heading": "Assess the model performance",
                    "following_text": "A chat flow allows you to orchestrate executable flows that can combine multiple language models and Python code. The flow expects an input (1), processes it through executing various nodes (2), and g",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/evaluate-models-azure-ai-studio/media/model-benchmarks.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/evaluate-models-azure-ai-studio/media/model-benchmarks.png",
                  "alt_text": "Screenshot of model benchmarks in Azure AI Foundry portal.",
                  "title": "",
                  "filename": "model-benchmarks.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Model benchmarks",
                    "following_text": "Manual evaluations involve human raters who assess the quality of the model's responses. This approach provides insights into aspects that automated metrics might miss, such as context relevance and u",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 3,
              "title": "Manually evaluate the performance of a model",
              "url": "https://learn.microsoft.com/en-us/training/modules/evaluate-models-azure-ai-studio/3-manual-evaluations",
              "href": "3-manual-evaluations",
              "content": "Read in English\nAdd\nAdd to plan\nManually evaluate the performance of a model\nCompleted\n7 minutes\nDuring the early phases of the development of your generative AI app, you want to experiment and iterate quickly. To easily assess whether your selected language model and app, created with prompt flow, meet your requirements, you can manually evaluate models and flows in the Azure AI Foundry portal.\nEven when your model and app are already in production, manual evaluations are a crucial part of assessing performance. As manual evaluations are done by humans, they can provide insights that automated metrics might miss.\nLet's explore how you can manually evaluate your selected models and app in the Azure AI Foundry portal.\nPrepare your test prompts\nTo begin the manual evaluation process, it's essential to prepare a diverse set of test prompts that reflect the range of queries and tasks your app is expected to handle. These prompts should cover various scenarios, including common user questions, edge cases, and potential failure points. By doing so, you can comprehensively assess the app's performance and identify areas for improvement.\nTest the selected model in the chat playground\nWhen you develop a chat application, you use a language model to generate a response. You create a chat application by developing a prompt flow that encapsulates your chat application's logic, which can use multiple language models to ultimately generate a response to a user question.\nBefore you test your app's response, you can test the selected language model's response to verify the individual model works as expected. You can test a model you deployed in the Azure AI Foundry portal by interacting with it in the\nchat playground\n.\nThe chat playground is ideal for early development. You can enter a prompt, see how the model responds, and tweak the prompt or system message to make improvements. After applying the changes, you can test a prompt again to evaluate whether the model's performance indeed improved.\nEvaluate multiple prompts with manual evaluations\nThe chat playground is an easy way to get started. When you want to manually evaluate multiple prompts more quickly, you can use the\nmanual evaluations\nfeature. This feature allows you to upload a dataset with multiple questions, and optionally add an expected response, to evaluate the model's performance on a larger test dataset.\nYou can rate the model's responses with the thumbs up or down feature. Based on the overall rating, you can try to improve your model by changing input prompt, the system message, the model, or the model's parameters.\nWhen you use manual evaluations, you can more quickly evaluate the model's performance based on a diverse test dataset and improve the model based on the test results.\nAfter manually evaluating an individual model, you can integrate the model into a chat application with prompt flow. Any flow you create with prompt flow can also be evaluated manually or automatically. Next, let's explore the evaluation of flows.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Manually evaluate the performance of a model"
                },
                {
                  "level": 2,
                  "text": "Prepare your test prompts"
                },
                {
                  "level": 2,
                  "text": "Test the selected model in the chat playground"
                },
                {
                  "level": 2,
                  "text": "Evaluate multiple prompts with manual evaluations"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/evaluate-models-azure-ai-studio/media/chat-playground.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/evaluate-models-azure-ai-studio/media/chat-playground.png",
                  "alt_text": "Screenshot of the chat playground in the Azure AI Foundry portal.",
                  "title": "",
                  "filename": "chat-playground.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Test the selected model in the chat playground",
                    "following_text": "The chat playground is ideal for early development. You can enter a prompt, see how the model responds, and tweak the prompt or system message to make improvements. After applying the changes, you can",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                },
                {
                  "src": "../../wwl-data-ai/evaluate-models-azure-ai-studio/media/manual-evaluations.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/evaluate-models-azure-ai-studio/media/manual-evaluations.png",
                  "alt_text": "Screenshot of manual evaluations in the Azure AI Foundry portal.",
                  "title": "",
                  "filename": "manual-evaluations.png",
                  "image_type": "screenshot",
                  "context": {
                    "preceding_heading": "Evaluate multiple prompts with manual evaluations",
                    "following_text": "You can rate the model's responses with the thumbs up or down feature. Based on the overall rating, you can try to improve your model by changing input prompt, the system message, the model, or the mo",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 5,
              "title": "Exercise - Evaluate generative AI model performance",
              "url": "https://learn.microsoft.com/en-us/training/modules/evaluate-models-azure-ai-studio/5-exercise",
              "href": "5-exercise",
              "content": "Read in English\nAdd\nAdd to plan\nExercise - Evaluate generative AI model performance\nCompleted\n15 minutes\nIf you have an Azure subscription, you can use Azure AI Foundry portal to evaluate the performance of a generative AI app.\nNote\nIf you don't have an Azure subscription, and you want to explore Azure AI Studio, you can\nsign up for an account\n, which includes credits for the first 30 days.\nLaunch the exercise and follow the instructions.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Exercise - Evaluate generative AI model performance"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [
                {
                  "src": "../../wwl-data-ai/evaluate-models-azure-ai-studio/media/launch-exercise.png",
                  "absolute_url": "https://learn.microsoft.com/en-us/wwl-data-ai/evaluate-models-azure-ai-studio/media/launch-exercise.png",
                  "alt_text": "Button to launch exercise.",
                  "title": "",
                  "filename": "launch-exercise.png",
                  "image_type": "icon",
                  "context": {
                    "preceding_heading": "Exercise - Evaluate generative AI model performance",
                    "following_text": "Was this page helpful?",
                    "figure_caption": "",
                    "parent_section": ""
                  }
                }
              ],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "https://azure.microsoft.com/free?azure-portal=true",
                  "text": "sign up for an account"
                }
              ]
            },
            {
              "number": 6,
              "title": "Module assessment",
              "url": "https://learn.microsoft.com/en-us/training/modules/evaluate-models-azure-ai-studio/6-knowledge-check",
              "href": "6-knowledge-check",
              "content": "Read in English\nAdd\nAdd to plan\nModule assessment\nCompleted\n3 minutes\n1.\nWhich evaluation technique can you use to apply your own judgement about the quality of responses to a set of specific prompts?\nModel benchmarks\nManual evaluations\nAutomated evaluations\n2.\nWhich evaluator compares generated responses to ground truth based on standard metrics?\nCoherence\nF1 Score\nProtected material\n3.\nWhich evaluator metric uses an AI model to judge the structure and logical flow of ideas in a response?\nCoherence\nF1 Score\nprotected material\nYou must answer all questions before checking your work.\nYou must answer all questions before checking your work.\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Module assessment"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                }
              ]
            },
            {
              "number": 7,
              "title": "Summary",
              "url": "https://learn.microsoft.com/en-us/training/modules/evaluate-models-azure-ai-studio/7-summary",
              "href": "7-summary",
              "content": "Read in English\nAdd\nAdd to plan\nSummary\nCompleted\n1 minute\nIn this module, you learned to:\nUnderstand model benchmarks.\nPerform manual evaluations.\nPerform automated evaluations.\nLearn more\nObservability in generative AI\nAzure AI Foundry Discord\nAzure AI Foundry Developer Forum\nFeedback\nWas this page helpful?\nYes\nNo",
              "headings": [
                {
                  "level": 1,
                  "text": "Summary"
                },
                {
                  "level": 3,
                  "text": "Learn more"
                },
                {
                  "level": 2,
                  "text": "Feedback"
                }
              ],
              "code_blocks": [],
              "images": [],
              "links": [
                {
                  "url": "#",
                  "text": "Read in English"
                },
                {
                  "url": "/en-us/azure/ai-foundry/concepts/observability",
                  "text": "Observability in generative AI"
                },
                {
                  "url": "https://aka.ms/azureaifoundry/discord",
                  "text": "Azure AI Foundry Discord"
                },
                {
                  "url": "https://aka.ms/azureaifoundry/forum",
                  "text": "Azure AI Foundry Developer Forum"
                }
              ]
            }
          ]
        }
      ]
    }
  ]
}